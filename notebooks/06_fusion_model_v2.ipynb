{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6adda39f",
   "metadata": {},
   "source": [
    "# 06 — Modeling Satellite + Tabular\n",
    "\n",
    "## Baselines + Models\n",
    "\n",
    "**DSRF + MCMIPF fusion with tabular, with MLflow tracking**\n",
    "\n",
    "**Optuna (JournalStorage + lock)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4f01581",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 11:56:12.280938: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-23 11:56:12.288150: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763916972.298283  484691 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763916972.300998  484691 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-23 11:56:12.310727: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os, json, math, time, random, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "import mlflow\n",
    "import mlflow.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a407134",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9da59b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for g in gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(g, True)\n",
    "    except Exception:\n",
    "        pass\n",
    "print(\"TF GPUs:\", gpus)\n",
    "\n",
    "# Rutas\n",
    "ROOT = Path(\"..\").resolve()\n",
    "DATA_CLEAN = ROOT / \"data\" / \"clean\" / \"base_dataset.csv\"\n",
    "GOES_DIR   = ROOT / \"data\" / \"GOES_v2\"\n",
    "MCMIPF_DIR = GOES_DIR / \"MCMIPF\"\n",
    "\n",
    "OUT_DIR = ROOT / \"outputs\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ART_DIR = OUT_DIR / \"artifacts_mcmipf_cnnlite\"\n",
    "ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR = OUT_DIR / \"figures\" / \"mcmipf_cnnlite\"\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TARGET_COL = \"GHI\"\n",
    "FREQ = \"10T\"\n",
    "\n",
    "# Tamaño de imagen y submuestreo\n",
    "IMG_SIZE = 32      # tamaño de imagen (32x32)\n",
    "SUBSAMPLE = 1      # 1 = usar cada 10 min.\n",
    "\n",
    "PATIENCE = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6483d0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow tracking: /mnt/SOLARLAB/E_Ladino/Repo_2/solar-forecasting-colombia/outputs/mlruns\n"
     ]
    }
   ],
   "source": [
    "PRESETS = {\n",
    "    \"debug\": {   # para probar que todo corre\n",
    "        \"input_steps\":   6,\n",
    "        \"horizon_steps\": 6,\n",
    "        \"stride\":        6,\n",
    "        \"batch_size\":    2,\n",
    "        \"epochs_img\":    3,\n",
    "        \"epochs_fus\":    3,\n",
    "    },\n",
    "    \"light\": {   # corrida razonable sin matar la GPU\n",
    "        \"input_steps\":   12,\n",
    "        \"horizon_steps\": 6,\n",
    "        \"stride\":        3,\n",
    "        \"batch_size\":    4,\n",
    "        \"epochs_img\":    10,\n",
    "        \"epochs_fus\":    15,\n",
    "    },\n",
    "    \"heavy\": {   # cuando quieras apretar más (cuidado con el tiempo)\n",
    "        \"input_steps\":   18,\n",
    "        \"horizon_steps\": 6,\n",
    "        \"stride\":        2,\n",
    "        \"batch_size\":    4,\n",
    "        \"epochs_img\":    20,\n",
    "        \"epochs_fus\":    25,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Defaults \"globales\" (los usamos solo si no se sobreescriben en los presets)\n",
    "DEFAULT_INPUT_STEPS   = 12\n",
    "DEFAULT_HORIZON_STEPS = 6\n",
    "\n",
    "# MLflow\n",
    "MLFLOW_DIR = (OUT_DIR / \"mlruns\").resolve()\n",
    "mlflow.set_tracking_uri(\"file://\" + str(MLFLOW_DIR))\n",
    "mlflow.set_experiment(\"pg_industrial_satellite_MCMIPF_CNNLite\")\n",
    "mlflow.keras.autolog(log_models=False)\n",
    "print(\"MLflow tracking:\", MLFLOW_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5089ec8b",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89551bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño original: 107172  → submuestreado: 107172\n",
      "Total features used (tabular): 28\n",
      "['Presion', 'TempAmb', 'WindSpeed', 'WindDirection', 'hour_sin', 'hour_cos', 'DoY Sin', 'DoY Cos', 'solar_zenith', 'solar_azimuth', 'solar_elevation', 'TempAmb_roll1h_mean', 'TempAmb_roll6h_mean', 'Presion_roll1h_mean', 'Presion_roll6h_mean', 'WindSpeed_roll1h_mean', 'WindSpeed_roll6h_mean', 'temp_pressure_ratio', 'wind_temp_interaction', 'GHI_lag1', 'GHI_lag3', 'GHI_lag6', 'GHI_lag12', 'GHI_lag36', 'GHI_roll1h_mean', 'GHI_roll3h_mean', 'GHI_roll6h_mean', 'GHI_roll1h_max']\n",
      "N train/val/test (submuestreado): 75020 16076 16076\n"
     ]
    }
   ],
   "source": [
    "df_full = pd.read_csv(DATA_CLEAN, parse_dates=[0], index_col=0).sort_index()\n",
    "df_full.index.name = \"time\"\n",
    "\n",
    "# Submuestreo\n",
    "idx = np.arange(len(df_full))\n",
    "keep_mask = (idx % SUBSAMPLE) == 0\n",
    "df = df_full.iloc[keep_mask].copy()\n",
    "print(\"Tamaño original:\", len(df_full), \" → submuestreado:\", len(df))\n",
    "\n",
    "# Features tabulares\n",
    "base_feats = [\n",
    "    'Presion','TempAmb','WindSpeed','WindDirection',\n",
    "    'hour_sin','hour_cos','DoY Sin','DoY Cos',\n",
    "    'solar_zenith','solar_azimuth','solar_elevation',\n",
    "    'TempAmb_roll1h_mean','TempAmb_roll6h_mean',\n",
    "    'Presion_roll1h_mean','Presion_roll6h_mean',\n",
    "    'WindSpeed_roll1h_mean','WindSpeed_roll6h_mean',\n",
    "    'temp_pressure_ratio','wind_temp_interaction'\n",
    "]\n",
    "ghi_lags  = [c for c in ['GHI_lag1','GHI_lag3','GHI_lag6','GHI_lag12','GHI_lag36'] if c in df.columns]\n",
    "ghi_rolls = [c for c in ['GHI_roll1h_mean','GHI_roll3h_mean','GHI_roll6h_mean','GHI_roll1h_max'] if c in df.columns]\n",
    "feat_cols = [c for c in base_feats if c in df.columns] + ghi_lags + ghi_rolls\n",
    "print(f\"Total features used (tabular): {len(feat_cols)}\")\n",
    "print(feat_cols)\n",
    "\n",
    "assert TARGET_COL in df.columns, f\"TARGET_COL='{TARGET_COL}' no existe en el dataset\"\n",
    "\n",
    "# Split temporal\n",
    "n = len(df); i_tr = int(0.7*n); i_va = int(0.85*n)\n",
    "df_train, df_val, df_test = df.iloc[:i_tr], df.iloc[i_tr:i_va], df.iloc[i_va:]\n",
    "\n",
    "# Escalado\n",
    "X_scaler = StandardScaler(); y_scaler = StandardScaler()\n",
    "X_train = X_scaler.fit_transform(df_train[feat_cols].values)\n",
    "X_val   = X_scaler.transform(df_val[feat_cols].values)\n",
    "X_test  = X_scaler.transform(df_test[feat_cols].values)\n",
    "\n",
    "y_train = y_scaler.fit_transform(df_train[[TARGET_COL]].values).ravel()\n",
    "y_val   = y_scaler.transform(df_val[[TARGET_COL]].values).ravel()\n",
    "y_test  = y_scaler.transform(df_test[[TARGET_COL]].values).ravel()\n",
    "\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "X_train = imp.fit_transform(X_train)\n",
    "X_val   = imp.transform(X_val)\n",
    "X_test  = imp.transform(X_test)\n",
    "\n",
    "for name, arr in [(\"X_train\",X_train),(\"X_val\",X_val),(\"X_test\",X_test),\n",
    "                  (\"y_train\",y_train),(\"y_val\",y_val),(\"y_test\",y_test)]:\n",
    "    assert np.isfinite(arr).all(), f\"{name} tiene NaN/Inf\"\n",
    "\n",
    "time_index = df.index\n",
    "time_train, time_val, time_test = time_index[:i_tr], time_index[i_tr:i_va], time_index[i_va:]\n",
    "print(\"N train/val/test (submuestreado):\", len(time_train), len(time_val), len(time_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f344dda",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0c49aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_from_scaled(pred_scaled, true_scaled, y_scaler):\n",
    "    \"\"\"\n",
    "    Recibe predicciones y verdaderos en espacio escalado (z-score) y los\n",
    "    lleva de vuelta a W/m² para calcular métricas.\n",
    "    \"\"\"\n",
    "    p = y_scaler.inverse_transform(pred_scaled.reshape(-1,1)).ravel()\n",
    "    t = y_scaler.inverse_transform(true_scaled.reshape(-1,1)).ravel()\n",
    "\n",
    "    mask = np.isfinite(p) & np.isfinite(t)\n",
    "    if mask.sum() == 0:\n",
    "        print(\"[metrics_from_scaled] Sin valores finitos.\")\n",
    "        metrics = {k: float(\"nan\") for k in [\"MAE\",\"RMSE\",\"MAPE\",\"sMAPE\",\"R2\"]}\n",
    "        return metrics, (t, p)\n",
    "\n",
    "    if mask.sum() < len(p):\n",
    "        print(f\"[metrics_from_scaled] WARNING: filtrados {len(p) - mask.sum()} puntos no finitos.\")\n",
    "\n",
    "    p = p[mask]; t = t[mask]\n",
    "\n",
    "    mae = mean_absolute_error(t, p)\n",
    "    rmse = float(np.sqrt(mean_squared_error(t, p)))\n",
    "    mape = float(np.mean(np.abs(t - p) / (np.abs(t) + 1e-6)) * 100)\n",
    "    smape = float(100 * np.mean(2*np.abs(p - t) / (np.abs(t) + np.abs(p) + 1e-6)))\n",
    "    r2 = float(r2_score(t, p))\n",
    "    return {\"MAE\": mae, \"RMSE\": rmse, \"MAPE\": mape, \"sMAPE\": smape, \"R2\": r2}, (t, p)\n",
    "\n",
    "def _rmse(a,b):\n",
    "    return float(np.sqrt(mean_squared_error(a,b)))\n",
    "\n",
    "def build_seq_arrays_img_only(imgs_4d, y_1d, L, horizon, stride=1):\n",
    "    \"\"\"\n",
    "    Secuencias sólo imágenes:\n",
    "      imgs_4d: (N, H, W, C)\n",
    "      y_1d   : (N,)\n",
    "    Devuelve:\n",
    "      X_img_seq: (N', L, H, W, C)\n",
    "      y_seq    : (N',)\n",
    "    \"\"\"\n",
    "    N = imgs_4d.shape[0]\n",
    "    assert len(y_1d) == N\n",
    "    H, W, C = imgs_4d.shape[1:]\n",
    "    outX, outy = [], []\n",
    "    last = N - L - horizon + 1\n",
    "    if last <= 0:\n",
    "        return (np.zeros((0, L, H, W, C), dtype=\"float32\"),\n",
    "                np.zeros((0,), dtype=\"float32\"))\n",
    "    for i in range(0, last, stride):\n",
    "        block_img = imgs_4d[i:i+L]\n",
    "        outX.append(block_img)\n",
    "        outy.append(y_1d[i + L + horizon - 1])\n",
    "    return np.asarray(outX, dtype=\"float32\"), np.asarray(outy, dtype=\"float32\")\n",
    "\n",
    "def build_seq_arrays_img_tab(imgs_4d, X_tab_2d, y_1d, L, horizon, stride=1):\n",
    "    \"\"\"\n",
    "    Secuencias conjuntas imágenes + tabular:\n",
    "\n",
    "      imgs_4d : (N, H, W, C)\n",
    "      X_tab_2d: (N, D)\n",
    "      y_1d    : (N,)\n",
    "\n",
    "    Devuelve:\n",
    "      X_img_seq: (M, L, H, W, C)\n",
    "      X_tab_seq: (M, L, D)\n",
    "      y_seq    : (M,)\n",
    "    \"\"\"\n",
    "    N = imgs_4d.shape[0]\n",
    "    assert X_tab_2d.shape[0] == N\n",
    "    assert len(y_1d) == N\n",
    "\n",
    "    H, W, C = imgs_4d.shape[1:]\n",
    "    D = X_tab_2d.shape[1]\n",
    "\n",
    "    outX_img, outX_tab, outy = [], [], []\n",
    "    last = N - L - horizon + 1\n",
    "    if last <= 0:\n",
    "        return (np.zeros((0, L, H, W, C), dtype=\"float32\"),\n",
    "                np.zeros((0, L, D), dtype=\"float32\"),\n",
    "                np.zeros((0,), dtype=\"float32\"))\n",
    "\n",
    "    for i in range(0, last, stride):\n",
    "        block_img = imgs_4d[i:i+L]\n",
    "        block_tab = X_tab_2d[i:i+L]\n",
    "        outX_img.append(block_img)\n",
    "        outX_tab.append(block_tab)\n",
    "        outy.append(y_1d[i + L + horizon - 1])\n",
    "\n",
    "    return (np.asarray(outX_img, dtype=\"float32\"),\n",
    "            np.asarray(outX_tab, dtype=\"float32\"),\n",
    "            np.asarray(outy, dtype=\"float32\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3033f37a",
   "metadata": {},
   "source": [
    "### Satellite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d3eacfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "DSRF_DIR   = GOES_DIR / \"DSRF\"\n",
    "MCMIPF_DIR = GOES_DIR / \"MCMIPF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc60fd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mcmipf_multichannel(time_index,\n",
    "                              target_size=IMG_SIZE,\n",
    "                              sel_channels=(1,2,3,5,7,10,13,15)):\n",
    "    \"\"\"\n",
    "    Construye:\n",
    "      mcm_all: (N, H, W, C) con C = len(sel_channels)\n",
    "    \"\"\"\n",
    "    hours = time_index.floor(\"H\")\n",
    "    unique_hours = sorted(hours.unique())\n",
    "\n",
    "    hour_to_seq = {}\n",
    "    missing_hours = 0\n",
    "\n",
    "    assert 256 % target_size == 0\n",
    "    step = 256 // target_size\n",
    "    sel_channels = tuple(sel_channels)\n",
    "\n",
    "    # 1) Carga por hora\n",
    "    all_imgs_list = []\n",
    "    for h in unique_hours:\n",
    "        key = h.strftime(\"%Y%m%d_%H\")\n",
    "        year = key[:4]\n",
    "        month = key[4:6]\n",
    "        fname = f\"{key}_MCMIPF.npz\"\n",
    "        path = MCMIPF_DIR / year / month / fname\n",
    "        if not path.exists():\n",
    "            # 6 frames hora, llenos de ceros\n",
    "            seq = np.zeros((6, target_size, target_size, len(sel_channels)),\n",
    "                           dtype=\"float32\")\n",
    "            hour_to_seq[key] = seq\n",
    "            missing_hours += 1\n",
    "            continue\n",
    "\n",
    "        data = np.load(path)\n",
    "        arr = data[list(data.files)[0]]  # (6,16,256,256)\n",
    "        arr = arr.astype(\"float32\")[:, sel_channels, ::step, ::step]  # (6,C,H,W)\n",
    "        arr = np.transpose(arr, (0, 2, 3, 1))  # (6,H,W,C)\n",
    "        hour_to_seq[key] = arr\n",
    "        all_imgs_list.append(arr)\n",
    "\n",
    "    print(f\"MCMIPF: horas únicas en df(sub)      = {len(unique_hours)}\")\n",
    "    print(f\"MCMIPF: horas sin archivo NOAA (sub) = {missing_hours}\")\n",
    "\n",
    "    if len(all_imgs_list) == 0:\n",
    "        raise RuntimeError(\"No se pudo cargar ningún archivo MCMIPF.\")\n",
    "\n",
    "    all_imgs = np.concatenate(all_imgs_list, axis=0)  # (6*Hrs, H,W,C)\n",
    "    all_imgs = np.nan_to_num(all_imgs, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    # 2) Normalización canal a canal\n",
    "    C = all_imgs.shape[-1]\n",
    "    flat = all_imgs.reshape(-1, C)\n",
    "    mean_ch = flat.mean(axis=0)\n",
    "    std_ch  = flat.std(axis=0) + 1e-6\n",
    "    print(\"MCMIPF per-channel mean:\", mean_ch)\n",
    "    print(\"MCMIPF per-channel std :\", std_ch)\n",
    "\n",
    "    # 3) Secuencia completa alineada a time_index\n",
    "    imgs = []\n",
    "    for ts in time_index:\n",
    "        key = ts.strftime(\"%Y%m%d_%H\")\n",
    "        seq = hour_to_seq.get(key, None)\n",
    "        if seq is None:\n",
    "            frame = np.zeros((target_size,target_size,len(sel_channels)), dtype=\"float32\")\n",
    "        else:\n",
    "            slot = ts.minute // 10  # 0..5\n",
    "            slot = min(max(slot,0), 5)\n",
    "            frame = seq[slot]\n",
    "        frame = np.nan_to_num(frame, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        frame = (frame - mean_ch) / std_ch\n",
    "        imgs.append(frame)\n",
    "\n",
    "    mcm_all = np.stack(imgs, axis=0).astype(\"float32\")\n",
    "    return mcm_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23888d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Cargando MCMIPF completo (submuestreado, 32x32, 8 canales)...\n"
     ]
    }
   ],
   "source": [
    "print(f\"→ Cargando MCMIPF completo (submuestreado, {IMG_SIZE}x{IMG_SIZE}, 8 canales)...\")\n",
    "mcmipf_all = build_mcmipf_multichannel(time_index,\n",
    "                                       target_size=IMG_SIZE,\n",
    "                                       sel_channels=(1,2,3,5,7,10,13,15))\n",
    "print(\"MCMIPF_all:\", mcmipf_all.shape)\n",
    "\n",
    "mcm_train, mcm_val, mcm_test = mcmipf_all[:i_tr], mcmipf_all[i_tr:i_va], mcmipf_all[i_va:]\n",
    "\n",
    "for name, arr in [(\"mcm_train\",mcm_train),(\"mcm_val\",mcm_val),(\"mcm_test\",mcm_test)]:\n",
    "    assert np.isfinite(arr).all(), f\"{name} tiene NaN/Inf después de normalizar\"\n",
    "print(\"Tensores MCMIPF listos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892d5a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensores MCMIPF listos.\n"
     ]
    }
   ],
   "source": [
    "mcm_train, mcm_val, mcm_test = mcmipf_all[:i_tr], mcmipf_all[i_tr:i_va], mcmipf_all[i_va:]\n",
    "\n",
    "for name, arr in [(\"mcm_train\",mcm_train),(\"mcm_val\",mcm_val),(\"mcm_test\",mcm_test)]:\n",
    "    assert np.isfinite(arr).all(), f\"{name} tiene NaN/Inf después de normalizar\"\n",
    "print(\"Tensores MCMIPF listos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c844531",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9206f40",
   "metadata": {},
   "source": [
    "1) CNN-Lite + LSTM (solo MCMIPF)\n",
    "2) CNN-Lite + LSTM (MCMIPF) + LSTM (tabular) → fusión\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4720a572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cnn_block_for_mcm(H, W, C, emb_dim=64, name_prefix=\"mcm_cnn\"):\n",
    "    \"\"\"\n",
    "    CNN ligera para un solo frame MCMIPF (H,W,C) → embedding 1D\n",
    "    \"\"\"\n",
    "    model = models.Sequential(name=name_prefix)\n",
    "    model.add(layers.Conv2D(32, (3,3), padding=\"same\", activation=\"relu\", input_shape=(H,W,C)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(layers.Dense(emb_dim, activation=\"relu\"))\n",
    "    return model\n",
    "\n",
    "def build_mcmipf_cnn_lstm_model(L, H=IMG_SIZE, W=IMG_SIZE, C=8,\n",
    "                                emb_dim=64,\n",
    "                                lstm_units=64,\n",
    "                                dense_units=64,\n",
    "                                dropout_rate=0.3):\n",
    "    \"\"\"\n",
    "    Modelo sólo imágenes MCMIPF:\n",
    "      Input: (L, H, W, C)\n",
    "      TimeDistributed(CNN-lite) → (L, emb_dim)\n",
    "      LSTM → Dense → GHI\n",
    "    \"\"\"\n",
    "    inp_img = layers.Input(shape=(L, H, W, C), name=\"img_seq\")\n",
    "\n",
    "    cnn_block = make_cnn_block_for_mcm(H, W, C, emb_dim=emb_dim, name_prefix=\"mcm_cnn_frame\")\n",
    "    x = layers.TimeDistributed(cnn_block, name=\"td_mcm_cnn\")(inp_img)\n",
    "    x = layers.LSTM(lstm_units, activation=\"tanh\", name=\"lstm_img\")(x)\n",
    "    x = layers.Dense(dense_units, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    out = layers.Dense(1, dtype=\"float32\", name=\"y_hat\")(x)\n",
    "\n",
    "    model = models.Model(inp_img, out, name=\"MCMIPF_CNN_LSTM_only\")\n",
    "    return model\n",
    "\n",
    "def build_mcmipf_tabular_fusion_model(L,\n",
    "                                      tab_dim,\n",
    "                                      H=IMG_SIZE, W=IMG_SIZE, C=8,\n",
    "                                      emb_dim=64,\n",
    "                                      lstm_img_units=64,\n",
    "                                      lstm_tab_units=64,\n",
    "                                      dense_fusion_units=64,\n",
    "                                      dropout_rate=0.3):\n",
    "    \"\"\"\n",
    "    Fusión:\n",
    "      - rama imágenes: TimeDistributed(CNN-lite) → LSTM_img\n",
    "      - rama tabular : LSTM_tab\n",
    "      - concat → Dense → Dropout → Dense(1)\n",
    "    \"\"\"\n",
    "    # Imágenes\n",
    "    inp_img = layers.Input(shape=(L, H, W, C), name=\"img_seq\")\n",
    "    cnn_block = make_cnn_block_for_mcm(H, W, C, emb_dim=emb_dim, name_prefix=\"mcm_cnn_frame\")\n",
    "    x_img = layers.TimeDistributed(cnn_block, name=\"td_mcm_cnn\")(inp_img)\n",
    "    x_img = layers.LSTM(lstm_img_units, activation=\"tanh\", name=\"lstm_img\")(x_img)\n",
    "\n",
    "    # Tabular\n",
    "    inp_tab = layers.Input(shape=(L, tab_dim), name=\"tab_seq\")\n",
    "    x_tab = layers.LSTM(lstm_tab_units, activation=\"tanh\", name=\"lstm_tab\")(inp_tab)\n",
    "\n",
    "    # Fusión\n",
    "    x = layers.concatenate([x_img, x_tab], name=\"fusion_concat\")\n",
    "    x = layers.Dense(dense_fusion_units, activation=\"relu\", name=\"fusion_dense\")(x)\n",
    "    x = layers.Dropout(dropout_rate, name=\"fusion_dropout\")(x)\n",
    "    out = layers.Dense(1, dtype=\"float32\", name=\"y_hat\")(x)\n",
    "\n",
    "    model = models.Model([inp_img, inp_tab], out, name=\"MCMIPF_Tabular_Fusion_CNNLite\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62723e5",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152648e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_series(y_true, y_pred, title, n=1000, fname=None):\n",
    "    n = min(n, len(y_true))\n",
    "    plt.figure(figsize=(11,3.8))\n",
    "    plt.plot(y_true[:n], label=\"Real\", lw=1.5)\n",
    "    plt.plot(y_pred[:n], label=\"Pred\", lw=1.2, alpha=0.9)\n",
    "    plt.title(title); plt.xlabel(\"Time steps (submuestreados)\")\n",
    "    plt.ylabel(\"GHI (W/m²)\")\n",
    "    plt.legend(frameon=False); plt.tight_layout()\n",
    "    if fname is not None:\n",
    "        plt.savefig(fname, dpi=140)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b899d4be",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d2e01d",
   "metadata": {},
   "source": [
    "#### Training — 1) Sólo imágenes MCMIPF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fe7297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mcmipf_cnn_lstm(input_steps=DEFAULT_INPUT_STEPS,\n",
    "                          horizon_steps=DEFAULT_HORIZON_STEPS,\n",
    "                          lr=5e-4,\n",
    "                          batch_size=4,\n",
    "                          epochs=20,\n",
    "                          stride=2):\n",
    "    \"\"\"\n",
    "    Modelo sólo imágenes MCMIPF con CNN-lite + LSTM.\n",
    "    \"\"\"\n",
    "    Xtr_img_seq, ytr_seq = build_seq_arrays_img_only(\n",
    "        imgs_4d=mcm_train, y_1d=y_train,\n",
    "        L=input_steps, horizon=horizon_steps,\n",
    "        stride=stride\n",
    "    )\n",
    "    Xva_img_seq, yva_seq = build_seq_arrays_img_only(\n",
    "        imgs_4d=mcm_val, y_1d=y_val,\n",
    "        L=input_steps, horizon=horizon_steps,\n",
    "        stride=stride\n",
    "    )\n",
    "\n",
    "    print(\"MCMIPF CNN-LSTM (solo imágenes) shapes:\")\n",
    "    print(\"Xtr_img_seq:\", Xtr_img_seq.shape)\n",
    "    print(\"ytr_seq    :\", ytr_seq.shape)\n",
    "\n",
    "    if Xtr_img_seq.shape[0] == 0:\n",
    "        raise RuntimeError(\"No hay muestras de entrenamiento (revisa L/horizon/stride).\")\n",
    "\n",
    "    L = input_steps\n",
    "    H, W, C = Xtr_img_seq.shape[2:]\n",
    "\n",
    "    model = build_mcmipf_cnn_lstm_model(\n",
    "        L=L, H=H, W=W, C=C,\n",
    "        emb_dim=64,\n",
    "        lstm_units=64,\n",
    "        dense_units=64,\n",
    "        dropout_rate=0.3\n",
    "    )\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss=\"mse\")\n",
    "\n",
    "    ckpt = (ART_DIR / \"best_mcmipf_cnn_lstm_only.weights.h5\").resolve()\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=PATIENCE+2,\n",
    "                                restore_best_weights=True, verbose=1),\n",
    "        callbacks.ModelCheckpoint(filepath=str(ckpt), monitor=\"val_loss\",\n",
    "                                  save_best_only=True, save_weights_only=True)\n",
    "    ]\n",
    "\n",
    "    with mlflow.start_run(run_name=\"MCMIPF_CNN_LSTM_only\"):\n",
    "        mlflow.log_param(\"mode\",          \"img_only\")\n",
    "        mlflow.log_param(\"input_steps\",   input_steps)\n",
    "        mlflow.log_param(\"horizon_steps\", horizon_steps)\n",
    "        mlflow.log_param(\"lr\",            lr)\n",
    "        mlflow.log_param(\"batch_size\",    batch_size)\n",
    "        mlflow.log_param(\"epochs\",        epochs)\n",
    "        mlflow.log_param(\"stride\",        stride)\n",
    "        mlflow.log_param(\"img_H\",         H)\n",
    "        mlflow.log_param(\"img_W\",         W)\n",
    "        mlflow.log_param(\"img_C\",         C)\n",
    "\n",
    "        hist = model.fit(\n",
    "            Xtr_img_seq, ytr_seq,\n",
    "            validation_data=(Xva_img_seq, yva_seq),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=1,\n",
    "            callbacks=cbs,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        # Test\n",
    "        Xte_img_seq, yte_seq = build_seq_arrays_img_only(\n",
    "            imgs_4d=mcm_test, y_1d=y_test,\n",
    "            L=input_steps, horizon=horizon_steps,\n",
    "            stride=stride\n",
    "        )\n",
    "        yhat_test_scaled = model.predict(Xte_img_seq, verbose=0).squeeze()\n",
    "\n",
    "        metrics, (t_o, p_o) = metrics_from_scaled(yhat_test_scaled, yte_seq, y_scaler)\n",
    "        for k,v in metrics.items():\n",
    "            mlflow.log_metric(f\"test_{k}\", float(v))\n",
    "\n",
    "        mlflow.keras.log_model(\n",
    "            model,\n",
    "            artifact_path=\"MCMIPF_CNN_LSTM_only\"\n",
    "        )\n",
    "\n",
    "        print(\"MCMIPF CNN-LSTM test metrics:\", metrics)\n",
    "\n",
    "    return model, metrics, (t_o, p_o)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f2fada",
   "metadata": {},
   "source": [
    "#### Training — 2) Fusión MCMIPF + Tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104383c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mcmipf_tabular_fusion(input_steps=DEFAULT_INPUT_STEPS,\n",
    "                                horizon_steps=DEFAULT_HORIZON_STEPS,\n",
    "                                lr=5e-4,\n",
    "                                batch_size=4,\n",
    "                                epochs=20,\n",
    "                                stride=2):\n",
    "    \"\"\"\n",
    "    Modelo que integra:\n",
    "      - secuencias tabulares (L, F)\n",
    "      - secuencias de imágenes MCMIPF (L, H, W, C)\n",
    "    \"\"\"\n",
    "\n",
    "    Xtr_img_seq, Xtr_tab_seq, ytr_seq = build_seq_arrays_img_tab(\n",
    "        imgs_4d=mcm_train, X_tab_2d=X_train, y_1d=y_train,\n",
    "        L=input_steps, horizon=horizon_steps, stride=stride\n",
    "    )\n",
    "    Xva_img_seq, Xva_tab_seq, yva_seq = build_seq_arrays_img_tab(\n",
    "        imgs_4d=mcm_val, X_tab_2d=X_val, y_1d=y_val,\n",
    "        L=input_steps, horizon=horizon_steps, stride=stride\n",
    "    )\n",
    "\n",
    "    print(\"MCMIPF+Tabular fusion shapes:\")\n",
    "    print(\"Xtr_img_seq:\", Xtr_img_seq.shape)\n",
    "    print(\"Xtr_tab_seq:\", Xtr_tab_seq.shape)\n",
    "    print(\"ytr_seq    :\", ytr_seq.shape)\n",
    "\n",
    "    if Xtr_img_seq.shape[0] == 0:\n",
    "        raise RuntimeError(\"No hay muestras de entrenamiento (revisa L/horizon/stride).\")\n",
    "\n",
    "    L = input_steps\n",
    "    H, W, C = Xtr_img_seq.shape[2:]\n",
    "    tab_dim = Xtr_tab_seq.shape[-1]\n",
    "\n",
    "    model = build_mcmipf_tabular_fusion_model(\n",
    "        L=L, tab_dim=tab_dim,\n",
    "        H=H, W=W, C=C,\n",
    "        emb_dim=64,\n",
    "        lstm_img_units=64,\n",
    "        lstm_tab_units=64,\n",
    "        dense_fusion_units=64,\n",
    "        dropout_rate=0.3\n",
    "    )\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss=\"mse\")\n",
    "\n",
    "    ckpt = (ART_DIR / \"best_mcmipf_tabular_fusion.weights.h5\").resolve()\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=PATIENCE+2,\n",
    "                                restore_best_weights=True, verbose=1),\n",
    "        callbacks.ModelCheckpoint(filepath=str(ckpt), monitor=\"val_loss\",\n",
    "                                  save_best_only=True, save_weights_only=True)\n",
    "    ]\n",
    "\n",
    "    with mlflow.start_run(run_name=\"MCMIPF_Tabular_Fusion_CNNLite\"):\n",
    "        mlflow.log_param(\"mode\",          \"img+tab_fusion\")\n",
    "        mlflow.log_param(\"input_steps\",   input_steps)\n",
    "        mlflow.log_param(\"horizon_steps\", horizon_steps)\n",
    "        mlflow.log_param(\"lr\",            lr)\n",
    "        mlflow.log_param(\"batch_size\",    batch_size)\n",
    "        mlflow.log_param(\"epochs\",        epochs)\n",
    "        mlflow.log_param(\"stride\",        stride)\n",
    "        mlflow.log_param(\"img_H\",         H)\n",
    "        mlflow.log_param(\"img_W\",         W)\n",
    "        mlflow.log_param(\"img_C\",         C)\n",
    "        mlflow.log_param(\"tab_dim\",       tab_dim)\n",
    "\n",
    "        hist = model.fit(\n",
    "            {\"img_seq\": Xtr_img_seq, \"tab_seq\": Xtr_tab_seq},\n",
    "            ytr_seq,\n",
    "            validation_data=(\n",
    "                {\"img_seq\": Xva_img_seq, \"tab_seq\": Xva_tab_seq},\n",
    "                yva_seq\n",
    "            ),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=1,\n",
    "            callbacks=cbs,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        # Test\n",
    "        Xte_img_seq, Xte_tab_seq, yte_seq = build_seq_arrays_img_tab(\n",
    "            imgs_4d=mcm_test, X_tab_2d=X_test, y_1d=y_test,\n",
    "            L=input_steps, horizon=horizon_steps, stride=stride\n",
    "        )\n",
    "        yhat_test_scaled = model.predict(\n",
    "            {\"img_seq\": Xte_img_seq, \"tab_seq\": Xte_tab_seq},\n",
    "            verbose=0\n",
    "        ).squeeze()\n",
    "\n",
    "        metrics, (t_o, p_o) = metrics_from_scaled(yhat_test_scaled, yte_seq, y_scaler)\n",
    "        for k,v in metrics.items():\n",
    "            mlflow.log_metric(f\"test_{k}\", float(v))\n",
    "\n",
    "        mlflow.keras.log_model(\n",
    "            model,\n",
    "            artifact_path=\"MCMIPF_Tabular_Fusion_CNNLite\"\n",
    "        )\n",
    "\n",
    "        print(\"MCMIPF + Tabular fusion test metrics:\", metrics)\n",
    "\n",
    "    return model, metrics, (t_o, p_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e746532e",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e567ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCMIPF CNN-LSTM (solo imágenes) shapes:\n",
      "Xtr_img_seq: (37499, 18, 32, 32, 8)\n",
      "ytr_seq    : (37499,)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # ---- Cambia SOLO esta línea para correr más suave o más duro ----\n",
    "    MODE = \"debug\"        # opciones: \"debug\", \"light\", \"heavy\"\n",
    "    RUN_IMG_ONLY = True   \n",
    "    RUN_FUSION   = True   \n",
    "    # ----------------------------------------------------------------\n",
    "\n",
    "    cfg = PRESETS[MODE]\n",
    "    print(f\"\\n>>> Running MCMIPF experiment in MODE = '{MODE}' with config:\")\n",
    "    print(cfg)\n",
    "\n",
    "    input_steps   = cfg[\"input_steps\"]\n",
    "    horizon_steps = cfg[\"horizon_steps\"]\n",
    "    stride        = cfg[\"stride\"]\n",
    "    batch_size    = cfg[\"batch_size\"]\n",
    "    epochs_img    = cfg[\"epochs_img\"]\n",
    "    epochs_fus    = cfg[\"epochs_fus\"]\n",
    "\n",
    "    metrics_img = None\n",
    "    metrics_fus = None\n",
    "\n",
    "    if RUN_IMG_ONLY:\n",
    "        model_img, metrics_img, (t_img, p_img) = train_mcmipf_cnn_lstm(\n",
    "            input_steps=input_steps,\n",
    "            horizon_steps=horizon_steps,\n",
    "            lr=5e-4,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs_img,\n",
    "            stride=stride\n",
    "        )\n",
    "        print(\"MCMIPF CNN-LSTM metrics:\", metrics_img)\n",
    "        plot_sample_series(\n",
    "            t_img, p_img,\n",
    "            f\"MCMIPF CNN-LSTM — Test (sample) — MODE={MODE}\",\n",
    "            n=500,\n",
    "            fname=FIG_DIR / f\"mcmipf_cnn_lstm_only_series_{MODE}.png\"\n",
    "        )\n",
    "\n",
    "    if RUN_FUSION:\n",
    "        model_fus, metrics_fus, (t_fus, p_fus) = train_mcmipf_tabular_fusion(\n",
    "            input_steps=input_steps,\n",
    "            horizon_steps=horizon_steps,\n",
    "            lr=5e-4,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs_fus,\n",
    "            stride=stride\n",
    "        )\n",
    "        print(\"MCMIPF + Tabular fusion metrics:\", metrics_fus)\n",
    "        plot_sample_series(\n",
    "            t_fus, p_fus,\n",
    "            f\"MCMIPF + Tabular Fusion — Test (sample) — MODE={MODE}\",\n",
    "            n=500,\n",
    "            fname=FIG_DIR / f\"mcmipf_tabular_fusion_cnnlite_series_{MODE}.png\"\n",
    "        )\n",
    "\n",
    "    # Comparación rápida (si se entrenaron ambos)\n",
    "    rows = {}\n",
    "    if metrics_img is not None:\n",
    "        rows[\"MCMIPF_CNN_LSTM_only\"] = metrics_img\n",
    "    if metrics_fus is not None:\n",
    "        rows[\"MCMIPF_Tabular_Fusion_CNNLite\"] = metrics_fus\n",
    "\n",
    "    if rows:\n",
    "        res = pd.DataFrame(rows).T\n",
    "        print(\"\\nResumen métricas:\")\n",
    "        print(res.round(3).to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e_ladino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
