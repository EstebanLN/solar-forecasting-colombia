{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74d5237d",
   "metadata": {},
   "source": [
    "\n",
    "# 03 — Modeling Tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0b9ded",
   "metadata": {},
   "source": [
    "## Baselines + RNNs (LSTM, GRU, Dilated, Clockwork) con datos tabulados.\n",
    "\n",
    "**Optimización Bayesiana**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4be1918",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c04a835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, json, math, time, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6d05c9",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "801ea70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "929ee7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_CLEAN = Path(\"../data/clean/base_dataset.csv\")\n",
    "OUT_DIR = Path(\"../outputs\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ART_DIR = OUT_DIR / \"artifacts\"; ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR = OUT_DIR / \"figures\"; FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TARGET_COL = \"GHI\"\n",
    "FREQ = \"10T\"\n",
    "INPUT_STEPS   = 36   # 6h pasado\n",
    "HORIZON_STEPS = 6    # 1h adelante\n",
    "BATCH_SIZE    = 256\n",
    "EPOCHS        = 40\n",
    "PATIENCE      = 6 # Early stopping patience"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4a014b",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2b5b1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107172, 56) 2022-02-21 18:00:00+00:00 → 2024-03-06 23:50:00+00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "time",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "CSI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GHI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Presion",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TempAmb",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Wind Y",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Wind X",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DoY Sin",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DoY Cos",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "horas",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "__missing_target",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "flag_GHI_range",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "flag_TempAmb_range",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "flag_Presion_range",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "flag_CSI_range",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "hour",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dow",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "month",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "minute",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "is_weekend",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hour_sin",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hour_cos",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "WindSpeed",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "WindDirection",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GHI_roll1h_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GHI_roll3h_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GHI_roll6h_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GHI_roll1h_max",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TempAmb_roll1h_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TempAmb_roll3h_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TempAmb_roll6h_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TempAmb_roll1h_max",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Presion_roll1h_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Presion_roll3h_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Presion_roll6h_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Presion_roll1h_max",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "WindSpeed_roll1h_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "WindSpeed_roll3h_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "WindSpeed_roll6h_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "WindSpeed_roll1h_max",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GHI_lag1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GHI_lag3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GHI_lag6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GHI_lag12",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GHI_lag36",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "solar_zenith",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "solar_azimuth",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "solar_elevation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ETR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "clear_sky_ghi",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CSI_advanced",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ghi_1min_change",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ghi_5min_std",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ghi_persistence_1h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "temp_pressure_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wind_temp_interaction",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wind_cloud_effect",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "60974f23-d6ac-4ae9-bce5-36e0955f4374",
       "rows": [
        [
         "2022-02-21 18:00:00+00:00",
         "2.0",
         "3.0352",
         "1000.7912",
         "29.9672",
         "2.8329537511734304",
         "-0.0936124655822536",
         "0.7787639308347607",
         "0.6273170968742937",
         "18",
         "False",
         "False",
         "False",
         "False",
         "False",
         "13",
         "0",
         "2",
         "0",
         "0",
         "-0.2588190451025208",
         "-0.9659258262890684",
         "2.8345",
         "358.1074",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "23.644150793303567",
         "215.26801716298132",
         "66.35584920669643",
         "1397.3794352543612",
         "1280.0749623380234",
         "0.0023711111356206",
         null,
         null,
         null,
         "0.0299435086659999",
         "84.94202839999998",
         "0.0067209145139167"
        ],
        [
         "2022-02-21 18:10:00+00:00",
         "0.0",
         "0.3562",
         "1000.9321",
         "29.5689",
         "3.387551831665581",
         "0.7968014732536361",
         "0.7787639308347607",
         "0.6273170968742937",
         "18",
         "False",
         "False",
         "False",
         "False",
         "False",
         "13",
         "0",
         "2",
         "10",
         "0",
         "-0.2588190451025208",
         "-0.9659258262890684",
         "3.48",
         "13.236199999999997",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "3.0352",
         null,
         null,
         null,
         null,
         "25.150910668915078",
         "219.9770996021093",
         "64.84908933108493",
         "1397.3794352543612",
         "1264.8960086455206",
         "0.0002816041771685",
         "2.6790000000000003",
         null,
         null,
         "0.0295413644646411",
         "102.899772",
         "0.0009799825365465"
        ],
        [
         "2022-02-21 18:20:00+00:00",
         "0.0",
         "0.0",
         "1001.1479",
         "29.2593",
         "2.091197167038805",
         "-0.8786804302867318",
         "0.7787639308347607",
         "0.6273170968742937",
         "18",
         "False",
         "False",
         "False",
         "False",
         "False",
         "13",
         "0",
         "2",
         "20",
         "0",
         "-0.2588190451025208",
         "-0.9659258262890684",
         "2.2683",
         "337.2088",
         "1.1304666666666667",
         null,
         null,
         "3.0352",
         "29.598466666666667",
         null,
         null,
         "29.9672",
         "1000.9570666666668",
         null,
         null,
         "1001.1479",
         "2.860933333333333",
         null,
         null,
         "3.48",
         "0.3562",
         null,
         null,
         null,
         null,
         "26.8043303279754",
         "224.13655852327923",
         "63.1956696720246",
         "1397.3794352543612",
         "1247.233445347055",
         "0.0",
         "0.3562",
         null,
         null,
         "0.0292257517303629",
         "66.36887019",
         "0.0"
        ],
        [
         "2022-02-21 18:30:00+00:00",
         "0.0",
         "0.0",
         "1001.2992",
         "28.9183",
         "-0.4879573421959761",
         "-1.4785623531650731",
         "0.7787639308347607",
         "0.6273170968742937",
         "18",
         "False",
         "False",
         "False",
         "False",
         "False",
         "13",
         "0",
         "2",
         "30",
         "0",
         "-0.2588190451025208",
         "-0.9659258262890684",
         "1.5569999999999995",
         "251.736",
         "0.84785",
         null,
         null,
         "3.0352",
         "29.428425",
         null,
         null,
         "29.9672",
         "1001.0426",
         null,
         null,
         "1001.2992",
         "2.53495",
         null,
         null,
         "3.48",
         "0.0",
         "3.0352",
         null,
         null,
         null,
         "28.57896193662612",
         "227.80307793922333",
         "61.42103806337388",
         "1397.3794352543612",
         "1227.1208858794985",
         "0.0",
         "0.0",
         null,
         null,
         "0.0288807780642581",
         "45.02579309999999",
         "0.0"
        ],
        [
         "2022-02-21 18:40:00+00:00",
         "0.0",
         "0.0",
         "1001.4676",
         "28.5578",
         "0.8911714612141777",
         "-2.047462435972242",
         "0.7787639308347607",
         "0.6273170968742937",
         "18",
         "False",
         "False",
         "False",
         "False",
         "False",
         "13",
         "0",
         "2",
         "40",
         "0",
         "-0.2588190451025208",
         "-0.9659258262890684",
         "2.233",
         "293.5214",
         "0.67828",
         null,
         null,
         "3.0352",
         "29.2543",
         null,
         null,
         "29.9672",
         "1001.1276",
         null,
         null,
         "1001.4676",
         "2.47456",
         null,
         null,
         "3.48",
         "0.0",
         "0.3562",
         null,
         null,
         null,
         "30.45361759855332",
         "231.0364393760373",
         "59.54638240144668",
         "1397.3794352543612",
         "1204.5966097687358",
         "0.0",
         "0.0",
         "1.3265555668723417",
         null,
         "0.0285159499633178",
         "63.76956740000001",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 56,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CSI</th>\n",
       "      <th>GHI</th>\n",
       "      <th>Presion</th>\n",
       "      <th>TempAmb</th>\n",
       "      <th>Wind Y</th>\n",
       "      <th>Wind X</th>\n",
       "      <th>DoY Sin</th>\n",
       "      <th>DoY Cos</th>\n",
       "      <th>horas</th>\n",
       "      <th>__missing_target</th>\n",
       "      <th>...</th>\n",
       "      <th>solar_elevation</th>\n",
       "      <th>ETR</th>\n",
       "      <th>clear_sky_ghi</th>\n",
       "      <th>CSI_advanced</th>\n",
       "      <th>ghi_1min_change</th>\n",
       "      <th>ghi_5min_std</th>\n",
       "      <th>ghi_persistence_1h</th>\n",
       "      <th>temp_pressure_ratio</th>\n",
       "      <th>wind_temp_interaction</th>\n",
       "      <th>wind_cloud_effect</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-02-21 18:00:00+00:00</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0352</td>\n",
       "      <td>1000.7912</td>\n",
       "      <td>29.9672</td>\n",
       "      <td>2.832954</td>\n",
       "      <td>-0.093612</td>\n",
       "      <td>0.778764</td>\n",
       "      <td>0.627317</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>66.355849</td>\n",
       "      <td>1397.379435</td>\n",
       "      <td>1280.074962</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.029944</td>\n",
       "      <td>84.942028</td>\n",
       "      <td>0.006721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-21 18:10:00+00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3562</td>\n",
       "      <td>1000.9321</td>\n",
       "      <td>29.5689</td>\n",
       "      <td>3.387552</td>\n",
       "      <td>0.796801</td>\n",
       "      <td>0.778764</td>\n",
       "      <td>0.627317</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>64.849089</td>\n",
       "      <td>1397.379435</td>\n",
       "      <td>1264.896009</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>2.6790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.029541</td>\n",
       "      <td>102.899772</td>\n",
       "      <td>0.000980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-21 18:20:00+00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1001.1479</td>\n",
       "      <td>29.2593</td>\n",
       "      <td>2.091197</td>\n",
       "      <td>-0.878680</td>\n",
       "      <td>0.778764</td>\n",
       "      <td>0.627317</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>63.195670</td>\n",
       "      <td>1397.379435</td>\n",
       "      <td>1247.233445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.029226</td>\n",
       "      <td>66.368870</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-21 18:30:00+00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1001.2992</td>\n",
       "      <td>28.9183</td>\n",
       "      <td>-0.487957</td>\n",
       "      <td>-1.478562</td>\n",
       "      <td>0.778764</td>\n",
       "      <td>0.627317</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>61.421038</td>\n",
       "      <td>1397.379435</td>\n",
       "      <td>1227.120886</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028881</td>\n",
       "      <td>45.025793</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-21 18:40:00+00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1001.4676</td>\n",
       "      <td>28.5578</td>\n",
       "      <td>0.891171</td>\n",
       "      <td>-2.047462</td>\n",
       "      <td>0.778764</td>\n",
       "      <td>0.627317</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>59.546382</td>\n",
       "      <td>1397.379435</td>\n",
       "      <td>1204.596610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.326556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028516</td>\n",
       "      <td>63.769567</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           CSI     GHI    Presion  TempAmb    Wind Y  \\\n",
       "time                                                                   \n",
       "2022-02-21 18:00:00+00:00  2.0  3.0352  1000.7912  29.9672  2.832954   \n",
       "2022-02-21 18:10:00+00:00  0.0  0.3562  1000.9321  29.5689  3.387552   \n",
       "2022-02-21 18:20:00+00:00  0.0  0.0000  1001.1479  29.2593  2.091197   \n",
       "2022-02-21 18:30:00+00:00  0.0  0.0000  1001.2992  28.9183 -0.487957   \n",
       "2022-02-21 18:40:00+00:00  0.0  0.0000  1001.4676  28.5578  0.891171   \n",
       "\n",
       "                             Wind X   DoY Sin   DoY Cos  horas  \\\n",
       "time                                                             \n",
       "2022-02-21 18:00:00+00:00 -0.093612  0.778764  0.627317     18   \n",
       "2022-02-21 18:10:00+00:00  0.796801  0.778764  0.627317     18   \n",
       "2022-02-21 18:20:00+00:00 -0.878680  0.778764  0.627317     18   \n",
       "2022-02-21 18:30:00+00:00 -1.478562  0.778764  0.627317     18   \n",
       "2022-02-21 18:40:00+00:00 -2.047462  0.778764  0.627317     18   \n",
       "\n",
       "                           __missing_target  ...  solar_elevation  \\\n",
       "time                                         ...                    \n",
       "2022-02-21 18:00:00+00:00             False  ...        66.355849   \n",
       "2022-02-21 18:10:00+00:00             False  ...        64.849089   \n",
       "2022-02-21 18:20:00+00:00             False  ...        63.195670   \n",
       "2022-02-21 18:30:00+00:00             False  ...        61.421038   \n",
       "2022-02-21 18:40:00+00:00             False  ...        59.546382   \n",
       "\n",
       "                                   ETR  clear_sky_ghi  CSI_advanced  \\\n",
       "time                                                                  \n",
       "2022-02-21 18:00:00+00:00  1397.379435    1280.074962      0.002371   \n",
       "2022-02-21 18:10:00+00:00  1397.379435    1264.896009      0.000282   \n",
       "2022-02-21 18:20:00+00:00  1397.379435    1247.233445      0.000000   \n",
       "2022-02-21 18:30:00+00:00  1397.379435    1227.120886      0.000000   \n",
       "2022-02-21 18:40:00+00:00  1397.379435    1204.596610      0.000000   \n",
       "\n",
       "                           ghi_1min_change  ghi_5min_std  ghi_persistence_1h  \\\n",
       "time                                                                           \n",
       "2022-02-21 18:00:00+00:00              NaN           NaN                 NaN   \n",
       "2022-02-21 18:10:00+00:00           2.6790           NaN                 NaN   \n",
       "2022-02-21 18:20:00+00:00           0.3562           NaN                 NaN   \n",
       "2022-02-21 18:30:00+00:00           0.0000           NaN                 NaN   \n",
       "2022-02-21 18:40:00+00:00           0.0000      1.326556                 NaN   \n",
       "\n",
       "                           temp_pressure_ratio  wind_temp_interaction  \\\n",
       "time                                                                    \n",
       "2022-02-21 18:00:00+00:00             0.029944              84.942028   \n",
       "2022-02-21 18:10:00+00:00             0.029541             102.899772   \n",
       "2022-02-21 18:20:00+00:00             0.029226              66.368870   \n",
       "2022-02-21 18:30:00+00:00             0.028881              45.025793   \n",
       "2022-02-21 18:40:00+00:00             0.028516              63.769567   \n",
       "\n",
       "                           wind_cloud_effect  \n",
       "time                                          \n",
       "2022-02-21 18:00:00+00:00           0.006721  \n",
       "2022-02-21 18:10:00+00:00           0.000980  \n",
       "2022-02-21 18:20:00+00:00           0.000000  \n",
       "2022-02-21 18:30:00+00:00           0.000000  \n",
       "2022-02-21 18:40:00+00:00           0.000000  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_CLEAN, parse_dates=[0], index_col=0)\n",
    "df.index.name = \"time\"\n",
    "df = df.sort_index()\n",
    "\n",
    "print(df.shape, df.index.min(), \"→\", df.index.max())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ca1579f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CSI', 'GHI', 'Presion', 'TempAmb', 'Wind Y', 'Wind X', 'DoY Sin',\n",
       "       'DoY Cos', 'horas', '__missing_target', 'flag_GHI_range',\n",
       "       'flag_TempAmb_range', 'flag_Presion_range', 'flag_CSI_range', 'hour',\n",
       "       'dow', 'month', 'minute', 'is_weekend', 'hour_sin', 'hour_cos',\n",
       "       'WindSpeed', 'WindDirection', 'GHI_roll1h_mean', 'GHI_roll3h_mean',\n",
       "       'GHI_roll6h_mean', 'GHI_roll1h_max', 'TempAmb_roll1h_mean',\n",
       "       'TempAmb_roll3h_mean', 'TempAmb_roll6h_mean', 'TempAmb_roll1h_max',\n",
       "       'Presion_roll1h_mean', 'Presion_roll3h_mean', 'Presion_roll6h_mean',\n",
       "       'Presion_roll1h_max', 'WindSpeed_roll1h_mean', 'WindSpeed_roll3h_mean',\n",
       "       'WindSpeed_roll6h_mean', 'WindSpeed_roll1h_max', 'GHI_lag1', 'GHI_lag3',\n",
       "       'GHI_lag6', 'GHI_lag12', 'GHI_lag36', 'solar_zenith', 'solar_azimuth',\n",
       "       'solar_elevation', 'ETR', 'clear_sky_ghi', 'CSI_advanced',\n",
       "       'ghi_1min_change', 'ghi_5min_std', 'ghi_persistence_1h',\n",
       "       'temp_pressure_ratio', 'wind_temp_interaction', 'wind_cloud_effect'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8f2f2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [\n",
    "    'Presion', 'TempAmb', 'WindSpeed', 'WindDirection',\n",
    "    'hour_sin', 'hour_cos', 'DoY Sin', 'DoY Cos', 'is_weekend',\n",
    "    'solar_zenith', 'solar_azimuth', 'solar_elevation',\n",
    "    'TempAmb_roll1h_mean','TempAmb_roll6h_mean',\n",
    "    'Presion_roll1h_mean','Presion_roll6h_mean',\n",
    "    'WindSpeed_roll1h_mean','WindSpeed_roll6h_mean',\n",
    "    'ghi_5min_std','wind_temp_interaction'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9dc3a6",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d50df66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.impute import SimpleImputer\n",
    "\n",
    "# # Configuración de imputers\n",
    "# X_imputer = SimpleImputer(strategy='mean')\n",
    "# y_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# # Imputar valores NaN\n",
    "# X_train_imp = X_imputer.fit_transform(X_train)\n",
    "# y_train_imp = y_imputer.fit_transform(y_train.reshape(-1, 1)).ravel()\n",
    "# X_val_imp = X_imputer.transform(X_val)\n",
    "# X_test_imp = X_imputer.transform(X_test)\n",
    "\n",
    "# # Verificar que no hay NaN\n",
    "# print(\"NaN después de imputación:\")\n",
    "# print(\"X_train:\", np.isnan(X_train_imp).sum())\n",
    "# print(\"y_train:\", np.isnan(y_train_imp).sum())\n",
    "# print(\"X_val:\", np.isnan(X_val_imp).sum())\n",
    "# print(\"X_test:\", np.isnan(X_test_imp).sum())\n",
    "\n",
    "# # Usar datos imputados en lugar de los originales\n",
    "# X_train_clean, y_train_clean = X_train_imp, y_train_imp\n",
    "# X_val_clean, X_test_clean = X_val_imp, X_test_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "641bef31",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df)\n",
    "i_tr = int(0.7*n); i_va = int(0.85*n)\n",
    "df_train, df_val, df_test = df.iloc[:i_tr], df.iloc[i_tr:i_va], df.iloc[i_va:]\n",
    "\n",
    "X_scaler, y_scaler = StandardScaler(), StandardScaler()\n",
    "X_train = X_scaler.fit_transform(df_train[feat_cols].values)\n",
    "y_train = y_scaler.fit_transform(df_train[[TARGET_COL]].values).ravel()\n",
    "X_val   = X_scaler.transform(df_val[feat_cols].values)\n",
    "y_val   = y_scaler.transform(df_val[[TARGET_COL]].values).ravel()\n",
    "X_test  = X_scaler.transform(df_test[feat_cols].values)\n",
    "y_test  = y_scaler.transform(df_test[[TARGET_COL]].values).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aafb2d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores NaN en X_train: 61\n",
      "Valores NaN en y_train: 0\n",
      "Valores NaN en X_val: 0\n",
      "Valores NaN en X_test: 0\n",
      "Eliminadas 17 filas con NaN de entrenamiento\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores NaN antes del split\n",
    "print(\"Valores NaN en X_train:\", np.isnan(X_train).sum())\n",
    "print(\"Valores NaN en y_train:\", np.isnan(y_train).sum())\n",
    "print(\"Valores NaN en X_val:\", np.isnan(X_val).sum())\n",
    "print(\"Valores NaN en X_test:\", np.isnan(X_test).sum())\n",
    "\n",
    "nan_mask = np.isnan(X_train).any(axis=1) | np.isnan(y_train)\n",
    "X_train_clean = X_train[~nan_mask]\n",
    "y_train_clean = y_train[~nan_mask]\n",
    "\n",
    "print(f\"Eliminadas {nan_mask.sum()} filas con NaN de entrenamiento\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3ca3e7",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "956f0efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear: {'MAE': 128.58392354897063, 'RMSE': 168.46142137925324, 'MAPE': np.float64(2041760184.8979485)} \n",
      "RF baseline: {'MAE': 37.016858900378246, 'RMSE': 79.77865583750265, 'MAPE': np.float64(110234072.6442202)}\n"
     ]
    }
   ],
   "source": [
    "def metrics_from_scaled(pred_scaled, true_scaled, y_scaler):\n",
    "    \"\"\"Calculate metrics from scaled predictions and true values\"\"\"\n",
    "    p = y_scaler.inverse_transform(pred_scaled.reshape(-1, 1)).ravel()\n",
    "    t = y_scaler.inverse_transform(true_scaled.reshape(-1, 1)).ravel()\n",
    "    mae = mean_absolute_error(t, p)\n",
    "    rmse = math.sqrt(mean_squared_error(t, p))\n",
    "    mape = np.mean(np.abs((t + 1e-6) - p) / (np.abs(t) + 1e-6)) * 100\n",
    "    return {\"MAE\": mae, \"RMSE\": rmse, \"MAPE\": mape}, (t, p)\n",
    "\n",
    "# Linear\n",
    "lin = LinearRegression().fit(X_train_clean, y_train_clean)\n",
    "lin_metrics, (y_true_lin, y_pred_lin) = metrics_from_scaled(lin.predict(X_test), y_test, y_scaler)\n",
    "\n",
    "# RF (baseline fijo)\n",
    "rf0 = RandomForestRegressor(n_estimators=300, random_state=SEED, n_jobs=-1).fit(X_train_clean, y_train_clean)\n",
    "rf0_metrics, (y_true_rf0, y_pred_rf0) = metrics_from_scaled(rf0.predict(X_test), y_test, y_scaler)\n",
    "print(\"Linear:\", lin_metrics, \"\\nRF baseline:\", rf0_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95e8457",
   "metadata": {},
   "source": [
    "## Sequentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65de131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, X, y, input_steps=36, horizon=6):\n",
    "        self.X, self.y = X, y\n",
    "        self.input_steps, self.horizon = input_steps, horizon\n",
    "        self.max_i = len(X) - input_steps - horizon\n",
    "        assert self.max_i > 0, \"No hay suficientes muestras.\"\n",
    "    def __len__(self): return self.max_i\n",
    "    def __getitem__(self, idx):\n",
    "        i0, i1 = idx, idx + self.input_steps\n",
    "        ih = i1 + self.horizon - 1\n",
    "        return (torch.tensor(self.X[i0:i1], dtype=torch.float32),\n",
    "                torch.tensor(self.y[ih], dtype=torch.float32))\n",
    "\n",
    "def make_loaders(X_tr, y_tr, X_va, y_va, X_te, y_te, steps, horizon, batch=256):\n",
    "    ds_tr = SeqDataset(X_tr, y_tr, steps, horizon)\n",
    "    ds_va = SeqDataset(X_va, y_va, steps, horizon)\n",
    "    ds_te = SeqDataset(X_te, y_te, steps, horizon)\n",
    "    return (DataLoader(ds_tr, batch_size=batch, shuffle=True, drop_last=True),\n",
    "            DataLoader(ds_va, batch_size=batch, shuffle=False, drop_last=False),\n",
    "            DataLoader(ds_te, batch_size=batch, shuffle=False, drop_last=False))\n",
    "\n",
    "dl_train, dl_val, dl_test = make_loaders(X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "                                         INPUT_STEPS, HORIZON_STEPS, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6e703e",
   "metadata": {},
   "source": [
    "### PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "084eff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, in_dim, hidden=64, num_layers=1, dropout=0.0, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(in_dim, hidden, num_layers=num_layers, batch_first=True,\n",
    "                           dropout=(dropout if num_layers>1 else 0.0), bidirectional=bidirectional)\n",
    "        out_dim = hidden * (2 if bidirectional else 1)\n",
    "        self.fc = nn.Linear(out_dim, 1)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        return self.fc(out[:, -1, :]).squeeze(1)\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, in_dim, hidden=64, num_layers=1, dropout=0.0, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.GRU(in_dim, hidden, num_layers=num_layers, batch_first=True,\n",
    "                          dropout=(dropout if num_layers>1 else 0.0), bidirectional=bidirectional)\n",
    "        out_dim = hidden * (2 if bidirectional else 1)\n",
    "        self.fc = nn.Linear(out_dim, 1)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        return self.fc(out[:, -1, :]).squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8506b8b",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0251fb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_torch_model(model, dl_train, dl_val, epochs=40, lr=1e-3, patience=6, device=DEVICE, trial=None):\n",
    "    model = model.to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    best_val, best_state, no_improve = float(\"inf\"), None, 0\n",
    "    history = {\"train\": [], \"val\": []}\n",
    "    \n",
    "    for ep in range(1, epochs+1):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for xb, yb in dl_train:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            opt.zero_grad()\n",
    "            pred = model(xb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            train_losses.append(loss.item())\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in dl_val:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                pred = model(xb)\n",
    "                val_losses.append(loss_fn(pred, yb).item())\n",
    "        \n",
    "        train_mse = np.mean(train_losses)\n",
    "        val_mse = np.mean(val_losses)\n",
    "        history[\"train\"].append(train_mse)\n",
    "        history[\"val\"].append(val_mse)\n",
    "\n",
    "        if trial is not None:\n",
    "            trial.report(val_mse, ep)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "\n",
    "        if val_mse < best_val - 1e-6:\n",
    "            best_val, best_state, no_improve = val_mse, model.state_dict(), 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    return model, best_val, history\n",
    "\n",
    "def eval_sequence_model(model, dl, y_scaler, device=DEVICE):\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in dl:\n",
    "            xb = xb.to(device)\n",
    "            preds.append(model(xb).cpu().numpy())\n",
    "            trues.append(yb.cpu().numpy())\n",
    "    p = np.concatenate(preds); t = np.concatenate(trues)\n",
    "    p_o = y_scaler.inverse_transform(p.reshape(-1,1)).ravel()\n",
    "    t_o = y_scaler.inverse_transform(t.reshape(-1,1)).ravel()\n",
    "    mae  = mean_absolute_error(t_o, p_o)\n",
    "    rmse = math.sqrt(mean_squared_error(t_o, p_o))\n",
    "    mape = np.mean(np.abs((t_o + 1e-6) - p_o) / (np.abs(t_o) + 1e-6)) * 100\n",
    "    return {\"MAE\":mae, \"RMSE\":rmse, \"MAPE\":mape}, (t_o, p_o)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04811ade",
   "metadata": {},
   "source": [
    "## Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb2b541",
   "metadata": {},
   "source": [
    "#### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82f38df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-09-19 09:11:01,556] Trial 1 failed with parameters: {'n_estimators': 697, 'max_depth': 24, 'min_samples_split': 16, 'min_samples_leaf': 6} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Esteban\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Esteban\\AppData\\Local\\Temp\\ipykernel_26372\\2799514303.py\", line 9, in objective_rf\n",
      "    rf.fit(X_train, y_train)\n",
      "  File \"c:\\Users\\Esteban\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Esteban\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 486, in fit\n",
      "    trees = Parallel(\n",
      "            ^^^^^^^^^\n",
      "  File \"c:\\Users\\Esteban\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 82, in __call__\n",
      "    return super().__call__(iterable_with_config_and_warning_filters)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Esteban\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 2072, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Esteban\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1682, in _get_outputs\n",
      "    yield from self._retrieve()\n",
      "  File \"c:\\Users\\Esteban\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1800, in _retrieve\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n",
      "[W 2025-09-19 09:11:01,764] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m math.sqrt(mean_squared_error(t_o, p_o))\n\u001b[32m     15\u001b[39m study_rf = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m\"\u001b[39m, study_name=\u001b[33m\"\u001b[39m\u001b[33mRF_RMSE\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mstudy_rf\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_rf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m best_rf = RandomForestRegressor(random_state=SEED, n_jobs=-\u001b[32m1\u001b[39m, **study_rf.best_trial.params)\n\u001b[32m     19\u001b[39m best_rf.fit(np.vstack([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Esteban\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Esteban\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Esteban\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Esteban\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:258\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    251\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    254\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    255\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    256\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    257\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Esteban\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mobjective_rf\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mobjective_rf\u001b[39m(trial: optuna.Trial):\n\u001b[32m      2\u001b[39m     rf = RandomForestRegressor(\n\u001b[32m      3\u001b[39m         n_estimators      = trial.suggest_int(\u001b[33m\"\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m200\u001b[39m, \u001b[32m700\u001b[39m),\n\u001b[32m      4\u001b[39m         max_depth         = trial.suggest_int(\u001b[33m\"\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m6\u001b[39m, \u001b[32m28\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m      7\u001b[39m         n_jobs=-\u001b[32m1\u001b[39m, random_state=SEED\n\u001b[32m      8\u001b[39m     )\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[43mrf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     pred_val = rf.predict(X_val)\n\u001b[32m     11\u001b[39m     p_o = y_scaler.inverse_transform(pred_val.reshape(-\u001b[32m1\u001b[39m,\u001b[32m1\u001b[39m)).ravel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Esteban\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Esteban\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:486\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    475\u001b[39m trees = [\n\u001b[32m    476\u001b[39m     \u001b[38;5;28mself\u001b[39m._make_estimator(append=\u001b[38;5;28;01mFalse\u001b[39;00m, random_state=random_state)\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[32m    478\u001b[39m ]\n\u001b[32m    480\u001b[39m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m trees = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[32m    508\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_.extend(trees)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Esteban\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Esteban\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Esteban\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Esteban\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def objective_rf(trial: optuna.Trial):\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators      = trial.suggest_int(\"n_estimators\", 200, 700),\n",
    "        max_depth         = trial.suggest_int(\"max_depth\", 6, 28),\n",
    "        min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "        min_samples_leaf  = trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "        n_jobs=-1, random_state=SEED\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "    pred_val = rf.predict(X_val)\n",
    "    p_o = y_scaler.inverse_transform(pred_val.reshape(-1,1)).ravel()\n",
    "    t_o = y_scaler.inverse_transform(y_val.reshape(-1,1)).ravel()\n",
    "    return math.sqrt(mean_squared_error(t_o, p_o))\n",
    "\n",
    "study_rf = optuna.create_study(direction=\"minimize\", study_name=\"RF_RMSE\")\n",
    "study_rf.optimize(objective_rf, n_trials=30)\n",
    "\n",
    "best_rf = RandomForestRegressor(random_state=SEED, n_jobs=-1, **study_rf.best_trial.params)\n",
    "best_rf.fit(np.vstack([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "rf_pred = best_rf.predict(X_test)\n",
    "rf_metrics, (y_true_rf, y_pred_rf) = metrics_from_scaled(rf_pred, y_test, y_scaler)\n",
    "print(\"RF (Optuna):\", rf_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabc4cec",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff53f869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loaders_from_arrays(X_tr, y_tr, X_va, y_va, steps, horizon, batch=256):\n",
    "    \"\"\"Create train and validation loaders from arrays\"\"\"\n",
    "    ds_tr = SeqDataset(X_tr, y_tr, steps, horizon)\n",
    "    ds_va = SeqDataset(X_va, y_va, steps, horizon)\n",
    "    return (DataLoader(ds_tr, batch_size=batch, shuffle=True, drop_last=True),\n",
    "            DataLoader(ds_va, batch_size=batch, shuffle=False, drop_last=False))\n",
    "\n",
    "def objective_rnn(model_kind=\"LSTM\"):\n",
    "    def _obj(trial: optuna.Trial):\n",
    "        hidden = trial.suggest_int(\"hidden\", 32, 160, step=32)\n",
    "        layers = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "        dropout = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "        bidir   = trial.suggest_categorical(\"bidirectional\", [False, True])\n",
    "        lr      = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "        steps   = trial.suggest_categorical(\"input_steps\", [24, 36, 48])\n",
    "        horizon = trial.suggest_categorical(\"horizon_steps\", [3, 6, 12])\n",
    "        batch   = trial.suggest_categorical(\"batch\", [128, 256, 512])\n",
    "\n",
    "        dl_tr, dl_va = make_loaders_from_arrays(X_train, y_train, X_val, y_val, steps, horizon, batch=batch)\n",
    "\n",
    "        in_dim = X_train.shape[1]\n",
    "        if model_kind == \"LSTM\":\n",
    "            model = LSTMModel(in_dim, hidden=hidden, num_layers=layers, dropout=dropout, bidirectional=bidir)\n",
    "        else:\n",
    "            model = GRUModel(in_dim, hidden=hidden, num_layers=layers, dropout=dropout, bidirectional=bidir)\n",
    "\n",
    "        _, best_val, _ = train_torch_model(model, dl_tr, dl_va,\n",
    "                                          epochs=EPOCHS, lr=lr, patience=PATIENCE,\n",
    "                                          device=DEVICE, trial=trial)\n",
    "        return best_val\n",
    "    return _obj\n",
    "\n",
    "study_lstm = optuna.create_study(direction=\"minimize\", study_name=\"LSTM_MSEval\")\n",
    "study_lstm.optimize(objective_rnn(\"LSTM\"), n_trials=30)\n",
    "\n",
    "study_gru = optuna.create_study(direction=\"minimize\", study_name=\"GRU_MSEval\")\n",
    "study_gru.optimize(objective_rnn(\"GRU\"), n_trials=30)\n",
    "\n",
    "print(\"Best LSTM:\", study_lstm.best_trial.params)\n",
    "print(\"Best GRU :\", study_gru.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0747fc",
   "metadata": {},
   "source": [
    "## Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14cab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_best(model_kind, params, in_dim):\n",
    "    \"\"\"Build the best model from optimized parameters\"\"\"\n",
    "    model_cls = LSTMModel if model_kind == \"LSTM\" else GRUModel\n",
    "    return model_cls(in_dim,\n",
    "                     hidden=params[\"hidden\"],\n",
    "                     num_layers=params[\"num_layers\"],\n",
    "                     dropout=params[\"dropout\"],\n",
    "                     bidirectional=params[\"bidirectional\"])\n",
    "\n",
    "def retrain_and_test(model_kind, best_params):\n",
    "    steps, horizon, batch, lr = best_params[\"input_steps\"], best_params[\"horizon_steps\"], best_params[\"batch\"], best_params[\"lr\"]\n",
    "    X_trv = np.vstack([X_train, X_val]); y_trv = np.concatenate([y_train, y_val])\n",
    "    dl_tr, dl_va, dl_te = make_loaders(X_trv, y_trv, X_val, y_val, X_test, y_test, steps, horizon, batch)\n",
    "    model = build_best(model_kind, best_params, in_dim=X_train.shape[1])\n",
    "    model, best_val, history = train_torch_model(model, dl_tr, dl_va, epochs=EPOCHS, lr=lr, patience=PATIENCE, device=DEVICE)\n",
    "    \n",
    "    # Save best model\n",
    "    torch.save(model.state_dict(), ART_DIR / f\"best_{model_kind.lower()}_model.pt\")\n",
    "    \n",
    "    return eval_sequence_model(model, dl_te, y_scaler), history\n",
    "\n",
    "lstm_metrics, (yt_lstm, yp_lstm) = retrain_and_test(\"LSTM\", study_lstm.best_trial.params)[0]\n",
    "gru_metrics,  (yt_gru,  yp_gru)  = retrain_and_test(\"GRU\",  study_gru.best_trial.params)[0]\n",
    "\n",
    "print(\"LSTM (Optuna):\", lstm_metrics)\n",
    "print(\"GRU  (Optuna):\", gru_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed1b960",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850bd218",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"LinearRegression\": lin_metrics,\n",
    "    \"RandomForest_baseline\": rf0_metrics,\n",
    "    \"RandomForest_Optuna\": rf_metrics,\n",
    "    \"LSTM_Optuna\": lstm_metrics,\n",
    "    \"GRU_Optuna\":  gru_metrics\n",
    "}\n",
    "res_df = pd.DataFrame(results).T.sort_values(\"RMSE\")\n",
    "display(res_df.round(3))\n",
    "\n",
    "# with open(ART_DIR/\"tabular_results_optuna.json\",\"w\") as f:\n",
    "#     json.dump({k:{m:float(vv) for m,vv in v.items()} for k,v in results.items()}, f, indent=2)\n",
    "# print(\"Saved:\", ART_DIR/\"tabular_results_optuna.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6a8805",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5c4dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot optimization history\n",
    "fig = optuna.visualization.plot_optimization_history(study_lstm)\n",
    "fig.show()\n",
    "\n",
    "# Plot parameter importances\n",
    "fig = optuna.visualization.plot_param_importances(study_lstm)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
