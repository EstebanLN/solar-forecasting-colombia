{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74d5237d",
   "metadata": {},
   "source": [
    "\n",
    "# 03 — Modeling Tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0b9ded",
   "metadata": {},
   "source": [
    "## Baselines + RNNs (LSTM, GRU, Dilated, Clockwork) con datos tabulados.\n",
    "\n",
    "**Optimización Bayesiana**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4be1918",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04a835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, json, math, time, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6d05c9",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801ea70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929ee7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_CLEAN = Path(\"../data/clean/base_dataset.csv\")\n",
    "OUT_DIR = Path(\"../outputs\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ART_DIR = OUT_DIR / \"artifacts\"; ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR = OUT_DIR / \"figures\"; FIG_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ca66d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COL = \"GHI\"\n",
    "FREQ = \"10T\"\n",
    "INPUT_STEPS   = 36   # 6h past\n",
    "HORIZON_STEPS = 6    # 1h ahead\n",
    "BATCH_SIZE    = 256\n",
    "EPOCHS        = 40\n",
    "PATIENCE      = 6    # Early stopping patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea0ad20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna runs\n",
    "\n",
    "OPTUNA_STORAGE = \"sqlite:///../outputs/artifacts/optuna_tabular.db\"\n",
    "\n",
    "N_TRIALS_RF   = 30\n",
    "N_TRIALS_LSTM = 30\n",
    "N_TRIALS_GRU  = 30\n",
    "N_TRIALS_DIL  = 30\n",
    "N_TRIALS_CW   = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bd8661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruner (cut bad trials short)\n",
    "PRUNER = optuna.pruners.MedianPruner(n_warmup_steps=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4a014b",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b5b1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_CLEAN, parse_dates=[0], index_col=0).sort_index()\n",
    "df.index.name = \"time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ca1579f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CSI', 'GHI', 'Presion', 'TempAmb', 'Wind Y', 'Wind X', 'DoY Sin',\n",
       "       'DoY Cos', 'horas', '__missing_target', 'flag_GHI_range',\n",
       "       'flag_TempAmb_range', 'flag_Presion_range', 'flag_CSI_range', 'hour',\n",
       "       'dow', 'month', 'minute', 'is_weekend', 'hour_sin', 'hour_cos',\n",
       "       'WindSpeed', 'WindDirection', 'GHI_roll1h_mean', 'GHI_roll3h_mean',\n",
       "       'GHI_roll6h_mean', 'GHI_roll1h_max', 'TempAmb_roll1h_mean',\n",
       "       'TempAmb_roll3h_mean', 'TempAmb_roll6h_mean', 'TempAmb_roll1h_max',\n",
       "       'Presion_roll1h_mean', 'Presion_roll3h_mean', 'Presion_roll6h_mean',\n",
       "       'Presion_roll1h_max', 'WindSpeed_roll1h_mean', 'WindSpeed_roll3h_mean',\n",
       "       'WindSpeed_roll6h_mean', 'WindSpeed_roll1h_max', 'GHI_lag1', 'GHI_lag3',\n",
       "       'GHI_lag6', 'GHI_lag12', 'GHI_lag36', 'solar_zenith', 'solar_azimuth',\n",
       "       'solar_elevation', 'ETR', 'clear_sky_ghi', 'CSI_advanced',\n",
       "       'ghi_1min_change', 'ghi_5min_std', 'ghi_persistence_1h',\n",
       "       'temp_pressure_ratio', 'wind_temp_interaction', 'wind_cloud_effect'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f2f2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_feats = [\n",
    "    'Presion','TempAmb','WindSpeed','WindDirection',\n",
    "    'hour_sin','hour_cos','DoY Sin','DoY Cos',\n",
    "    'solar_zenith','solar_azimuth','solar_elevation',\n",
    "    'TempAmb_roll1h_mean','TempAmb_roll6h_mean',\n",
    "    'Presion_roll1h_mean','Presion_roll6h_mean',\n",
    "    'WindSpeed_roll1h_mean','WindSpeed_roll6h_mean',\n",
    "    'temp_pressure_ratio','wind_temp_interaction'\n",
    "]\n",
    "\n",
    "ghi_lags = [c for c in ['GHI_lag1','GHI_lag3','GHI_lag6','GHI_lag12','GHI_lag36'] if c in df.columns]\n",
    "ghi_rolls = [c for c in ['GHI_roll1h_mean','GHI_roll3h_mean','GHI_roll6h_mean','GHI_roll1h_max'] if c in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68406b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [c for c in base_feats if c in df.columns] + ghi_lags + ghi_rolls\n",
    "print(f\"Total features used: {len(feat_cols)}\")\n",
    "print(feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9dc3a6",
   "metadata": {},
   "source": [
    "## Split\n",
    "\n",
    "Temporal split  70/15/15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641bef31",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df); i_tr = int(0.7*n); i_va = int(0.85*n)\n",
    "df_train, df_val, df_test = df.iloc[:i_tr], df.iloc[i_tr:i_va], df.iloc[i_va:]\n",
    "\n",
    "X_scaler = StandardScaler(); y_scaler = StandardScaler()\n",
    "\n",
    "X_train = X_scaler.fit_transform(df_train[feat_cols].values)\n",
    "y_train = y_scaler.fit_transform(df_train[[TARGET_COL]].values).ravel()\n",
    "X_val   = X_scaler.transform(df_val[feat_cols].values)\n",
    "y_val   = y_scaler.transform(df_val[[TARGET_COL]].values).ravel()\n",
    "X_test  = X_scaler.transform(df_test[feat_cols].values)\n",
    "y_test  = y_scaler.transform(df_test[[TARGET_COL]].values).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafb2d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores NaN en X_train: 57\n",
      "Valores NaN en y_train: 0\n",
      "Valores NaN en X_val: 0\n",
      "Valores NaN en X_test: 0\n"
     ]
    }
   ],
   "source": [
    "# NaN before split\n",
    "print(\"Valores NaN en X_train:\", np.isnan(X_train).sum())\n",
    "print(\"Valores NaN en y_train:\", np.isnan(y_train).sum())\n",
    "print(\"Valores NaN en X_val:\", np.isnan(X_val).sum())\n",
    "print(\"Valores NaN en X_test:\", np.isnan(X_test).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eebde43",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(strategy=\"median\")\n",
    "X_train = imp.fit_transform(X_train)\n",
    "X_val   = imp.transform(X_val)\n",
    "X_test  = imp.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f977df16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, arr in [(\"X_train\",X_train),(\"X_val\",X_val),(\"X_test\",X_test),(\"y_train\",y_train),(\"y_val\",y_val),(\"y_test\",y_test)]:\n",
    "    assert np.isfinite(arr).all(), f\"{name} tiene NaN/Inf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9c37dc",
   "metadata": {},
   "source": [
    "## Helpers - Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee598c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_from_scaled(pred_scaled, true_scaled, y_scaler):\n",
    "    p = y_scaler.inverse_transform(pred_scaled.reshape(-1,1)).ravel()\n",
    "    t = y_scaler.inverse_transform(true_scaled.reshape(-1,1)).ravel()\n",
    "    mae = mean_absolute_error(t, p)\n",
    "    rmse = math.sqrt(mean_squared_error(t, p))\n",
    "    mape = np.mean(np.abs((t + 1e-6) - p) / (np.abs(t) + 1e-6)) * 100\n",
    "    return {\"MAE\": mae, \"RMSE\": rmse, \"MAPE\": mape}, (t, p)\n",
    "\n",
    "def persistence_baseline(y_scaled, horizon):\n",
    "    # ŷ(t+h) = y(t) en espacio ESCALADO \n",
    "    y_hat = np.roll(y_scaled, horizon)\n",
    "    y_hat[:horizon] = y_scaled[horizon]  # simple fill\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3ca3e7",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956f0efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear: {'MAE': 133.67257677220636, 'RMSE': 180.89666474680828, 'MAPE': np.float64(2010103435.0315397)}\n",
      "RF baseline: {'MAE': 53.15648075886887, 'RMSE': 98.82656751538924, 'MAPE': np.float64(504496106.27778584)}\n"
     ]
    }
   ],
   "source": [
    "lin = LinearRegression().fit(X_train, y_train)\n",
    "lin_metrics, (y_true_lin, y_pred_lin) = metrics_from_scaled(lin.predict(X_test), y_test, y_scaler)\n",
    "\n",
    "rf0 = RandomForestRegressor(n_estimators=300, random_state=SEED, n_jobs=-1).fit(X_train, y_train)\n",
    "rf0_metrics, (y_true_rf0, y_pred_rf0) = metrics_from_scaled(rf0.predict(X_test), y_test, y_scaler)\n",
    "\n",
    "y_pers_test = persistence_baseline(y_test, HORIZON_STEPS)\n",
    "pers_metrics, (y_true_pers, y_pred_pers) = metrics_from_scaled(y_pers_test, y_test, y_scaler)\n",
    "\n",
    "print(\"Persistence:\", pers_metrics)\n",
    "print(\"Linear     :\", lin_metrics)\n",
    "print(\"RF baseline:\", rf0_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95e8457",
   "metadata": {},
   "source": [
    "## Sequentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2112369b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loaders_from_arrays(X_tr, y_tr, X_va, y_va, steps, horizon, batch=256):\n",
    "    ds_tr = SeqDataset(X_tr, y_tr, steps, horizon)\n",
    "    ds_va = SeqDataset(X_va, y_va, steps, horizon)\n",
    "    return (DataLoader(ds_tr, batch_size=batch, shuffle=True, drop_last=True),\n",
    "            DataLoader(ds_va, batch_size=batch, shuffle=False, drop_last=False))\n",
    "\n",
    "def make_loaders(X_tr, y_tr, X_va, y_va, X_te, y_te, steps, horizon, batch=256):\n",
    "    ds_tr = SeqDataset(X_tr, y_tr, steps, horizon)\n",
    "    ds_va = SeqDataset(X_va, y_va, steps, horizon)\n",
    "    ds_te = SeqDataset(X_te, y_te, steps, horizon)\n",
    "    return (DataLoader(ds_tr, batch_size=batch, shuffle=True, drop_last=True),\n",
    "            DataLoader(ds_va, batch_size=batch, shuffle=False, drop_last=False),\n",
    "            DataLoader(ds_te, batch_size=batch, shuffle=False, drop_last=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65de131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, X, y, input_steps=36, horizon=6):\n",
    "        self.X, self.y = X, y\n",
    "        self.input_steps, self.horizon = input_steps, horizon\n",
    "        self.max_i = len(X) - input_steps - horizon\n",
    "        assert self.max_i > 0, \"No hay suficientes muestras para ventanas.\"\n",
    "    def __len__(self): return self.max_i\n",
    "    def __getitem__(self, idx):\n",
    "        i0, i1 = idx, idx + self.input_steps\n",
    "        ih = i1 + self.horizon - 1\n",
    "        return (torch.tensor(self.X[i0:i1], dtype=torch.float32),\n",
    "                torch.tensor(self.y[ih], dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6e703e",
   "metadata": {},
   "source": [
    "### PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4116f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, in_dim, hidden=64, num_layers=1, dropout=0.0, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(in_dim, hidden, num_layers=num_layers, batch_first=True,\n",
    "                           dropout=(dropout if num_layers>1 else 0.0), bidirectional=bidirectional)\n",
    "        out_dim = hidden * (2 if bidirectional else 1)\n",
    "        self.fc = nn.Linear(out_dim, 1)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        return self.fc(out[:, -1, :]).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a8be29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, in_dim, hidden=64, num_layers=1, dropout=0.0, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.GRU(in_dim, hidden, num_layers=num_layers, batch_first=True,\n",
    "                          dropout=(dropout if num_layers>1 else 0.0), bidirectional=bidirectional)\n",
    "        out_dim = hidden * (2 if bidirectional else 1)\n",
    "        self.fc = nn.Linear(out_dim, 1)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        return self.fc(out[:, -1, :]).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afae3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DilatedRNNCell(nn.Module):\n",
    "    def __init__(self, in_dim, hidden):\n",
    "        super().__init__()\n",
    "        self.Wx = nn.Linear(in_dim, hidden)\n",
    "        self.Wh = nn.Linear(hidden, hidden)\n",
    "        self.act = nn.Tanh()\n",
    "    def forward(self, x_t, h):\n",
    "        return self.act(self.Wx(x_t) + self.Wh(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac5a568",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DilatedRNN(nn.Module):\n",
    "    def __init__(self, in_dim, hidden=64, dilation=2, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.cell = DilatedRNNCell(in_dim, hidden)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden, 1)\n",
    "        self.d = max(1, int(dilation))\n",
    "        self.hidden_size = hidden\n",
    "    def forward(self, x):\n",
    "        B, T, F = x.size()\n",
    "        h = torch.zeros(B, self.hidden_size, device=x.device)\n",
    "        for t in range(0, T, self.d):\n",
    "            h = self.cell(x[:, t, :], h)\n",
    "            h = self.dropout(h)\n",
    "        return self.fc(h).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495d593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClockworkRNN(nn.Module):\n",
    "    def __init__(self, in_dim, hidden=60, modules=3, base_period=1, dropout=0.0):\n",
    "        super().__init__()\n",
    "        assert hidden % modules == 0, \"hidden debe ser múltiplo de modules\"\n",
    "        self.modules = modules\n",
    "        self.h_per = hidden // modules\n",
    "        self.periods = [base_period * (2**m) for m in range(modules)]\n",
    "        self.Wx = nn.ModuleList([nn.Linear(in_dim, self.h_per) for _ in range(modules)])\n",
    "        self.Wh = nn.ModuleList([nn.Linear(self.h_per, self.h_per) for _ in range(modules)])\n",
    "        self.act = nn.Tanh()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc  = nn.Linear(hidden, 1)\n",
    "    def forward(self, x):\n",
    "        B, T, F = x.size()\n",
    "        hs = [torch.zeros(B, self.h_per, device=x.device) for _ in range(self.modules)]\n",
    "        for t in range(T):\n",
    "            for m in range(self.modules):\n",
    "                if t % self.periods[m] == 0:\n",
    "                    hs[m] = self.act(self.Wx[m](x[:, t, :]) + self.Wh[m](hs[m]))\n",
    "                    hs[m] = self.dropout(hs[m])\n",
    "        h_all = torch.cat(hs, dim=1)\n",
    "        return self.fc(h_all).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084eff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LSTMModel(nn.Module):\n",
    "#     def __init__(self, in_dim, hidden=64, num_layers=1, dropout=0.0, bidirectional=False):\n",
    "#         super().__init__()\n",
    "#         self.rnn = nn.LSTM(in_dim, hidden, num_layers=num_layers, batch_first=True,\n",
    "#                            dropout=(dropout if num_layers>1 else 0.0), bidirectional=bidirectional)\n",
    "#         out_dim = hidden * (2 if bidirectional else 1)\n",
    "#         self.fc = nn.Linear(out_dim, 1)\n",
    "#     def forward(self, x):\n",
    "#         out, _ = self.rnn(x)\n",
    "#         return self.fc(out[:, -1, :]).squeeze(1)\n",
    "\n",
    "# class GRUModel(nn.Module):\n",
    "#     def __init__(self, in_dim, hidden=64, num_layers=1, dropout=0.0, bidirectional=False):\n",
    "#         super().__init__()\n",
    "#         self.rnn = nn.GRU(in_dim, hidden, num_layers=num_layers, batch_first=True,\n",
    "#                           dropout=(dropout if num_layers>1 else 0.0), bidirectional=bidirectional)\n",
    "#         out_dim = hidden * (2 if bidirectional else 1)\n",
    "#         self.fc = nn.Linear(out_dim, 1)\n",
    "#     def forward(self, x):\n",
    "#         out, _ = self.rnn(x)\n",
    "#         return self.fc(out[:, -1, :]).squeeze(1)\n",
    "\n",
    "# # Dilated RNN sencilla: procesa cada d-ésimo paso\n",
    "# class DilatedRNNCell(nn.Module):\n",
    "#     def __init__(self, in_dim, hidden):\n",
    "#         super().__init__()\n",
    "#         self.Wx = nn.Linear(in_dim, hidden)\n",
    "#         self.Wh = nn.Linear(hidden, hidden)\n",
    "#         self.act = nn.Tanh()\n",
    "#     def forward(self, x_t, h):\n",
    "#         return self.act(self.Wx(x_t) + self.Wh(h))\n",
    "\n",
    "# class DilatedRNN(nn.Module):\n",
    "#     def __init__(self, in_dim, hidden=64, dilation=2, dropout=0.0):\n",
    "#         super().__init__()\n",
    "#         self.cell = DilatedRNNCell(in_dim, hidden)\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "#         self.fc = nn.Linear(hidden, 1)\n",
    "#         self.d = max(1, int(dilation))\n",
    "#         self.hidden_size = hidden\n",
    "#     def forward(self, x):\n",
    "#         B, T, F = x.size()\n",
    "#         h = torch.zeros(B, self.hidden_size, device=x.device)\n",
    "#         for t in range(0, T, self.d):\n",
    "#             h = self.cell(x[:, t, :], h)\n",
    "#             h = self.dropout(h)\n",
    "#         return self.fc(h).squeeze(1)\n",
    "# class ClockworkRNN(nn.Module):\n",
    "#     def __init__(self, in_dim, hidden=60, modules=3, base_period=1, dropout=0.0):\n",
    "#         super().__init__()\n",
    "#         assert hidden % modules == 0, \"hidden debe ser múltiplo de modules\"\n",
    "#         self.modules = modules\n",
    "#         self.h_per = hidden // modules\n",
    "#         # periodos tipo 1, 2, 4... * base_period\n",
    "#         self.periods = [base_period * (2**m) for m in range(modules)]\n",
    "#         self.Wx = nn.ModuleList([nn.Linear(in_dim, self.h_per) for _ in range(modules)])\n",
    "#         self.Wh = nn.ModuleList([nn.Linear(self.h_per, self.h_per) for _ in range(modules)])\n",
    "#         self.act = nn.Tanh()\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "#         self.fc  = nn.Linear(hidden, 1)\n",
    "#     def forward(self, x):\n",
    "#         B, T, F = x.size()\n",
    "#         hs = [torch.zeros(B, self.h_per, device=x.device) for _ in range(self.modules)]\n",
    "#         for t in range(T):\n",
    "#             for m in range(self.modules):\n",
    "#                 if t % self.periods[m] == 0:\n",
    "#                     hs[m] = self.act(self.Wx[m](x[:, t, :]) + self.Wh[m](hs[m]))\n",
    "#                     hs[m] = self.dropout(hs[m])\n",
    "#         h_all = torch.cat(hs, dim=1)\n",
    "#         return self.fc(h_all).squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8506b8b",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0251fb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_torch_model(model, dl_train, dl_val, epochs=40, lr=1e-3, patience=6, device=DEVICE, trial=None, weight_decay=0.0):\n",
    "    model = model.to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"min\", factor=0.5, patience=2, verbose=False)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    best_val, best_state, no_improve = float(\"inf\"), None, 0\n",
    "\n",
    "    for ep in range(1, epochs+1):\n",
    "        model.train(); tr_losses=[]\n",
    "        for xb, yb in dl_train:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            opt.zero_grad(); pred = model(xb)\n",
    "            loss = loss_fn(pred, yb); loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            opt.step()\n",
    "            tr_losses.append(loss.item())\n",
    "\n",
    "        model.eval(); va_losses=[]\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in dl_val:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                va_losses.append(loss_fn(model(xb), yb).item())\n",
    "        val_mse = float(np.mean(va_losses))\n",
    "        sched.step(val_mse)\n",
    "\n",
    "        if trial is not None:\n",
    "            trial.report(val_mse, ep)\n",
    "            if trial.should_prune(): raise optuna.TrialPruned()\n",
    "\n",
    "        if val_mse < best_val - 1e-6:\n",
    "            best_val, best_state, no_improve = val_mse, model.state_dict(), 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience: break\n",
    "\n",
    "    if best_state is not None: model.load_state_dict(best_state)\n",
    "    return model, best_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5eb616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_sequence_model(model, dl, y_scaler, device=DEVICE):\n",
    "    model.eval(); preds, trues = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in dl:\n",
    "            xb = xb.to(device)\n",
    "            preds.append(model(xb).cpu().numpy())\n",
    "            trues.append(yb.cpu().numpy())\n",
    "    p = np.concatenate(preds); t = np.concatenate(trues)\n",
    "    p_o = y_scaler.inverse_transform(p.reshape(-1,1)).ravel()\n",
    "    t_o = y_scaler.inverse_transform(t.reshape(-1,1)).ravel()\n",
    "    mae  = mean_absolute_error(t_o, p_o)\n",
    "    rmse = math.sqrt(mean_squared_error(t_o, p_o))\n",
    "    mape = np.mean(np.abs((t_o + 1e-6) - p_o) / (np.abs(t_o) + 1e-6)) * 100\n",
    "    return {\"MAE\":mae, \"RMSE\":rmse, \"MAPE\":mape}, (t_o, p_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04811ade",
   "metadata": {},
   "source": [
    "## Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ff2898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_study(name):\n",
    "    return optuna.create_study(direction=\"minimize\", study_name=name, pruner=PRUNER, storage=OPTUNA_STORAGE, load_if_exists=bool(OPTUNA_STORAGE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb2b541",
   "metadata": {},
   "source": [
    "#### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f38df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_rf(trial):\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators      = trial.suggest_int(\"n_estimators\", 200, 700),\n",
    "        max_depth         = trial.suggest_int(\"max_depth\", 6, 28),\n",
    "        min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "        min_samples_leaf  = trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "        n_jobs=-1, random_state=SEED\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "    pred_val = rf.predict(X_val)\n",
    "    p_o = y_scaler.inverse_transform(pred_val.reshape(-1,1)).ravel()\n",
    "    t_o = y_scaler.inverse_transform(y_val.reshape(-1,1)).ravel()\n",
    "    return math.sqrt(mean_squared_error(t_o, p_o))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabc4cec",
   "metadata": {},
   "source": [
    "#### RNN\n",
    "(causals: bidirectional=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff53f869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_rnn_builder(model_kind=\"LSTM\"):\n",
    "    def _obj(trial):\n",
    "        hidden  = trial.suggest_int(\"hidden\", 64, 256, step=32)\n",
    "        layers  = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "        dropout = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "        bidir   = False  # causal para operación real\n",
    "        lr      = trial.suggest_float(\"lr\", 3e-4, 3e-3, log=True)\n",
    "        steps   = trial.suggest_categorical(\"input_steps\", [24, 36, 48, 60])\n",
    "        horizon = trial.suggest_categorical(\"horizon_steps\", [3, 6, 12])\n",
    "        batch   = trial.suggest_categorical(\"batch\", [128, 256, 512])\n",
    "        wd      = trial.suggest_float(\"weight_decay\", 0.0, 5e-4)  # regularización ligera\n",
    "\n",
    "        dl_tr, dl_va = make_loaders_from_arrays(X_train, y_train, X_val, y_val, steps, horizon, batch=batch)\n",
    "        in_dim = X_train.shape[1]\n",
    "        model = LSTMModel(in_dim, hidden, layers, dropout, bidir) if model_kind==\"LSTM\" else GRUModel(in_dim, hidden, layers, dropout, bidir)\n",
    "\n",
    "        _, best_val = train_torch_model(model, dl_tr, dl_va, epochs=EPOCHS, lr=lr, patience=PATIENCE, device=DEVICE, trial=trial, weight_decay=wd)\n",
    "        return best_val\n",
    "    return _obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a4ab0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_dilated(trial: optuna.Trial):\n",
    "    hidden  = trial.suggest_int(\"hidden\", 32, 192, step=32)\n",
    "    dilation= trial.suggest_categorical(\"dilation\", [1, 2, 3, 4, 6])\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "    lr      = trial.suggest_float(\"lr\", 3e-4, 3e-3, log=True)\n",
    "    steps   = trial.suggest_categorical(\"input_steps\", [24, 36, 48, 60])\n",
    "    horizon = trial.suggest_categorical(\"horizon_steps\", [3, 6, 12])\n",
    "    batch   = trial.suggest_categorical(\"batch\", [128, 256, 512])\n",
    "    wd      = trial.suggest_float(\"weight_decay\", 0.0, 5e-4)\n",
    "\n",
    "    dl_tr, dl_va = make_loaders_from_arrays(X_train, y_train, X_val, y_val, steps, horizon, batch=batch)\n",
    "    model = DilatedRNN(X_train.shape[1], hidden=hidden, dilation=dilation, dropout=dropout)\n",
    "    _, best_val = train_torch_model(model, dl_tr, dl_va, epochs=EPOCHS, lr=lr, patience=PATIENCE, device=DEVICE, trial=trial, weight_decay=wd)\n",
    "    return best_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8011e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_clockwork(trial: optuna.Trial):\n",
    "    hidden  = trial.suggest_int(\"hidden\", 60, 180, step=30)\n",
    "    modules = trial.suggest_categorical(\"modules\", [3, 4, 5])\n",
    "    if hidden % modules != 0: raise optuna.TrialPruned()\n",
    "    base_period = trial.suggest_categorical(\"base_period\", [1, 2])\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "    lr      = trial.suggest_float(\"lr\", 3e-4, 3e-3, log=True)\n",
    "    steps   = trial.suggest_categorical(\"input_steps\", [24, 36, 48, 60])\n",
    "    horizon = trial.suggest_categorical(\"horizon_steps\", [3, 6, 12])\n",
    "    batch   = trial.suggest_categorical(\"batch\", [128, 256, 512])\n",
    "    wd      = trial.suggest_float(\"weight_decay\", 0.0, 5e-4)\n",
    "\n",
    "    dl_tr, dl_va = make_loaders_from_arrays(X_train, y_train, X_val, y_val, steps, horizon, batch=batch)\n",
    "    model = ClockworkRNN(X_train.shape[1], hidden=hidden, modules=modules, base_period=base_period, dropout=dropout)\n",
    "    _, best_val = train_torch_model(model, dl_tr, dl_va, epochs=EPOCHS, lr=lr, patience=PATIENCE, device=DEVICE, trial=trial, weight_decay=wd)\n",
    "    return best_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df937830",
   "metadata": {},
   "source": [
    "### Run Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b59152a",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_rf   = _create_study(\"RF_RMSE\");      study_rf.optimize(objective_rf,                n_trials=N_TRIALS_RF)\n",
    "study_lstm = _create_study(\"LSTM_MSEval\");  study_lstm.optimize(objective_rnn_builder(\"LSTM\"), n_trials=N_TRIALS_LSTM)\n",
    "study_gru  = _create_study(\"GRU_MSEval\");   study_gru.optimize(objective_rnn_builder(\"GRU\"),  n_trials=N_TRIALS_GRU)\n",
    "study_dil  = _create_study(\"DilatedRNN_MSEval\"); study_dil.optimize(objective_dilated,     n_trials=N_TRIALS_DIL)\n",
    "study_cw   = _create_study(\"ClockworkRNN_MSEval\"); study_cw.optimize(objective_clockwork,  n_trials=N_TRIALS_CW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0747fc",
   "metadata": {},
   "source": [
    "## Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14cab37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LSTM      : {'hidden': 128, 'num_layers': 3, 'dropout': 0.01767602417948283, 'bidirectional': False, 'lr': 0.0015974153776496232, 'input_steps': 36, 'horizon_steps': 3, 'batch': 128}\n",
      "Best GRU       : {'hidden': 64, 'num_layers': 3, 'dropout': 0.1717267069132688, 'bidirectional': True, 'lr': 0.0015539401909891695, 'input_steps': 36, 'horizon_steps': 3, 'batch': 128}\n",
      "Best Dilated   : {'hidden': 64, 'dilation': 1, 'dropout': 0.28304300372038427, 'lr': 0.0005606575429489244, 'input_steps': 36, 'horizon_steps': 3, 'batch': 128}\n",
      "Best Clockwork : {'hidden': 90, 'modules': 5, 'base_period': 2, 'dropout': 0.05935084995017281, 'lr': 0.0014238921494951263, 'input_steps': 24, 'horizon_steps': 3, 'batch': 128}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best LSTM      :\", study_lstm.best_trial.params)\n",
    "print(\"Best GRU       :\", study_gru.best_trial.params)\n",
    "print(\"Best Dilated   :\", study_dil.best_trial.params)\n",
    "print(\"Best Clockwork :\", study_cw.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837d9ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = RandomForestRegressor(random_state=SEED, n_jobs=-1, **study_rf.best_trial.params)\n",
    "best_rf.fit(np.vstack([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "rf_opt_metrics, (y_true_rf_opt, y_pred_rf_opt) = metrics_from_scaled(best_rf.predict(X_test), y_test, y_scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed1b960",
   "metadata": {},
   "source": [
    "## Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850bd218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain_and_test_build(build_fn, best_params, label):\n",
    "    steps, horizon = best_params[\"input_steps\"], best_params[\"horizon_steps\"]\n",
    "    batch = best_params[\"batch\"]; lr = best_params[\"lr\"]\n",
    "    wd    = best_params.get(\"weight_decay\", 0.0)\n",
    "    dl_tr, dl_va, dl_te = make_loaders(\n",
    "        np.vstack([X_train, X_val]), np.concatenate([y_train, y_val]),\n",
    "        X_val, y_val, X_test, y_test, steps, horizon, batch\n",
    "    )\n",
    "    model = build_fn(best_params)\n",
    "    model, best_val = train_torch_model(model, dl_tr, dl_va, epochs=EPOCHS, lr=lr, patience=PATIENCE, device=DEVICE, weight_decay=wd)\n",
    "    torch.save(model.state_dict(), ART_DIR / f\"best_{label}.pt\")\n",
    "    return eval_sequence_model(model, dl_te, y_scaler)\n",
    "\n",
    "in_dim = X_train.shape[1]\n",
    "build_lstm = lambda p: LSTMModel(in_dim, p[\"hidden\"], p[\"num_layers\"], p[\"dropout\"], False)\n",
    "build_gru  = lambda p: GRUModel(in_dim,  p[\"hidden\"], p[\"num_layers\"], p[\"dropout\"], False)\n",
    "build_dil  = lambda p: DilatedRNN(in_dim, p[\"hidden\"], p[\"dilation\"], p[\"dropout\"])\n",
    "build_cw   = lambda p: ClockworkRNN(in_dim, p[\"hidden\"], p[\"modules\"], p[\"base_period\"], p[\"dropout\"])\n",
    "\n",
    "lstm_metrics, (yt_lstm, yp_lstm) = retrain_and_test_build(build_lstm, study_lstm.best_trial.params, \"lstm\")\n",
    "gru_metrics,  (yt_gru,  yp_gru)  = retrain_and_test_build(build_gru,  study_gru.best_trial.params,  \"gru\")\n",
    "dil_metrics,  (yt_dil,  yp_dil)  = retrain_and_test_build(build_dil,  study_dil.best_trial.params,  \"dilated\")\n",
    "cw_metrics,   (yt_cw,   yp_cw)   = retrain_and_test_build(build_cw,   study_cw.best_trial.params,   \"clockwork\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6a8805",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5c4dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAPE",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "a95cca3a-6baf-4c27-a5dc-63e970d5660a",
       "rows": [
        [
         "RandomForest_Optuna",
         "51.439",
         "93.832",
         "510536489.121"
        ],
        [
         "RandomForest_baseline",
         "53.156",
         "98.827",
         "504496106.278"
        ],
        [
         "ClockworkRNN_Optuna",
         "68.803",
         "105.409",
         "189301856.0"
        ],
        [
         "DilatedRNN_Optuna",
         "71.063",
         "106.877",
         "191465600.0"
        ],
        [
         "GRU_Optuna",
         "62.026",
         "112.381",
         "37252140.0"
        ],
        [
         "LSTM_Optuna",
         "77.717",
         "143.675",
         "179506960.0"
        ],
        [
         "LinearRegression",
         "133.673",
         "180.897",
         "2010103435.032"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 7
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForest_Optuna</th>\n",
       "      <td>51.439</td>\n",
       "      <td>93.832</td>\n",
       "      <td>5.105365e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest_baseline</th>\n",
       "      <td>53.156</td>\n",
       "      <td>98.827</td>\n",
       "      <td>5.044961e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ClockworkRNN_Optuna</th>\n",
       "      <td>68.803</td>\n",
       "      <td>105.409</td>\n",
       "      <td>1.893019e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DilatedRNN_Optuna</th>\n",
       "      <td>71.063</td>\n",
       "      <td>106.877</td>\n",
       "      <td>1.914656e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRU_Optuna</th>\n",
       "      <td>62.026</td>\n",
       "      <td>112.381</td>\n",
       "      <td>3.725214e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM_Optuna</th>\n",
       "      <td>77.717</td>\n",
       "      <td>143.675</td>\n",
       "      <td>1.795070e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>133.673</td>\n",
       "      <td>180.897</td>\n",
       "      <td>2.010103e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MAE     RMSE          MAPE\n",
       "RandomForest_Optuna     51.439   93.832  5.105365e+08\n",
       "RandomForest_baseline   53.156   98.827  5.044961e+08\n",
       "ClockworkRNN_Optuna     68.803  105.409  1.893019e+08\n",
       "DilatedRNN_Optuna       71.063  106.877  1.914656e+08\n",
       "GRU_Optuna              62.026  112.381  3.725214e+07\n",
       "LSTM_Optuna             77.717  143.675  1.795070e+08\n",
       "LinearRegression       133.673  180.897  2.010103e+09"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = {\n",
    "    \"Persistence\": pers_metrics,\n",
    "    \"LinearRegression\": lin_metrics,\n",
    "    \"RandomForest_baseline\": rf0_metrics,\n",
    "    \"RandomForest_Optuna\": rf_opt_metrics,\n",
    "    \"LSTM_Optuna\": lstm_metrics,\n",
    "    \"GRU_Optuna\":  gru_metrics,\n",
    "    \"DilatedRNN_Optuna\": dil_metrics,\n",
    "    \"ClockworkRNN_Optuna\": cw_metrics,\n",
    "}\n",
    "res_df = pd.DataFrame(results).T.sort_values(\"RMSE\")\n",
    "display(res_df.round(3))\n",
    "\n",
    "with open(ART_DIR/\"tabular_results_optuna.json\",\"w\") as f:\n",
    "    json.dump({k:{m:float(vv) for m,vv in v.items()} for k,v in results.items()}, f, indent=2)\n",
    "print(\"Saved:\", ART_DIR/\"tabular_results_optuna.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cf640a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ..\\outputs\\artifacts\\tabular_results_optuna.json\n"
     ]
    }
   ],
   "source": [
    "with open(ART_DIR/\"tabular_results_optuna.json\",\"w\") as f:\n",
    "    json.dump({k:{m:float(vv) for m,vv in v.items()} for k,v in results.items()}, f, indent=2)\n",
    "print(\"Saved:\", ART_DIR/\"tabular_results_optuna.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b03326",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc4bd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(y_true, y_pred, title, n=1000):\n",
    "    n = min(n, len(y_true))\n",
    "    plt.figure(figsize=(11,3.8))\n",
    "    plt.plot(y_true[:n], label=\"Real\", lw=1.5)\n",
    "    plt.plot(y_pred[:n], label=\"Pred\", lw=1.2, alpha=0.9)\n",
    "    plt.title(title); plt.xlabel(\"Time steps (10-min)\"); plt.ylabel(\"GHI (W/m²)\")\n",
    "    plt.legend(frameon=False); plt.tight_layout()\n",
    "\n",
    "plot_sample(y_true_rf_opt, y_pred_rf_opt, \"RandomForest Optuna — Test (sample)\")\n",
    "plt.savefig(FIG_DIR / \"pred_rf_opt_sample.png\"); plt.show()\n",
    "\n",
    "for name, (yt, yp) in {\n",
    "    \"LSTM\": (yt_lstm, yp_lstm),\n",
    "    \"GRU\":  (yt_gru,  yp_gru),\n",
    "    \"Dilated\": (yt_dil, yp_dil),\n",
    "    \"Clockwork\": (yt_cw, yp_cw),\n",
    "}.items():\n",
    "    plot_sample(yt, yp, f\"{name} — Test (sample)\")\n",
    "    plt.savefig(FIG_DIR / f\"pred_{name.lower()}_sample.png\"); plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
