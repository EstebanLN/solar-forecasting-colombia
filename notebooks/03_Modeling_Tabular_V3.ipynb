{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5b8071f",
   "metadata": {},
   "source": [
    "# 03 — Modeling Tabular (Keras/TF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bdbfaa",
   "metadata": {},
   "source": [
    "## Baselines + RNNs (LSTM, GRU, Dilated, Clockwork).\n",
    "\n",
    "**Optuna (JournalStorage + lock)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cec559",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ed0089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, json, math, time, random, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, regularizers, backend as K\n",
    "\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from optuna.storages import JournalStorage, JournalFileStorage\n",
    "from optuna.storages.journal._file import JournalFileOpenLock\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1b4b34",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f18028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for g in gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(g, True)\n",
    "    except Exception:\n",
    "        pass\n",
    "print(\"TF GPUs:\", gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0119b19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_CLEAN = Path(\"../data/clean/base_dataset.csv\")\n",
    "OUT_DIR = Path(\"../outputs\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ART_DIR = OUT_DIR / \"artifacts_keras\"; ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR = OUT_DIR / \"figures\"; FIG_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d616b8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COL = \"GHI\"\n",
    "FREQ = \"10T\"\n",
    "DEFAULT_INPUT_STEPS   = 36   # 6h pasado\n",
    "DEFAULT_HORIZON_STEPS = 6    # 1h adelante\n",
    "\n",
    "PATIENCE = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbf025c",
   "metadata": {},
   "source": [
    "### Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3661cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = \"AIA\"  # \"LAPTOP\" o \"AIA\"\n",
    "\n",
    "if MODE == \"LAPTOP\":\n",
    "    N_TRIALS_RF   = 30\n",
    "    N_TRIALS_LSTM = 40\n",
    "    N_TRIALS_GRU  = 40\n",
    "    N_TRIALS_DIL  = 35\n",
    "    N_TRIALS_CW   = 35\n",
    "    MAX_EPOCHS    = 60\n",
    "elif MODE == \"AIA\":\n",
    "    N_TRIALS_RF   = 120\n",
    "    N_TRIALS_LSTM = 120\n",
    "    N_TRIALS_GRU  = 120\n",
    "    N_TRIALS_DIL  = 120\n",
    "    N_TRIALS_CW   = 120\n",
    "    MAX_EPOCHS    = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2389671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRUNER = MedianPruner(n_warmup_steps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f51e548",
   "metadata": {},
   "source": [
    "### Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbab10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "JOURNAL_PATH = (OUT_DIR / \"optuna_tabular_keras.journal\").resolve()\n",
    "LOCK = JournalFileOpenLock(str(JOURNAL_PATH) + \".lock\")\n",
    "STORAGE = JournalStorage(JournalFileStorage(str(JOURNAL_PATH), lock_obj=LOCK))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce3d4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_journal_storage(study_name: str) -> JournalStorage:\n",
    "    log_path = (OUT_DIR / f\"{study_name}.log\").resolve()\n",
    "    lock     = JournalFileOpenLock(str(log_path) + \".lock\")\n",
    "    return JournalStorage(JournalFileStorage(str(log_path), lock_obj=lock))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c348c1",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6103b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_CLEAN, parse_dates=[0], index_col=0).sort_index()\n",
    "df.index.name = \"time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da43e291",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_feats = [\n",
    "    'Presion','TempAmb','WindSpeed','WindDirection',\n",
    "    'hour_sin','hour_cos','DoY Sin','DoY Cos',\n",
    "    'solar_zenith','solar_azimuth','solar_elevation',\n",
    "    'TempAmb_roll1h_mean','TempAmb_roll6h_mean',\n",
    "    'Presion_roll1h_mean','Presion_roll6h_mean',\n",
    "    'WindSpeed_roll1h_mean','WindSpeed_roll6h_mean',\n",
    "    'temp_pressure_ratio','wind_temp_interaction'\n",
    "]\n",
    "ghi_lags  = [c for c in ['GHI_lag1','GHI_lag3','GHI_lag6','GHI_lag12','GHI_lag36'] if c in df.columns]\n",
    "ghi_rolls = [c for c in ['GHI_roll1h_mean','GHI_roll3h_mean','GHI_roll6h_mean','GHI_roll1h_max'] if c in df.columns]\n",
    "feat_cols = [c for c in base_feats if c in df.columns] + ghi_lags + ghi_rolls\n",
    "print(f\"Total features used: {len(feat_cols)}\")\n",
    "print(feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34245985",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert TARGET_COL in df.columns, f\"TARGET_COL='{TARGET_COL}' no existe en el dataset\"\n",
    "n = len(df); i_tr = int(0.7*n); i_va = int(0.85*n)\n",
    "df_train, df_val, df_test = df.iloc[:i_tr], df.iloc[i_tr:i_va], df.iloc[i_va:]\n",
    "\n",
    "X_scaler = StandardScaler(); y_scaler = StandardScaler()\n",
    "X_train = X_scaler.fit_transform(df_train[feat_cols].values)\n",
    "X_val   = X_scaler.transform(df_val[feat_cols].values)\n",
    "X_test  = X_scaler.transform(df_test[feat_cols].values)\n",
    "\n",
    "y_train = y_scaler.fit_transform(df_train[[TARGET_COL]].values).ravel()\n",
    "y_val   = y_scaler.transform(df_val[[TARGET_COL]].values).ravel()\n",
    "y_test  = y_scaler.transform(df_test[[TARGET_COL]].values).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3984f4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NaNs antes de imputar:\",\n",
    "      np.isnan(X_train).sum(), np.isnan(X_val).sum(), np.isnan(X_test).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ec342f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(strategy=\"median\")\n",
    "X_train = imp.fit_transform(X_train)\n",
    "X_val   = imp.transform(X_val)\n",
    "X_test  = imp.transform(X_test)\n",
    "\n",
    "for name, arr in [(\"X_train\",X_train),(\"X_val\",X_val),(\"X_test\",X_test),\n",
    "                  (\"y_train\",y_train),(\"y_val\",y_val),(\"y_test\",y_test)]:\n",
    "    assert np.isfinite(arr).all(), f\"{name} tiene NaN/Inf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f32955",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb67ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_from_scaled(pred_scaled, true_scaled, y_scaler):\n",
    "    p = y_scaler.inverse_transform(pred_scaled.reshape(-1,1)).ravel()\n",
    "    t = y_scaler.inverse_transform(true_scaled.reshape(-1,1)).ravel()\n",
    "    mae = mean_absolute_error(t, p)\n",
    "    rmse = float(np.sqrt(mean_squared_error(t, p)))\n",
    "    mape = float(np.mean(np.abs((t + 1e-6) - p) / (np.abs(t) + 1e-6)) * 100)\n",
    "    smape = float(100 * np.mean(2*np.abs(p - t) / (np.abs(t) + np.abs(p) + 1e-6)))\n",
    "    r2 = float(r2_score(t, p))\n",
    "    return {\"MAE\": mae, \"RMSE\": rmse, \"MAPE\": mape, \"sMAPE\": smape, \"R2\": r2}, (t, p)\n",
    "\n",
    "def persistence_baseline(y_scaled, horizon):\n",
    "    y_hat = np.roll(y_scaled, horizon)\n",
    "    y_hat[:horizon] = y_scaled[horizon]  \n",
    "    return y_hat\n",
    "\n",
    "def _rmse(a,b): return float(np.sqrt(mean_squared_error(a,b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf439492",
   "metadata": {},
   "source": [
    "### sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ceb042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_seq_arrays(X_2d, y_1d, L, horizon):\n",
    "    \"\"\"\n",
    "    X_2d: (N, F), y_1d: (N,), L: window len (input_steps), horizon: steps ahead\n",
    "    Devuelve X_seq (N', L, F), y_seq (N',)\n",
    "    \"\"\"\n",
    "    N, F = X_2d.shape\n",
    "    outX, outy = [], []\n",
    "    last = N - L - horizon + 1\n",
    "    if last <= 0:\n",
    "        return np.zeros((0, L, F), dtype=\"float32\"), np.zeros((0,), dtype=\"float32\")\n",
    "    for i in range(last):\n",
    "        block = X_2d[i:i+L]\n",
    "        if np.isnan(block).any():\n",
    "            continue\n",
    "        outX.append(block)\n",
    "        outy.append(y_1d[i + L + horizon - 1])\n",
    "    return np.asarray(outX, dtype=\"float32\"), np.asarray(outy, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ccd7bd",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7088d2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = LinearRegression().fit(X_train, y_train)\n",
    "lin_metrics, (y_true_lin, y_pred_lin) = metrics_from_scaled(lin.predict(X_test), y_test, y_scaler)\n",
    "\n",
    "rf0 = RandomForestRegressor(n_estimators=300, random_state=SEED, n_jobs=-1).fit(X_train, y_train)\n",
    "rf0_metrics, (y_true_rf0, y_pred_rf0) = metrics_from_scaled(rf0.predict(X_test), y_test, y_scaler)\n",
    "\n",
    "y_pers_test = persistence_baseline(y_test, DEFAULT_HORIZON_STEPS)\n",
    "pers_metrics, (y_true_pers, y_pred_pers) = metrics_from_scaled(y_pers_test, y_test, y_scaler)\n",
    "\n",
    "print(\"Persistence:\", pers_metrics)\n",
    "print(\"Linear     :\", lin_metrics)\n",
    "print(\"RF baseline:\", rf0_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8605d6e4",
   "metadata": {},
   "source": [
    "## Models - Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62c8328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(L, n_feat, units=64, layers_n=1, dropout=0.0, bidir=False):\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    x = inp\n",
    "    for i in range(layers_n-1):\n",
    "        cell = layers.LSTM(units, return_sequences=True, dropout=dropout)\n",
    "        if bidir: cell = layers.Bidirectional(cell)\n",
    "        x = cell(x)\n",
    "    # capa final\n",
    "    cell = layers.LSTM(units, dropout=dropout)\n",
    "    if bidir: cell = layers.Bidirectional(cell)\n",
    "    x = cell(x)\n",
    "    out = layers.Dense(1, dtype=\"float32\")(x)\n",
    "    return models.Model(inp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c54e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gru(L, n_feat, units=64, layers_n=1, dropout=0.0, bidir=False):\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    x = inp\n",
    "    for i in range(layers_n-1):\n",
    "        cell = layers.GRU(units, return_sequences=True, dropout=dropout)\n",
    "        if bidir: cell = layers.Bidirectional(cell)\n",
    "        x = cell(x)\n",
    "    cell = layers.GRU(units, dropout=dropout)\n",
    "    if bidir: cell = layers.Bidirectional(cell)\n",
    "    x = cell(x)\n",
    "    out = layers.Dense(1, dtype=\"float32\")(x)\n",
    "    return models.Model(inp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a52e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dilated_like(L, n_feat, units=64, dilation=2, dropout=0.0):\n",
    "    assert dilation >= 1\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    # Submuestreo por \"dilation\"\n",
    "    x = layers.Lambda(lambda t: t[:, ::dilation, :])(inp)\n",
    "    x = layers.LSTM(units, dropout=dropout)(x)\n",
    "    out = layers.Dense(1, dtype=\"float32\")(x)\n",
    "    return models.Model(inp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542a5d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_clockwork(L, n_feat, hidden=60, modules=3, base_period=1, dropout=0.0):\n",
    "    assert hidden % modules == 0\n",
    "    h_per = hidden // modules\n",
    "    periods = [base_period * (2**m) for m in range(modules)]\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    h_list = []\n",
    "    for p in periods:\n",
    "        # Submuestrea según periodo p (t%p==0) ~ aproximación\n",
    "        xt = layers.Lambda(lambda t, step=p: t[:, ::step, :])(inp)\n",
    "        ht = layers.SimpleRNN(h_per, activation=\"tanh\", dropout=dropout)(xt)\n",
    "        h_list.append(ht)\n",
    "    h = layers.Concatenate()(h_list) if len(h_list) > 1 else h_list[0]\n",
    "    out = layers.Dense(1, dtype=\"float32\")(h)\n",
    "    return models.Model(inp, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919fb592",
   "metadata": {},
   "source": [
    "## Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7908b525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_seq_data_for_trial(steps, horizon):\n",
    "    Xtr_seq, ytr_seq = build_seq_arrays(X_train, y_train, steps, horizon)\n",
    "    Xva_seq, yva_seq = build_seq_arrays(X_val,   y_val,   steps, horizon)\n",
    "    if min(len(Xtr_seq), len(Xva_seq)) == 0:\n",
    "        raise optuna.TrialPruned()\n",
    "    return Xtr_seq, ytr_seq, Xva_seq, yva_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba5c37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_rf(trial: optuna.Trial) -> float:\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=trial.suggest_int(\"n_estimators\", 200, 800, step=100),\n",
    "        max_depth=trial.suggest_int(\"max_depth\", 6, 28),\n",
    "        min_samples_split=trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "        min_samples_leaf=trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "        n_jobs=-1, random_state=SEED\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "    pred_val = rf.predict(X_val)\n",
    "    p_o = y_scaler.inverse_transform(pred_val.reshape(-1,1)).ravel()\n",
    "    t_o = y_scaler.inverse_transform(y_val.reshape(-1,1)).ravel()\n",
    "    return float(np.sqrt(mean_squared_error(t_o, p_o)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2664fa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM/GRU generic\n",
    "def objective_rnn(trial: optuna.Trial, kind=\"lstm\") -> float:\n",
    "    steps   = trial.suggest_categorical(\"input_steps\",  [24, 36, 48, 60, 72])\n",
    "    horizon = trial.suggest_categorical(\"horizon_steps\",[3, 6, 12])\n",
    "    units   = trial.suggest_int(\"hidden\", 64, 256, step=32)\n",
    "    layers_n= trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "    bidir   = False\n",
    "    lr      = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "    bs      = trial.suggest_categorical(\"batch\", [64, 128, 256, 512])\n",
    "    eps     = trial.suggest_int(\"epochs\", 40, MAX_EPOCHS)\n",
    "\n",
    "    Xtr_seq, ytr_seq, Xva_seq, yva_seq = make_seq_data_for_trial(steps, horizon)\n",
    "    n_feat = Xtr_seq.shape[2]\n",
    "\n",
    "    if kind == \"lstm\":\n",
    "        model = build_lstm(steps, n_feat, units=units, layers_n=layers_n, dropout=dropout, bidir=bidir)\n",
    "    else:\n",
    "        model = build_gru(steps, n_feat, units=units, layers_n=layers_n, dropout=dropout, bidir=bidir)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss=\"mse\")\n",
    "    tmp_dir = (ART_DIR / f\"{kind}_t{trial.number:04d}\"); tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.weights.h5\").resolve()\n",
    "\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=PATIENCE, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-5, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\", save_best_only=True, save_weights_only=True),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "    model.fit(Xtr_seq, ytr_seq, validation_data=(Xva_seq, yva_seq),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    # Validación en espacio ORIGINAL\n",
    "    yhat = model.predict(Xva_seq, verbose=0).squeeze()\n",
    "    p_o = y_scaler.inverse_transform(yhat.reshape(-1,1)).ravel()\n",
    "    t_o = y_scaler.inverse_transform(yva_seq.reshape(-1,1)).ravel()\n",
    "    val_rmse = float(np.sqrt(mean_squared_error(t_o, p_o)))\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    trial.set_user_attr(\"seq_len_used\", steps)\n",
    "    trial.set_user_attr(\"horizon_used\", horizon)\n",
    "    trial.set_user_attr(\"n_feat\", n_feat)\n",
    "    trial.set_user_attr(\"arch\", kind.upper())\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ec782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dilated-like\n",
    "def objective_dilated(trial: optuna.Trial) -> float:\n",
    "    steps   = trial.suggest_categorical(\"input_steps\",  [24, 36, 48, 60, 72])\n",
    "    horizon = trial.suggest_categorical(\"horizon_steps\",[3, 6, 12])\n",
    "    units   = trial.suggest_int(\"hidden\", 64, 256, step=32)\n",
    "    dilation= trial.suggest_categorical(\"dilation\", [1, 2, 3, 4, 6])\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "    lr      = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "    bs      = trial.suggest_categorical(\"batch\", [64, 128, 256, 512])\n",
    "    eps     = trial.suggest_int(\"epochs\", 40, MAX_EPOCHS)\n",
    "\n",
    "    Xtr_seq, ytr_seq, Xva_seq, yva_seq = make_seq_data_for_trial(steps, horizon)\n",
    "    n_feat = Xtr_seq.shape[2]\n",
    "    model = build_dilated_like(steps, n_feat, units=units, dilation=dilation, dropout=dropout)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss=\"mse\")\n",
    "    tmp_dir = (ART_DIR / f\"dilated_t{trial.number:04d}\"); tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.weights.h5\").resolve()\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=PATIENCE, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\", save_best_only=True, save_weights_only=True),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "    model.fit(Xtr_seq, ytr_seq, validation_data=(Xva_seq, yva_seq),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xva_seq, verbose=0).squeeze()\n",
    "    p_o = y_scaler.inverse_transform(yhat.reshape(-1,1)).ravel()\n",
    "    t_o = y_scaler.inverse_transform(yva_seq.reshape(-1,1)).ravel()\n",
    "    val_rmse = float(np.sqrt(mean_squared_error(t_o, p_o)))\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    trial.set_user_attr(\"seq_len_used\", steps)\n",
    "    trial.set_user_attr(\"horizon_used\", horizon)\n",
    "    trial.set_user_attr(\"n_feat\", n_feat)\n",
    "    trial.set_user_attr(\"arch\", \"DILATED\")\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b02bb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clockwork\n",
    "def objective_clockwork(trial: optuna.Trial) -> float:\n",
    "    steps   = trial.suggest_categorical(\"input_steps\",  [24, 36, 48, 60, 72])\n",
    "    horizon = trial.suggest_categorical(\"horizon_steps\",[3, 6, 12])\n",
    "    hidden  = trial.suggest_int(\"hidden\", 90, 300, step=30)\n",
    "    modules = trial.suggest_categorical(\"modules\", [3, 4, 5])\n",
    "    if hidden % modules != 0:\n",
    "        raise optuna.TrialPruned()\n",
    "    base_p  = trial.suggest_categorical(\"base_period\", [1, 2])\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "    lr      = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "    bs      = trial.suggest_categorical(\"batch\", [64, 128, 256, 512])\n",
    "    eps     = trial.suggest_int(\"epochs\", 40, MAX_EPOCHS)\n",
    "\n",
    "    Xtr_seq, ytr_seq, Xva_seq, yva_seq = make_seq_data_for_trial(steps, horizon)\n",
    "    n_feat = Xtr_seq.shape[2]\n",
    "    model = build_clockwork(steps, n_feat, hidden=hidden, modules=modules, base_period=base_p, dropout=dropout)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss=\"mse\")\n",
    "    tmp_dir = (ART_DIR / f\"clock_t{trial.number:04d}\"); tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.weights.h5\").resolve()\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=PATIENCE, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\", save_best_only=True, save_weights_only=True),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "    model.fit(Xtr_seq, ytr_seq, validation_data=(Xva_seq, yva_seq),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xva_seq, verbose=0).squeeze()\n",
    "    p_o = y_scaler.inverse_transform(yhat.reshape(-1,1)).ravel()\n",
    "    t_o = y_scaler.inverse_transform(yva_seq.reshape(-1,1)).ravel()\n",
    "    val_rmse = float(np.sqrt(mean_squared_error(t_o, p_o)))\n",
    "\n",
    "    # defensas extra (evita None/NaN/Inf)\n",
    "    if not np.isfinite(val_rmse):\n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    trial.set_user_attr(\"seq_len_used\", steps)\n",
    "    trial.set_user_attr(\"horizon_used\", horizon)\n",
    "    trial.set_user_attr(\"n_feat\", n_feat)\n",
    "    trial.set_user_attr(\"arch\", \"CLOCKWORK\")\n",
    "\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7002d475",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7ff578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_study(name, obj_fn, n_trials):\n",
    "#     print(f\"→ Running {name} …\")\n",
    "#     storage = STORAGE  # o: prepare_journal_storage(name)\n",
    "#     study = optuna.create_study(direction=\"minimize\",\n",
    "#                                 sampler=TPESampler(seed=SEED),\n",
    "#                                 pruner=PRUNER,\n",
    "#                                 study_name=name,\n",
    "#                                 storage=storage,\n",
    "#                                 load_if_exists=True)\n",
    "#     study.optimize(obj_fn, n_trials=n_trials, show_progress_bar=True)\n",
    "#     print(f\"{name} best:\", study.best_trial.value, study.best_trial.params)\n",
    "#     return study\n",
    "\n",
    "def run_study(name, obj_fn, n_trials):\n",
    "    print(f\"→ Running {name} …\")\n",
    "    study = optuna.create_study(\n",
    "        direction=\"minimize\",\n",
    "        sampler=TPESampler(seed=SEED),\n",
    "        pruner=PRUNER,\n",
    "        study_name=name,\n",
    "        storage=STORAGE,\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(obj_fn, n_trials=n_trials, show_progress_bar=True)\n",
    "\n",
    "    # robustez: si no hay trials completados, no intentes best_trial\n",
    "    completes = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "    if completes:\n",
    "        print(f\"{name} best:\", study.best_trial.value, study.best_trial.params)\n",
    "    else:\n",
    "        print(f\"{name}: no completed trials (all pruned/failed).\")\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacebc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_rf   = run_study(\"RF_RMSE\", objective_rf, N_TRIALS_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e116035",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_lstm = run_study(\"LSTM_MSEval\", lambda t: objective_rnn(t,\"lstm\"), N_TRIALS_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e474d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_gru  = run_study(\"GRU_MSEval\", lambda t: objective_rnn(t,\"gru\"), N_TRIALS_GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127b8153",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_dil  = run_study(\"DilatedRNN_MSEval\", objective_dilated, N_TRIALS_DIL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e772413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_cw   = run_study(\"ClockworkRNN_MSEval\", objective_clockwork, N_TRIALS_CW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb4c1b7",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4c3d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best LSTM      :\", study_lstm.best_trial.params)\n",
    "print(\"Best GRU       :\", study_gru.best_trial.params)\n",
    "print(\"Best Dilated   :\", study_dil.best_trial.params)\n",
    "print(\"Best Clockwork :\", study_cw.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0e8a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF (tabular)\n",
    "best_rf = RandomForestRegressor(random_state=SEED, n_jobs=-1, **study_rf.best_trial.params)\n",
    "best_rf.fit(np.vstack([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "rf_opt_metrics, (y_true_rf_opt, y_pred_rf_opt) = metrics_from_scaled(best_rf.predict(X_test), y_test, y_scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e8afcc",
   "metadata": {},
   "source": [
    "## Retrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354b658e",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf23e877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebuild_and_train(best_trial, arch):\n",
    "    steps   = best_trial.user_attrs.get(\"seq_len_used\") or best_trial.params.get(\"input_steps\", DEFAULT_INPUT_STEPS)\n",
    "    horizon = best_trial.user_attrs.get(\"horizon_used\") or best_trial.params.get(\"horizon_steps\", DEFAULT_HORIZON_STEPS)\n",
    "    Xtr_seq, ytr_seq = build_seq_arrays(np.vstack([X_train, X_val]),\n",
    "                                        np.concatenate([y_train, y_val]),\n",
    "                                        steps, horizon)\n",
    "    Xva_seq, yva_seq = build_seq_arrays(X_val, y_val, steps, horizon)  # val para early stopping consistente\n",
    "    n_feat = Xtr_seq.shape[2]\n",
    "\n",
    "    p = best_trial.params\n",
    "    lr = p.get(\"lr\", 1e-3)\n",
    "    bs = p.get(\"batch\", 128)\n",
    "    eps = min(p.get(\"epochs\", MAX_EPOCHS), MAX_EPOCHS)\n",
    "\n",
    "    if arch == \"LSTM\":\n",
    "        model = build_lstm(steps, n_feat, units=p.get(\"hidden\",64),\n",
    "                           layers_n=p.get(\"num_layers\",1),\n",
    "                           dropout=p.get(\"dropout\",0.0), bidir=False)\n",
    "    elif arch == \"GRU\":\n",
    "        model = build_gru(steps, n_feat, units=p.get(\"hidden\",64),\n",
    "                          layers_n=p.get(\"num_layers\",1),\n",
    "                          dropout=p.get(\"dropout\",0.0), bidir=False)\n",
    "    elif arch == \"DILATED\":\n",
    "        model = build_dilated_like(steps, n_feat, units=p.get(\"hidden\",64),\n",
    "                                   dilation=p.get(\"dilation\",2),\n",
    "                                   dropout=p.get(\"dropout\",0.0))\n",
    "    elif arch == \"CLOCKWORK\":\n",
    "        model = build_clockwork(steps, n_feat, hidden=p.get(\"hidden\",120),\n",
    "                                modules=p.get(\"modules\",3),\n",
    "                                base_period=p.get(\"base_period\",1),\n",
    "                                dropout=p.get(\"dropout\",0.0))\n",
    "    else:\n",
    "        raise ValueError(arch)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss=\"mse\")\n",
    "    ckpt = (ART_DIR / f\"best_{arch.lower()}.weights.h5\").resolve()\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=PATIENCE, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(ckpt), monitor=\"val_loss\", save_best_only=True, save_weights_only=True),\n",
    "    ]\n",
    "    model.fit(Xtr_seq, ytr_seq, validation_data=(Xva_seq, yva_seq),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    # Eval test\n",
    "    Xte_seq, yte_seq = build_seq_arrays(X_test, y_test, steps, horizon)\n",
    "    yhat = model.predict(Xte_seq, verbose=0).squeeze()\n",
    "\n",
    "    # A métricas originales\n",
    "    p_o = y_scaler.inverse_transform(yhat.reshape(-1,1)).ravel()\n",
    "    t_o = y_scaler.inverse_transform(yte_seq.reshape(-1,1)).ravel()\n",
    "    mae  = mean_absolute_error(t_o, p_o)\n",
    "    rmse = _rmse(t_o, p_o)\n",
    "    mape = float(np.mean(np.abs((t_o + 1e-6) - p_o) / (np.abs(t_o) + 1e-6)) * 100)\n",
    "    smape= float(100*np.mean(2*np.abs(p_o - t_o)/(np.abs(t_o)+np.abs(p_o)+1e-6)))\n",
    "    r2   = r2_score(t_o, p_o)\n",
    "    return {\"MAE\":mae,\"RMSE\":rmse,\"MAPE\":mape,\"sMAPE\":smape,\"R2\":r2}, (t_o, p_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6147d52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_metrics, (yt_lstm, yp_lstm) = rebuild_and_train(study_lstm.best_trial, \"LSTM\")\n",
    "gru_metrics,  (yt_gru,  yp_gru)  = rebuild_and_train(study_gru.best_trial,  \"GRU\")\n",
    "dil_metrics,  (yt_dil,  yp_dil)  = rebuild_and_train(study_dil.best_trial,  \"DILATED\")\n",
    "cw_metrics,   (yt_cw,   yp_cw)   = rebuild_and_train(study_cw.best_trial,   \"CLOCKWORK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42374722",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175b39e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Persistence\": pers_metrics,\n",
    "    \"LinearRegression\": lin_metrics,\n",
    "    \"RandomForest_baseline\": rf0_metrics,\n",
    "    \"RandomForest_Optuna\": rf_opt_metrics,\n",
    "    \"LSTM_Optuna\": lstm_metrics,\n",
    "    \"GRU_Optuna\":  gru_metrics,\n",
    "    \"DilatedRNN_Optuna\": dil_metrics,\n",
    "    \"ClockworkRNN_Optuna\": cw_metrics,\n",
    "}\n",
    "res_df = pd.DataFrame(results).T.sort_values(\"RMSE\")\n",
    "#display(res_df.round(3))\n",
    "print(res_df.round(3).to_string())\n",
    "\n",
    "with open(ART_DIR/\"tabular_results_optuna_keras.json\",\"w\") as f:\n",
    "    json.dump({k:{m:float(vv) for m,vv in v.items()} for k,v in results.items()}, f, indent=2)\n",
    "print(\"Saved:\", ART_DIR/\"tabular_results_optuna_keras.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf287c6",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0277e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(y_true, y_pred, title, n=1000, fname=None):\n",
    "    n = min(n, len(y_true))\n",
    "    plt.figure(figsize=(11,3.8))\n",
    "    plt.plot(y_true[:n], label=\"Real\", lw=1.5)\n",
    "    plt.plot(y_pred[:n], label=\"Pred\", lw=1.2, alpha=0.9)\n",
    "    plt.title(title); plt.xlabel(\"Time steps (10-min)\"); plt.ylabel(\"GHI (W/m²)\")\n",
    "    plt.legend(frameon=False); plt.tight_layout()\n",
    "    if fname: plt.savefig(fname, dpi=140)\n",
    "    plt.show()\n",
    "\n",
    "plot_sample(y_true_rf_opt, y_pred_rf_opt, \"RandomForest Optuna — Test (sample)\",\n",
    "            fname=FIG_DIR / \"pred_rf_opt_sample.png\")\n",
    "\n",
    "for name, (yt, yp) in {\n",
    "    \"LSTM\": (yt_lstm, yp_lstm),\n",
    "    \"GRU\":  (yt_gru,  yp_gru),\n",
    "    \"Dilated\": (yt_dil, yp_dil),\n",
    "    \"Clockwork\": (yt_cw, yp_cw),\n",
    "}.items():\n",
    "    plot_sample(yt, yp, f\"{name} — Test (sample)\",\n",
    "                fname=FIG_DIR / f\"pred_{name.lower()}_sample.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e_ladino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
