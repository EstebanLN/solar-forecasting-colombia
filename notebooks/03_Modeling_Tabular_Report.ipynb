{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a8beeed",
   "metadata": {},
   "source": [
    "# 03 — Report Modeling Tabular (Keras/TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa3c56c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "import optuna\n",
    "from optuna.storages import JournalStorage, JournalFileStorage\n",
    "from optuna.storages.journal._file import JournalFileOpenLock\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0412f5dd",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84043b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path.cwd() # Path(__file__).resolve().parent\n",
    "DATA_CLEAN = (ROOT / \"../data/clean/base_dataset.csv\").resolve()\n",
    "OUT_DIR    = (ROOT / \"../outputs\").resolve()\n",
    "ART_DIR    = (OUT_DIR / \"artifacts_keras\").resolve()\n",
    "FIG_DIR    = (OUT_DIR / \"figures\").resolve()\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "632330d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "JOURNAL_PATH = (OUT_DIR / \"optuna_tabular_keras.journal\").resolve()\n",
    "LOCK = JournalFileOpenLock(str(JOURNAL_PATH) + \".lock\")\n",
    "STORAGE = JournalStorage(JournalFileStorage(str(JOURNAL_PATH), lock_obj=LOCK))\n",
    "\n",
    "TARGET_COL = \"GHI\"\n",
    "DEFAULT_INPUT_STEPS = 36\n",
    "DEFAULT_HORIZON_STEPS = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a0c866",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ffc629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(L, n_feat, units=64, layers_n=1, dropout=0.0, bidir=False):\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    x = inp\n",
    "    for _ in range(layers_n-1):\n",
    "        cell = layers.LSTM(units, return_sequences=True, dropout=dropout)\n",
    "        if bidir: cell = layers.Bidirectional(cell)\n",
    "        x = cell(x)\n",
    "    cell = layers.LSTM(units, dropout=dropout)\n",
    "    if bidir: cell = layers.Bidirectional(cell)\n",
    "    x = cell(x)\n",
    "    out = layers.Dense(1, dtype=\"float32\")(x)\n",
    "    return models.Model(inp, out)\n",
    "\n",
    "def build_gru(L, n_feat, units=64, layers_n=1, dropout=0.0, bidir=False):\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    x = inp\n",
    "    for _ in range(layers_n-1):\n",
    "        cell = layers.GRU(units, return_sequences=True, dropout=dropout)\n",
    "        if bidir: cell = layers.Bidirectional(cell)\n",
    "        x = cell(x)\n",
    "    cell = layers.GRU(units, dropout=dropout)\n",
    "    if bidir: cell = layers.Bidirectional(cell)\n",
    "    x = cell(x)\n",
    "    out = layers.Dense(1, dtype=\"float32\")(x)\n",
    "    return models.Model(inp, out)\n",
    "\n",
    "def build_dilated_like(L, n_feat, units=64, dilation=2, dropout=0.0):\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    x = layers.Lambda(lambda t: t[:, ::dilation, :])(inp)\n",
    "    x = layers.LSTM(units, dropout=dropout)(x)\n",
    "    out = layers.Dense(1, dtype=\"float32\")(x)\n",
    "    return models.Model(inp, out)\n",
    "\n",
    "def build_clockwork(L, n_feat, hidden=60, modules=3, base_period=1, dropout=0.0):\n",
    "    assert hidden % modules == 0\n",
    "    h_per = hidden // modules\n",
    "    periods = [base_period * (2**m) for m in range(modules)]\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    h_list = []\n",
    "    for p in periods:\n",
    "        xt = layers.Lambda(lambda t, step=p: t[:, ::step, :])(inp)\n",
    "        ht = layers.SimpleRNN(h_per, activation=\"tanh\", dropout=dropout)(xt)\n",
    "        h_list.append(ht)\n",
    "    h = layers.Concatenate()(h_list) if len(h_list) > 1 else h_list[0]\n",
    "    out = layers.Dense(1, dtype=\"float32\")(h)\n",
    "    return models.Model(inp, out)\n",
    "\n",
    "def build_seq_arrays(X_2d, y_1d, L, horizon):\n",
    "    N, F = X_2d.shape\n",
    "    outX, outy = [], []\n",
    "    last = N - L - horizon + 1\n",
    "    for i in range(max(0,last)):\n",
    "        outX.append(X_2d[i:i+L])\n",
    "        outy.append(y_1d[i + L + horizon - 1])\n",
    "    return np.asarray(outX, dtype=\"float32\"), np.asarray(outy, dtype=\"float32\")\n",
    "\n",
    "def metrics_from_scaled(pred_scaled, true_scaled, y_scaler):\n",
    "    p = y_scaler.inverse_transform(pred_scaled.reshape(-1,1)).ravel()\n",
    "    t = y_scaler.inverse_transform(true_scaled.reshape(-1,1)).ravel()\n",
    "    mae = mean_absolute_error(t, p)\n",
    "    rmse = float(np.sqrt(mean_squared_error(t, p)))\n",
    "    mape = float(np.mean(np.abs((t + 1e-6) - p) / (np.abs(t) + 1e-6)) * 100)\n",
    "    smape = float(100 * np.mean(2*np.abs(p - t) / (np.abs(t) + np.abs(p) + 1e-6)))\n",
    "    r2 = float(r2_score(t, p))\n",
    "    return {\"MAE\": mae, \"RMSE\": rmse, \"MAPE\": mape, \"sMAPE\": smape, \"R2\": r2}, (t, p)\n",
    "\n",
    "def plot_series(y_true, y_pred, title, n=1000, fname=None):\n",
    "    plt.rcParams[\"axes.grid\"] = True\n",
    "    plt.rcParams[\"grid.alpha\"] = 0.25\n",
    "    n = min(n, len(y_true))\n",
    "    fig, ax = plt.subplots(figsize=(11,3.8))\n",
    "    ax.plot(y_true[:n], label=\"Real\", lw=1.2)\n",
    "    ax.plot(y_pred[:n], label=\"Pred\", lw=1.0, alpha=0.95)\n",
    "    ax.set_title(title); ax.set_xlabel(\"Time steps (10-min)\"); ax.set_ylabel(\"GHI (W/m²)\")\n",
    "    ax.legend(frameon=False); fig.tight_layout()\n",
    "    if fname: fig.savefig(fname, dpi=140)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ac372b",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "635e3a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_CLEAN, parse_dates=[0], index_col=0).sort_index()\n",
    "df.index.name = \"time\"\n",
    "base_feats = [\n",
    "    'Presion','TempAmb','WindSpeed','WindDirection',\n",
    "    'hour_sin','hour_cos','DoY Sin','DoY Cos',\n",
    "    'solar_zenith','solar_azimuth','solar_elevation',\n",
    "    'TempAmb_roll1h_mean','TempAmb_roll6h_mean',\n",
    "    'Presion_roll1h_mean','Presion_roll6h_mean',\n",
    "    'WindSpeed_roll1h_mean','WindSpeed_roll6h_mean',\n",
    "    'temp_pressure_ratio','wind_temp_interaction'\n",
    "]\n",
    "ghi_lags  = [c for c in ['GHI_lag1','GHI_lag3','GHI_lag6','GHI_lag12','GHI_lag36'] if c in df.columns]\n",
    "ghi_rolls = [c for c in ['GHI_roll1h_mean','GHI_roll3h_mean','GHI_roll6h_mean','GHI_roll1h_max'] if c in df.columns]\n",
    "feat_cols = [c for c in base_feats if c in df.columns] + ghi_lags + ghi_rolls\n",
    "\n",
    "n = len(df); i_tr = int(0.7*n); i_va = int(0.85*n)\n",
    "df_train, df_val, df_test = df.iloc[:i_tr], df.iloc[i_tr:i_va], df.iloc[i_va:]\n",
    "X_scaler = StandardScaler(); y_scaler = StandardScaler()\n",
    "X_train = X_scaler.fit_transform(df_train[feat_cols].values)\n",
    "X_val   = X_scaler.transform(df_val[feat_cols].values)\n",
    "X_test  = X_scaler.transform(df_test[feat_cols].values)\n",
    "y_train = y_scaler.fit_transform(df_train[[TARGET_COL]].values).ravel()\n",
    "y_val   = y_scaler.transform(df_val[[TARGET_COL]].values).ravel()\n",
    "y_test  = y_scaler.transform(df_test[[TARGET_COL]].values).ravel()\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "X_train = imp.fit_transform(X_train); X_val = imp.transform(X_val); X_test = imp.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a223f142",
   "metadata": {},
   "source": [
    "## Reload/Rebuild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d655fa2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 17:03:01,516] Using an existing study with name 'RF_RMSE' instead of creating a new one.\n",
      "[I 2025-10-14 17:03:01,524] Using an existing study with name 'LSTM_MSEval' instead of creating a new one.\n",
      "[I 2025-10-14 17:03:01,532] Using an existing study with name 'GRU_MSEval' instead of creating a new one.\n",
      "[I 2025-10-14 17:03:01,542] Using an existing study with name 'DilatedRNN_MSEval' instead of creating a new one.\n",
      "[I 2025-10-14 17:03:01,550] Using an existing study with name 'ClockworkRNN_MSEval' instead of creating a new one.\n",
      "I0000 00:00:1760479431.155572  890921 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22136 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "I0000 00:00:1760479432.061029  891132 cuda_dnn.cc:529] Loaded cuDNN version 90101\n",
      "I0000 00:00:1760479439.272130  891132 service.cc:148] XLA service 0x7ff0117a1d40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1760479439.272150  891132 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-10-14 17:03:59.290219: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1760479439.427458  891132 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report figures saved to: /mnt/SOLARLAB/E_Ladino/Repo_2/solar-forecasting-colombia/outputs/figures\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Reload best trials from journal ----------------\n",
    "def load_best(name):  # returns optuna.study.Study\n",
    "    return optuna.create_study(study_name=name, storage=STORAGE, load_if_exists=True, direction=\"minimize\")\n",
    "\n",
    "study_rf = load_best(\"RF_RMSE\")\n",
    "study_lstm = load_best(\"LSTM_MSEval\")\n",
    "study_gru = load_best(\"GRU_MSEval\")\n",
    "study_dil = load_best(\"DilatedRNN_MSEval\")\n",
    "study_cw = load_best(\"ClockworkRNN_MSEval\")\n",
    "\n",
    "# ---------------- Rebuild models, load weights, predict ----------------\n",
    "# RF (no pesos externos)\n",
    "best_rf = RandomForestRegressor(random_state=42, n_jobs=-1, **study_rf.best_trial.params)\n",
    "best_rf.fit(np.vstack([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "rf_metrics, (y_true_rf, y_pred_rf) = metrics_from_scaled(best_rf.predict(X_test), y_test, y_scaler)\n",
    "plot_series(y_true_rf, y_pred_rf, \"RandomForest Optuna — Test (sample)\", fname=FIG_DIR / \"pred_rf_opt_sample.png\")\n",
    "\n",
    "# Redes\n",
    "def rebuild_from_trial(study, arch):\n",
    "    p = study.best_trial.params\n",
    "    L = study.best_trial.user_attrs.get(\"seq_len_used\", p.get(\"input_steps\", DEFAULT_INPUT_STEPS))\n",
    "    H = study.best_trial.user_attrs.get(\"horizon_used\",  p.get(\"horizon_steps\", DEFAULT_HORIZON_STEPS))\n",
    "    Xtr_seq, ytr_seq = build_seq_arrays(np.vstack([X_train, X_val]),\n",
    "                                        np.concatenate([y_train, y_val]), L, H)\n",
    "    Xte_seq, yte_seq = build_seq_arrays(X_test, y_test, L, H)\n",
    "    n_feat = Xtr_seq.shape[2]\n",
    "    if arch == \"LSTM\":\n",
    "        model = build_lstm(L, n_feat, p.get(\"hidden\",64), p.get(\"num_layers\",1), p.get(\"dropout\",0.0))\n",
    "        ck = ART_DIR / \"best_lstm.weights.h5\"\n",
    "    elif arch == \"GRU\":\n",
    "        model = build_gru(L, n_feat, p.get(\"hidden\",64), p.get(\"num_layers\",1), p.get(\"dropout\",0.0))\n",
    "        ck = ART_DIR / \"best_gru.weights.h5\"\n",
    "    elif arch == \"DILATED\":\n",
    "        model = build_dilated_like(L, n_feat, p.get(\"hidden\",64), p.get(\"dilation\",2), p.get(\"dropout\",0.0))\n",
    "        ck = ART_DIR / \"best_dilated.weights.h5\"\n",
    "    else:\n",
    "        model = build_clockwork(L, n_feat, p.get(\"hidden\",120), p.get(\"modules\",3), p.get(\"base_period\",1), p.get(\"dropout\",0.0))\n",
    "        ck = ART_DIR / \"best_clockwork.weights.h5\"\n",
    "    model.load_weights(str(ck))\n",
    "    yhat = model.predict(Xte_seq, verbose=0).squeeze()\n",
    "    y_true = y_scaler.inverse_transform(yte_seq.reshape(-1,1)).ravel()\n",
    "    y_pred = y_scaler.inverse_transform(yhat.reshape(-1,1)).ravel()\n",
    "    return y_true, y_pred\n",
    "\n",
    "ytrue_lstm, ypred_lstm = rebuild_from_trial(study_lstm, \"LSTM\")\n",
    "plot_series(ytrue_lstm, ypred_lstm, \"LSTM — Test (sample)\", fname=FIG_DIR / \"pred_lstm_sample.png\")\n",
    "\n",
    "ytrue_gru, ypred_gru = rebuild_from_trial(study_gru, \"GRU\")\n",
    "plot_series(ytrue_gru, ypred_gru, \"GRU — Test (sample)\", fname=FIG_DIR / \"pred_gru_sample.png\")\n",
    "\n",
    "ytrue_dil, ypred_dil = rebuild_from_trial(study_dil, \"DILATED\")\n",
    "plot_series(ytrue_dil, ypred_dil, \"Dilated — Test (sample)\", fname=FIG_DIR / \"pred_dilated_sample.png\")\n",
    "\n",
    "ytrue_cw, ypred_cw = rebuild_from_trial(study_cw, \"CLOCKWORK\")\n",
    "plot_series(ytrue_cw, ypred_cw, \"Clockwork — Test (sample)\", fname=FIG_DIR / \"pred_clockwork_sample.png\")\n",
    "\n",
    "# Linear & Persistence\n",
    "lin = LinearRegression().fit(np.vstack([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "lin_metrics, (ytrue_lin, ypred_lin) = metrics_from_scaled(lin.predict(X_test), y_test, y_scaler)\n",
    "plot_series(ytrue_lin, ypred_lin, \"LinearRegression — Test (sample)\", fname=FIG_DIR / \"pred_linear_sample.png\")\n",
    "\n",
    "def persistence_baseline(y_scaled, horizon):\n",
    "    y_hat = np.roll(y_scaled, horizon)\n",
    "    y_hat[:horizon] = y_scaled[horizon]\n",
    "    return y_hat\n",
    "\n",
    "y_pers = persistence_baseline(y_test, DEFAULT_HORIZON_STEPS)\n",
    "pers_metrics, (ytrue_pers, ypred_pers) = metrics_from_scaled(y_pers, y_test, y_scaler)\n",
    "plot_series(ytrue_pers, ypred_pers, \"Persistence — Test (sample)\", fname=FIG_DIR / \"pred_persistence_sample.png\")\n",
    "\n",
    "# (Puedes copiar aquí el resto de funciones del bloque 1 para scatter, residuales, overlay y errores por hora/bin)\n",
    "print(\"Report figures saved to:\", FIG_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e_ladino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
