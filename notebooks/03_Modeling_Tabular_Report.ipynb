{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a8beeed",
   "metadata": {},
   "source": [
    "# 03 — Report Modeling Tabular (Keras/TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa3c56c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "import optuna\n",
    "from optuna.storages import JournalStorage, JournalFileStorage\n",
    "from optuna.storages.journal._file import JournalFileOpenLock\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0412f5dd",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84043b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path.cwd() # Path(__file__).resolve().parent\n",
    "DATA_CLEAN = (ROOT / \"../data/clean/base_dataset.csv\").resolve()\n",
    "OUT_DIR    = (ROOT / \"../outputs\").resolve()\n",
    "ART_DIR    = (OUT_DIR / \"artifacts_keras\").resolve()\n",
    "FIG_DIR    = (OUT_DIR / \"figures\").resolve()\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "632330d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "JOURNAL_PATH = (OUT_DIR / \"optuna_tabular_keras.journal\").resolve()\n",
    "LOCK = JournalFileOpenLock(str(JOURNAL_PATH) + \".lock\")\n",
    "STORAGE = JournalStorage(JournalFileStorage(str(JOURNAL_PATH), lock_obj=LOCK))\n",
    "\n",
    "TARGET_COL = \"GHI\"\n",
    "DEFAULT_INPUT_STEPS = 36\n",
    "DEFAULT_HORIZON_STEPS = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a0c866",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ffc629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(L, n_feat, units=64, layers_n=1, dropout=0.0, bidir=False):\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    x = inp\n",
    "    for _ in range(layers_n-1):\n",
    "        cell = layers.LSTM(units, return_sequences=True, dropout=dropout)\n",
    "        if bidir: cell = layers.Bidirectional(cell)\n",
    "        x = cell(x)\n",
    "    cell = layers.LSTM(units, dropout=dropout)\n",
    "    if bidir: cell = layers.Bidirectional(cell)\n",
    "    x = cell(x)\n",
    "    out = layers.Dense(1, dtype=\"float32\")(x)\n",
    "    return models.Model(inp, out)\n",
    "\n",
    "def build_gru(L, n_feat, units=64, layers_n=1, dropout=0.0, bidir=False):\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    x = inp\n",
    "    for _ in range(layers_n-1):\n",
    "        cell = layers.GRU(units, return_sequences=True, dropout=dropout)\n",
    "        if bidir: cell = layers.Bidirectional(cell)\n",
    "        x = cell(x)\n",
    "    cell = layers.GRU(units, dropout=dropout)\n",
    "    if bidir: cell = layers.Bidirectional(cell)\n",
    "    x = cell(x)\n",
    "    out = layers.Dense(1, dtype=\"float32\")(x)\n",
    "    return models.Model(inp, out)\n",
    "\n",
    "def build_dilated_like(L, n_feat, units=64, dilation=2, dropout=0.0):\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    x = layers.Lambda(lambda t: t[:, ::dilation, :])(inp)\n",
    "    x = layers.LSTM(units, dropout=dropout)(x)\n",
    "    out = layers.Dense(1, dtype=\"float32\")(x)\n",
    "    return models.Model(inp, out)\n",
    "\n",
    "def build_clockwork(L, n_feat, hidden=60, modules=3, base_period=1, dropout=0.0):\n",
    "    assert hidden % modules == 0\n",
    "    h_per = hidden // modules\n",
    "    periods = [base_period * (2**m) for m in range(modules)]\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    h_list = []\n",
    "    for p in periods:\n",
    "        xt = layers.Lambda(lambda t, step=p: t[:, ::step, :])(inp)\n",
    "        ht = layers.SimpleRNN(h_per, activation=\"tanh\", dropout=dropout)(xt)\n",
    "        h_list.append(ht)\n",
    "    h = layers.Concatenate()(h_list) if len(h_list) > 1 else h_list[0]\n",
    "    out = layers.Dense(1, dtype=\"float32\")(h)\n",
    "    return models.Model(inp, out)\n",
    "\n",
    "def build_seq_arrays(X_2d, y_1d, L, horizon):\n",
    "    N, F = X_2d.shape\n",
    "    outX, outy = [], []\n",
    "    last = N - L - horizon + 1\n",
    "    for i in range(max(0,last)):\n",
    "        outX.append(X_2d[i:i+L])\n",
    "        outy.append(y_1d[i + L + horizon - 1])\n",
    "    return np.asarray(outX, dtype=\"float32\"), np.asarray(outy, dtype=\"float32\")\n",
    "\n",
    "def metrics_from_scaled(pred_scaled, true_scaled, y_scaler):\n",
    "    p = y_scaler.inverse_transform(pred_scaled.reshape(-1,1)).ravel()\n",
    "    t = y_scaler.inverse_transform(true_scaled.reshape(-1,1)).ravel()\n",
    "    mae = mean_absolute_error(t, p)\n",
    "    rmse = float(np.sqrt(mean_squared_error(t, p)))\n",
    "    mape = float(np.mean(np.abs((t + 1e-6) - p) / (np.abs(t) + 1e-6)) * 100)\n",
    "    smape = float(100 * np.mean(2*np.abs(p - t) / (np.abs(t) + np.abs(p) + 1e-6)))\n",
    "    r2 = float(r2_score(t, p))\n",
    "    return {\"MAE\": mae, \"RMSE\": rmse, \"MAPE\": mape, \"sMAPE\": smape, \"R2\": r2}, (t, p)\n",
    "\n",
    "def plot_series(y_true, y_pred, title, n=1000, fname=None):\n",
    "    plt.rcParams[\"axes.grid\"] = True\n",
    "    plt.rcParams[\"grid.alpha\"] = 0.25\n",
    "    n = min(n, len(y_true))\n",
    "    fig, ax = plt.subplots(figsize=(11,3.8))\n",
    "    ax.plot(y_true[:n], label=\"Real\", lw=1.2)\n",
    "    ax.plot(y_pred[:n], label=\"Pred\", lw=1.0, alpha=0.95)\n",
    "    ax.set_title(title); ax.set_xlabel(\"Time steps (10-min)\"); ax.set_ylabel(\"GHI (W/m²)\")\n",
    "    ax.legend(frameon=False); fig.tight_layout()\n",
    "    if fname: fig.savefig(fname, dpi=140)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ac372b",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "635e3a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_CLEAN, parse_dates=[0], index_col=0).sort_index()\n",
    "df.index.name = \"time\"\n",
    "base_feats = [\n",
    "    'Presion','TempAmb','WindSpeed','WindDirection',\n",
    "    'hour_sin','hour_cos','DoY Sin','DoY Cos',\n",
    "    'solar_zenith','solar_azimuth','solar_elevation',\n",
    "    'TempAmb_roll1h_mean','TempAmb_roll6h_mean',\n",
    "    'Presion_roll1h_mean','Presion_roll6h_mean',\n",
    "    'WindSpeed_roll1h_mean','WindSpeed_roll6h_mean',\n",
    "    'temp_pressure_ratio','wind_temp_interaction'\n",
    "]\n",
    "ghi_lags  = [c for c in ['GHI_lag1','GHI_lag3','GHI_lag6','GHI_lag12','GHI_lag36'] if c in df.columns]\n",
    "ghi_rolls = [c for c in ['GHI_roll1h_mean','GHI_roll3h_mean','GHI_roll6h_mean','GHI_roll1h_max'] if c in df.columns]\n",
    "feat_cols = [c for c in base_feats if c in df.columns] + ghi_lags + ghi_rolls\n",
    "\n",
    "n = len(df); i_tr = int(0.7*n); i_va = int(0.85*n)\n",
    "df_train, df_val, df_test = df.iloc[:i_tr], df.iloc[i_tr:i_va], df.iloc[i_va:]\n",
    "X_scaler = StandardScaler(); y_scaler = StandardScaler()\n",
    "X_train = X_scaler.fit_transform(df_train[feat_cols].values)\n",
    "X_val   = X_scaler.transform(df_val[feat_cols].values)\n",
    "X_test  = X_scaler.transform(df_test[feat_cols].values)\n",
    "y_train = y_scaler.fit_transform(df_train[[TARGET_COL]].values).ravel()\n",
    "y_val   = y_scaler.transform(df_val[[TARGET_COL]].values).ravel()\n",
    "y_test  = y_scaler.transform(df_test[[TARGET_COL]].values).ravel()\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "X_train = imp.fit_transform(X_train); X_val = imp.transform(X_val); X_test = imp.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a223f142",
   "metadata": {},
   "source": [
    "## Reload/Rebuild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d655fa2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 19:10:15,619] Using an existing study with name 'RF_RMSE' instead of creating a new one.\n",
      "[I 2025-10-14 19:10:15,627] Using an existing study with name 'LSTM_MSEval' instead of creating a new one.\n",
      "[I 2025-10-14 19:10:15,674] Using an existing study with name 'GRU_MSEval' instead of creating a new one.\n",
      "[I 2025-10-14 19:10:15,683] Using an existing study with name 'DilatedRNN_MSEval' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-14 19:10:15,693] Using an existing study with name 'ClockworkRNN_MSEval' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report figures saved to: /mnt/SOLARLAB/E_Ladino/Repo_2/solar-forecasting-colombia/outputs/figures\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Reload best trials from journal ----------------\n",
    "def load_best(name):  # returns optuna.study.Study\n",
    "    return optuna.create_study(study_name=name, storage=STORAGE, load_if_exists=True, direction=\"minimize\")\n",
    "\n",
    "study_rf = load_best(\"RF_RMSE\")\n",
    "study_lstm = load_best(\"LSTM_MSEval\")\n",
    "study_gru = load_best(\"GRU_MSEval\")\n",
    "study_dil = load_best(\"DilatedRNN_MSEval\")\n",
    "study_cw = load_best(\"ClockworkRNN_MSEval\")\n",
    "\n",
    "# ---------------- Rebuild models, load weights, predict ----------------\n",
    "# RF (no pesos externos)\n",
    "best_rf = RandomForestRegressor(random_state=42, n_jobs=-1, **study_rf.best_trial.params)\n",
    "best_rf.fit(np.vstack([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "rf_metrics, (y_true_rf, y_pred_rf) = metrics_from_scaled(best_rf.predict(X_test), y_test, y_scaler)\n",
    "plot_series(y_true_rf, y_pred_rf, \"RandomForest Optuna — Test (sample)\", fname=FIG_DIR / \"pred_rf_opt_sample.png\")\n",
    "\n",
    "# Redes\n",
    "def rebuild_from_trial(study, arch):\n",
    "    p = study.best_trial.params\n",
    "    L = study.best_trial.user_attrs.get(\"seq_len_used\", p.get(\"input_steps\", DEFAULT_INPUT_STEPS))\n",
    "    H = study.best_trial.user_attrs.get(\"horizon_used\",  p.get(\"horizon_steps\", DEFAULT_HORIZON_STEPS))\n",
    "    Xtr_seq, ytr_seq = build_seq_arrays(np.vstack([X_train, X_val]),\n",
    "                                        np.concatenate([y_train, y_val]), L, H)\n",
    "    Xte_seq, yte_seq = build_seq_arrays(X_test, y_test, L, H)\n",
    "    n_feat = Xtr_seq.shape[2]\n",
    "    if arch == \"LSTM\":\n",
    "        model = build_lstm(L, n_feat, p.get(\"hidden\",64), p.get(\"num_layers\",1), p.get(\"dropout\",0.0))\n",
    "        ck = ART_DIR / \"best_lstm.weights.h5\"\n",
    "    elif arch == \"GRU\":\n",
    "        model = build_gru(L, n_feat, p.get(\"hidden\",64), p.get(\"num_layers\",1), p.get(\"dropout\",0.0))\n",
    "        ck = ART_DIR / \"best_gru.weights.h5\"\n",
    "    elif arch == \"DILATED\":\n",
    "        model = build_dilated_like(L, n_feat, p.get(\"hidden\",64), p.get(\"dilation\",2), p.get(\"dropout\",0.0))\n",
    "        ck = ART_DIR / \"best_dilated.weights.h5\"\n",
    "    else:\n",
    "        model = build_clockwork(L, n_feat, p.get(\"hidden\",120), p.get(\"modules\",3), p.get(\"base_period\",1), p.get(\"dropout\",0.0))\n",
    "        ck = ART_DIR / \"best_clockwork.weights.h5\"\n",
    "    model.load_weights(str(ck))\n",
    "    yhat = model.predict(Xte_seq, verbose=0).squeeze()\n",
    "    y_true = y_scaler.inverse_transform(yte_seq.reshape(-1,1)).ravel()\n",
    "    y_pred = y_scaler.inverse_transform(yhat.reshape(-1,1)).ravel()\n",
    "    return y_true, y_pred\n",
    "\n",
    "ytrue_lstm, ypred_lstm = rebuild_from_trial(study_lstm, \"LSTM\")\n",
    "plot_series(ytrue_lstm, ypred_lstm, \"LSTM — Test (sample)\", fname=FIG_DIR / \"pred_lstm_sample.png\")\n",
    "\n",
    "ytrue_gru, ypred_gru = rebuild_from_trial(study_gru, \"GRU\")\n",
    "plot_series(ytrue_gru, ypred_gru, \"GRU — Test (sample)\", fname=FIG_DIR / \"pred_gru_sample.png\")\n",
    "\n",
    "ytrue_dil, ypred_dil = rebuild_from_trial(study_dil, \"DILATED\")\n",
    "plot_series(ytrue_dil, ypred_dil, \"Dilated — Test (sample)\", fname=FIG_DIR / \"pred_dilated_sample.png\")\n",
    "\n",
    "ytrue_cw, ypred_cw = rebuild_from_trial(study_cw, \"CLOCKWORK\")\n",
    "plot_series(ytrue_cw, ypred_cw, \"Clockwork — Test (sample)\", fname=FIG_DIR / \"pred_clockwork_sample.png\")\n",
    "\n",
    "# Linear & Persistence\n",
    "lin = LinearRegression().fit(np.vstack([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "lin_metrics, (ytrue_lin, ypred_lin) = metrics_from_scaled(lin.predict(X_test), y_test, y_scaler)\n",
    "plot_series(ytrue_lin, ypred_lin, \"LinearRegression — Test (sample)\", fname=FIG_DIR / \"pred_linear_sample.png\")\n",
    "\n",
    "def persistence_baseline(y_scaled, horizon):\n",
    "    y_hat = np.roll(y_scaled, horizon)\n",
    "    y_hat[:horizon] = y_scaled[horizon]\n",
    "    return y_hat\n",
    "\n",
    "y_pers = persistence_baseline(y_test, DEFAULT_HORIZON_STEPS)\n",
    "pers_metrics, (ytrue_pers, ypred_pers) = metrics_from_scaled(y_pers, y_test, y_scaler)\n",
    "plot_series(ytrue_pers, ypred_pers, \"Persistence — Test (sample)\", fname=FIG_DIR / \"pred_persistence_sample.png\")\n",
    "\n",
    "# === Scatter y residuales por modelo ===\n",
    "def scatter_and_residuals(y_true, y_pred, label, prefix):\n",
    "    # Scatter real vs pred con línea y=x\n",
    "    fig, ax = plt.subplots(figsize=(4.8,4.8))\n",
    "    ax.scatter(y_true, y_pred, s=6, alpha=0.3)\n",
    "    lim = [min(y_true.min(), y_pred.min()), max(y_true.max(), y_pred.max())]\n",
    "    ax.plot(lim, lim, 'k--', lw=1)\n",
    "    ax.set_xlim(lim); ax.set_ylim(lim)\n",
    "    ax.set_title(f\"{label} — y_true vs y_pred\")\n",
    "    ax.set_xlabel(\"Real (W/m²)\"); ax.set_ylabel(\"Pred (W/m²)\")\n",
    "    ax.grid(True, alpha=0.25)\n",
    "    fig.tight_layout(); fig.savefig(FIG_DIR / f\"{prefix}_scatter.png\", dpi=140)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Histograma de residuales\n",
    "    resid = y_true - y_pred\n",
    "    fig, ax = plt.subplots(figsize=(6,3.5))\n",
    "    ax.hist(resid, bins=60, alpha=0.9)\n",
    "    ax.axvline(0, color='k', lw=1)\n",
    "    ax.set_title(f\"{label} — Residuals (Real - Pred)\")\n",
    "    ax.set_xlabel(\"Residual (W/m²)\"); ax.set_ylabel(\"Count\")\n",
    "    fig.tight_layout(); fig.savefig(FIG_DIR / f\"{prefix}_residuals_hist.png\", dpi=140)\n",
    "    plt.close(fig)\n",
    "\n",
    "# Llamar a esta función para cada modelo\n",
    "for label, (yt, yp), pref in [\n",
    "    (\"RF Optuna\", (y_true_rf, y_pred_rf), \"rf_opt\"),\n",
    "    (\"GRU\", (ytrue_gru, ypred_gru), \"gru\"),\n",
    "    (\"LSTM\", (ytrue_lstm, ypred_lstm), \"lstm\"),\n",
    "    (\"Dilated\", (ytrue_dil, ypred_dil), \"dilated\"),\n",
    "    (\"Clockwork\", (ytrue_cw, ypred_cw), \"clock\"),\n",
    "    (\"Linear\", (ytrue_lin, ypred_lin), \"linear\"),\n",
    "    (\"Persistence\", (ytrue_pers, ypred_pers), \"persistence\"),\n",
    "]:\n",
    "    scatter_and_residuals(yt, yp, label, pref)\n",
    "\n",
    "# === Overlay de varios modelos en un solo gráfico ===\n",
    "def overlay_models(models_dict, n=800, title=\"Models overlay — Test (sample)\", fname=None):\n",
    "    fig, ax = plt.subplots(figsize=(12,4))\n",
    "    first_true = None\n",
    "    for label, (yt, yp) in models_dict.items():\n",
    "        if first_true is None:\n",
    "            first_true = yt\n",
    "            ax.plot(yt[:n], label=\"Real\", lw=1.2)\n",
    "        ax.plot(yp[:n], label=label, lw=1.0, alpha=0.9)\n",
    "    ax.set_title(title); ax.set_xlabel(\"Time steps (10-min)\"); ax.set_ylabel(\"GHI (W/m²)\")\n",
    "    ax.legend(ncol=3, frameon=False); fig.tight_layout()\n",
    "    if fname: fig.savefig(fname, dpi=140)\n",
    "    plt.close(fig)\n",
    "\n",
    "overlay_models({\n",
    "    \"RF Optuna\": (y_true_rf, y_pred_rf),\n",
    "    \"GRU\": (ytrue_gru, ypred_gru),\n",
    "    \"LSTM\": (ytrue_lstm, ypred_lstm),\n",
    "    \"Clockwork\": (ytrue_cw, ypred_cw),\n",
    "    \"Dilated\": (ytrue_dil, ypred_dil),\n",
    "    \"Linear\": (ytrue_lin, ypred_lin),\n",
    "    \"Persistence\": (ytrue_pers, ypred_pers),\n",
    "}, n=1000, fname=FIG_DIR / \"overlay_all_models_sample.png\")\n",
    "\n",
    "# === Error absoluto por bins de GHI ===\n",
    "def error_by_ghi_bins(y_true, y_pred, fname):\n",
    "    import pandas as pd\n",
    "    dfp = pd.DataFrame({\"true\": y_true, \"pred\": y_pred})\n",
    "    dfp[\"abs_err\"] = (dfp[\"true\"] - dfp[\"pred\"]).abs()\n",
    "    bins = [0, 200, 400, 600, 800, 1000, 1400]\n",
    "    dfp[\"ghi_bin\"] = pd.cut(dfp[\"true\"], bins=bins, include_lowest=True)\n",
    "    ax = dfp.boxplot(column=\"abs_err\", by=\"ghi_bin\", rot=45, grid=True, figsize=(8,4))\n",
    "    ax.set_title(\"Absolute Error by GHI bin (W/m²)\")\n",
    "    ax.set_xlabel(\"GHI bins (W/m²)\"); ax.set_ylabel(\"Abs error (W/m²)\")\n",
    "    plt.suptitle(\"\")\n",
    "    plt.tight_layout(); plt.savefig(fname, dpi=140); plt.close()\n",
    "\n",
    "error_by_ghi_bins(y_true_rf, y_pred_rf, FIG_DIR / \"rf_opt_error_by_ghi_bin.png\")\n",
    "error_by_ghi_bins(ytrue_gru, ypred_gru, FIG_DIR / \"gru_error_by_ghi_bin.png\")\n",
    "\n",
    "# === Error absoluto mediano por hora del día ===\n",
    "def error_by_hour(y_true, y_pred, ts, title, fname):\n",
    "    import pandas as pd\n",
    "    dfp = pd.DataFrame({\"true\": y_true, \"pred\": y_pred}, index=ts)\n",
    "    dfp[\"abs_err\"] = (dfp[\"true\"] - dfp[\"pred\"]).abs()\n",
    "    ax = dfp.groupby(dfp.index.hour)[\"abs_err\"].median().plot(marker=\"o\")\n",
    "    ax.set_title(title); ax.set_xlabel(\"Hour of day\"); ax.set_ylabel(\"Median Abs Error (W/m²)\")\n",
    "    plt.tight_layout(); plt.savefig(fname, dpi=140); plt.close()\n",
    "\n",
    "# Ejemplo para GRU y RF (puedes replicar para otros)\n",
    "L_gru = study_gru.best_trial.user_attrs.get(\"seq_len_used\", study_gru.best_trial.params.get(\"input_steps\"))\n",
    "H_gru = study_gru.best_trial.user_attrs.get(\"horizon_used\",  study_gru.best_trial.params.get(\"horizon_steps\"))\n",
    "ts_gru = df_test.index[L_gru + H_gru - 1 : L_gru + H_gru - 1 + len(ytrue_gru)]\n",
    "error_by_hour(ytrue_gru, ypred_gru, ts_gru,\n",
    "              \"GRU — Median Abs Error by Hour\", FIG_DIR / \"gru_err_by_hour.png\")\n",
    "error_by_hour(y_true_rf, y_pred_rf, df_test.index,\n",
    "              \"RF Optuna — Median Abs Error by Hour\", FIG_DIR / \"rf_err_by_hour.png\")\n",
    "\n",
    "print(\"Report figures saved to:\", FIG_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e_ladino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
