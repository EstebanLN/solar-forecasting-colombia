{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe9bcfa0",
   "metadata": {},
   "source": [
    "# 05 — Final Modeling Tabular\n",
    "\n",
    "## Baselines + Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54310271",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, json, math, time, random, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, regularizers, backend as K\n",
    "\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from optuna.storages import JournalStorage, JournalFileStorage\n",
    "from optuna.storages.journal._file import JournalFileOpenLock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c09e9c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "USE_MLFLOW = False\n",
    "if USE_MLFLOW:\n",
    "    try:\n",
    "        import mlflow\n",
    "    except ImportError:\n",
    "        print(\"MLflow no está instalado; desactiva USE_MLFLOW o instala mlflow.\")\n",
    "        USE_MLFLOW = False\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83410639",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5c4881",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for g in gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(g, True)\n",
    "    except Exception:\n",
    "        pass\n",
    "print(\"TF GPUs:\", gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463e0476",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "DATA_CLEAN = Path(\"../data/clean/base_dataset.csv\")\n",
    "OUT_DIR = Path(\"../outputs\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ART_DIR = OUT_DIR / \"artifacts_keras\"; ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR = OUT_DIR / \"figures\"; FIG_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157adedc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "TARGET_COL = \"GHI\"\n",
    "FREQ = \"10T\"\n",
    "DEFAULT_INPUT_STEPS   = 36   # 6h pasado\n",
    "DEFAULT_HORIZON_STEPS = 6    # 1h adelante\n",
    "\n",
    "PATIENCE = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733f858c",
   "metadata": {},
   "source": [
    "### Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a72495",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "MODE = \"AIA\"  # \"LAPTOP\" o \"AIA\"\n",
    "\n",
    "if MODE == \"LAPTOP\":\n",
    "    N_TRIALS_RF   = 30\n",
    "    N_TRIALS_LSTM = 40\n",
    "    N_TRIALS_GRU  = 40\n",
    "    N_TRIALS_DIL  = 35\n",
    "    N_TRIALS_CW   = 35\n",
    "    MAX_EPOCHS    = 60\n",
    "elif MODE == \"AIA\":\n",
    "    N_TRIALS_RF   = 120\n",
    "    N_TRIALS_LSTM = 120\n",
    "    N_TRIALS_GRU  = 120\n",
    "    N_TRIALS_DIL  = 120\n",
    "    N_TRIALS_CW   = 120\n",
    "    MAX_EPOCHS    = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a619ce",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "PRUNER = MedianPruner(n_warmup_steps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0beee6",
   "metadata": {},
   "source": [
    "### Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de46c63",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "JOURNAL_PATH = (OUT_DIR / \"optuna_tabular_keras.journal\").resolve()\n",
    "LOCK = JournalFileOpenLock(str(JOURNAL_PATH) + \".lock\")\n",
    "STORAGE = JournalStorage(JournalFileStorage(str(JOURNAL_PATH), lock_obj=LOCK))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089aa95e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_journal_storage(study_name: str) -> JournalStorage:\n",
    "    log_path = (OUT_DIR / f\"{study_name}.log\").resolve()\n",
    "    lock     = JournalFileOpenLock(str(log_path) + \".lock\")\n",
    "    return JournalStorage(JournalFileStorage(str(log_path), lock_obj=lock))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622bde68",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56e931b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_CLEAN, parse_dates=[0], index_col=0).sort_index()\n",
    "df.index.name = \"time\"\n",
    "\n",
    "base_feats = [\n",
    "    'Presion','TempAmb','WindSpeed','WindDirection',\n",
    "    'hour_sin','hour_cos','DoY Sin','DoY Cos',\n",
    "    'solar_zenith','solar_azimuth','solar_elevation',\n",
    "    'TempAmb_roll1h_mean','TempAmb_roll6h_mean',\n",
    "    'Presion_roll1h_mean','Presion_roll6h_mean',\n",
    "    'WindSpeed_roll1h_mean','WindSpeed_roll6h_mean',\n",
    "    'temp_pressure_ratio','wind_temp_interaction'\n",
    "]\n",
    "ghi_lags  = [c for c in ['GHI_lag1','GHI_lag3','GHI_lag6','GHI_lag12','GHI_lag36'] if c in df.columns]\n",
    "ghi_rolls = [c for c in ['GHI_roll1h_mean','GHI_roll3h_mean','GHI_roll6h_mean','GHI_roll1h_max'] if c in df.columns]\n",
    "feat_cols = [c for c in base_feats if c in df.columns] + ghi_lags + ghi_rolls\n",
    "print(f\"Total features used: {len(feat_cols)}\")\n",
    "print(feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd63817",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "assert TARGET_COL in df.columns, f\"TARGET_COL='{TARGET_COL}' no existe en el dataset\"\n",
    "n = len(df); i_tr = int(0.7*n); i_va = int(0.85*n)\n",
    "df_train, df_val, df_test = df.iloc[:i_tr], df.iloc[i_tr:i_va], df.iloc[i_va:]\n",
    "\n",
    "X_scaler = StandardScaler(); y_scaler = StandardScaler()\n",
    "X_train = X_scaler.fit_transform(df_train[feat_cols].values)\n",
    "X_val   = X_scaler.transform(df_val[feat_cols].values)\n",
    "X_test  = X_scaler.transform(df_test[feat_cols].values)\n",
    "\n",
    "y_train = y_scaler.fit_transform(df_train[[TARGET_COL]].values).ravel()\n",
    "y_val   = y_scaler.transform(df_val[[TARGET_COL]].values).ravel()\n",
    "y_test  = y_scaler.transform(df_test[[TARGET_COL]].values).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635608b7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"NaNs antes de imputar:\",\n",
    "      np.isnan(X_train).sum(), np.isnan(X_val).sum(), np.isnan(X_test).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d562ffd5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "imp = SimpleImputer(strategy=\"median\")\n",
    "X_train = imp.fit_transform(X_train)\n",
    "X_val   = imp.transform(X_val)\n",
    "X_test  = imp.transform(X_test)\n",
    "\n",
    "for name, arr in [(\"X_train\",X_train),(\"X_val\",X_val),(\"X_test\",X_test),\n",
    "                  (\"y_train\",y_train),(\"y_val\",y_val),(\"y_test\",y_test)]:\n",
    "    assert np.isfinite(arr).all(), f\"{name} tiene NaN/Inf\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd74149",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556bf849",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def metrics_from_scaled(pred_scaled, true_scaled, y_scaler):\n",
    "    p = y_scaler.inverse_transform(pred_scaled.reshape(-1,1)).ravel()\n",
    "    t = y_scaler.inverse_transform(true_scaled.reshape(-1,1)).ravel()\n",
    "    mae = mean_absolute_error(t, p)\n",
    "    rmse = float(np.sqrt(mean_squared_error(t, p)))\n",
    "    # MAPE corregido (sin +1e-6 en el numerador)\n",
    "    mape = float(np.mean(np.abs(t - p) / (np.abs(t) + 1e-6)) * 100)\n",
    "    smape = float(100 * np.mean(2*np.abs(p - t) / (np.abs(t) + np.abs(p) + 1e-6)))\n",
    "    r2 = float(r2_score(t, p))\n",
    "    return {\"MAE\": mae, \"RMSE\": rmse, \"MAPE\": mape, \"sMAPE\": smape, \"R2\": r2}, (t, p)\n",
    "\n",
    "def persistence_baseline(y_scaled, horizon):\n",
    "    y_hat = np.roll(y_scaled, horizon)\n",
    "    y_hat[:horizon] = y_scaled[horizon]\n",
    "    return y_hat\n",
    "\n",
    "def _rmse(a,b): return float(np.sqrt(mean_squared_error(a,b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a2e992",
   "metadata": {},
   "source": [
    "### Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195d7e24",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def build_seq_arrays(X_2d, y_1d, L, horizon):\n",
    "    \"\"\"\n",
    "    X_2d: (N, F), y_1d: (N,), L: window len (input_steps), horizon: steps ahead\n",
    "    Devuelve X_seq (N', L, F), y_seq (N',)\n",
    "    \"\"\"\n",
    "    N, F = X_2d.shape\n",
    "    outX, outy = [], []\n",
    "    last = N - L - horizon + 1\n",
    "    if last <= 0:\n",
    "        return np.zeros((0, L, F), dtype=\"float32\"), np.zeros((0,), dtype=\"float32\")\n",
    "    for i in range(last):\n",
    "        block = X_2d[i:i+L]\n",
    "        if np.isnan(block).any():\n",
    "            continue\n",
    "        outX.append(block)\n",
    "        outy.append(y_1d[i + L + horizon - 1])\n",
    "    return np.asarray(outX, dtype=\"float32\"), np.asarray(outy, dtype=\"float32\")\n",
    "\n",
    "def build_seq_arrays_with_idx(X_2d, y_1d, idx, L, horizon):\n",
    "    \"\"\"\n",
    "    Versión extendida: devuelve también los timestamps de cada muestra de salida.\n",
    "    \"\"\"\n",
    "    N, F = X_2d.shape\n",
    "    outX, outy, out_idx = [], [], []\n",
    "    last = N - L - horizon + 1\n",
    "    if last <= 0:\n",
    "        return (np.zeros((0, L, F), dtype=\"float32\"),\n",
    "                np.zeros((0,), dtype=\"float32\"),\n",
    "                np.array([], dtype=\"datetime64[ns]\"))\n",
    "    for i in range(last):\n",
    "        block = X_2d[i:i+L]\n",
    "        if np.isnan(block).any():\n",
    "            continue\n",
    "        outX.append(block)\n",
    "        outy.append(y_1d[i + L + horizon - 1])\n",
    "        out_idx.append(idx[i + L + horizon - 1])\n",
    "    return (np.asarray(outX, dtype=\"float32\"),\n",
    "            np.asarray(outy, dtype=\"float32\"),\n",
    "            np.array(out_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a03e63",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e7f245",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "lin = LinearRegression().fit(X_train, y_train)\n",
    "lin_metrics, (y_true_lin, y_pred_lin) = metrics_from_scaled(lin.predict(X_test), y_test, y_scaler)\n",
    "\n",
    "rf0 = RandomForestRegressor(n_estimators=300, random_state=SEED, n_jobs=-1).fit(X_train, y_train)\n",
    "rf0_metrics, (y_true_rf0, y_pred_rf0) = metrics_from_scaled(rf0.predict(X_test), y_test, y_scaler)\n",
    "\n",
    "y_pers_test = persistence_baseline(y_test, DEFAULT_HORIZON_STEPS)\n",
    "pers_metrics, (y_true_pers, y_pred_pers) = metrics_from_scaled(y_pers_test, y_test, y_scaler)\n",
    "\n",
    "print(\"Persistence:\", pers_metrics)\n",
    "print(\"Linear     :\", lin_metrics)\n",
    "print(\"RF baseline:\", rf0_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2ad708",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8271e8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def build_lstm(L, n_feat, units=64, layers_n=1, dropout=0.0, bidir=False):\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    x = inp\n",
    "    for i in range(layers_n-1):\n",
    "        cell = layers.LSTM(units, return_sequences=True, dropout=dropout)\n",
    "        if bidir: cell = layers.Bidirectional(cell)\n",
    "        x = cell(x)\n",
    "    cell = layers.LSTM(units, dropout=dropout)\n",
    "    if bidir: cell = layers.Bidirectional(cell)\n",
    "    x = cell(x)\n",
    "    out = layers.Dense(1, dtype=\"float32\")(x)\n",
    "    return models.Model(inp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5575507b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def build_gru(L, n_feat, units=64, layers_n=1, dropout=0.0, bidir=False):\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    x = inp\n",
    "    for i in range(layers_n-1):\n",
    "        cell = layers.GRU(units, return_sequences=True, dropout=dropout)\n",
    "        if bidir: cell = layers.Bidirectional(cell)\n",
    "        x = cell(x)\n",
    "    cell = layers.GRU(units, dropout=dropout)\n",
    "    if bidir: cell = layers.Bidirectional(cell)\n",
    "    x = cell(x)\n",
    "    out = layers.Dense(1, dtype=\"float32\")(x)\n",
    "    return models.Model(inp, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c481d4d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def build_dilated_like(L, n_feat, units=64, dilation=2, dropout=0.0):\n",
    "    assert dilation >= 1\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    x = layers.Lambda(lambda t: t[:, ::dilation, :])(inp)\n",
    "    x = layers.LSTM(units, dropout=dropout)(x)\n",
    "    out = layers.Dense(1, dtype=\"float32\")(x)\n",
    "    return models.Model(inp, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b88e1fb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def build_clockwork(L, n_feat, hidden=60, modules=3, base_period=1, dropout=0.0):\n",
    "    assert hidden % modules == 0\n",
    "    h_per = hidden // modules\n",
    "    periods = [base_period * (2**m) for m in range(modules)]\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    h_list = []\n",
    "    for p in periods:\n",
    "        xt = layers.Lambda(lambda t, step=p: t[:, ::step, :])(inp)\n",
    "        ht = layers.SimpleRNN(h_per, activation=\"tanh\", dropout=dropout)(xt)\n",
    "        h_list.append(ht)\n",
    "    h = layers.Concatenate()(h_list) if len(h_list) > 1 else h_list[0]\n",
    "    out = layers.Dense(1, dtype=\"float32\")(h)\n",
    "    return models.Model(inp, out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e09541",
   "metadata": {},
   "source": [
    "## Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c5ae41",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def make_seq_data_for_trial(steps, horizon):\n",
    "    Xtr_seq, ytr_seq = build_seq_arrays(X_train, y_train, steps, horizon)\n",
    "    Xva_seq, yva_seq = build_seq_arrays(X_val,   y_val,   steps, horizon)\n",
    "    if min(len(Xtr_seq), len(Xva_seq)) == 0:\n",
    "        raise optuna.TrialPruned()\n",
    "    return Xtr_seq, ytr_seq, Xva_seq, yva_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183c0d24",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def objective_rf(trial: optuna.Trial) -> float:\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=trial.suggest_int(\"n_estimators\", 200, 800, step=100),\n",
    "        max_depth=trial.suggest_int(\"max_depth\", 6, 28),\n",
    "        min_samples_split=trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "        min_samples_leaf=trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "        n_jobs=-1, random_state=SEED\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "    pred_val = rf.predict(X_val)\n",
    "    p_o = y_scaler.inverse_transform(pred_val.reshape(-1,1)).ravel()\n",
    "    t_o = y_scaler.inverse_transform(y_val.reshape(-1,1)).ravel()\n",
    "    return float(np.sqrt(mean_squared_error(t_o, p_o)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc353c4",
   "metadata": {},
   "source": [
    "### LSTM/GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfea9421",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def objective_rnn(trial: optuna.Trial, kind=\"lstm\") -> float:\n",
    "    steps   = trial.suggest_categorical(\"input_steps\",  [24, 36, 48, 60, 72])\n",
    "    horizon = trial.suggest_categorical(\"horizon_steps\",[3, 6, 12])\n",
    "    units   = trial.suggest_int(\"hidden\", 64, 256, step=32)\n",
    "    layers_n= trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "    bidir   = False\n",
    "    lr      = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "    bs      = trial.suggest_categorical(\"batch\", [64, 128, 256, 512])\n",
    "    eps     = trial.suggest_int(\"epochs\", 40, MAX_EPOCHS)\n",
    "\n",
    "    Xtr_seq, ytr_seq, Xva_seq, yva_seq = make_seq_data_for_trial(steps, horizon)\n",
    "    n_feat = Xtr_seq.shape[2]\n",
    "\n",
    "    if kind == \"lstm\":\n",
    "        model = build_lstm(steps, n_feat, units=units, layers_n=layers_n, dropout=dropout, bidir=bidir)\n",
    "    else:\n",
    "        model = build_gru(steps, n_feat, units=units, layers_n=layers_n, dropout=dropout, bidir=bidir)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss=\"mse\")\n",
    "    tmp_dir = (ART_DIR / f\"{kind}_t{trial.number:04d}\"); tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.weights.h5\").resolve()\n",
    "\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=PATIENCE, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-5, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\", save_best_only=True, save_weights_only=True),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "    model.fit(Xtr_seq, ytr_seq, validation_data=(Xva_seq, yva_seq),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xva_seq, verbose=0).squeeze()\n",
    "    p_o = y_scaler.inverse_transform(yhat.reshape(-1,1)).ravel()\n",
    "    t_o = y_scaler.inverse_transform(yva_seq.reshape(-1,1)).ravel()\n",
    "    val_rmse = float(np.sqrt(mean_squared_error(t_o, p_o)))\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    trial.set_user_attr(\"seq_len_used\", steps)\n",
    "    trial.set_user_attr(\"horizon_used\", horizon)\n",
    "    trial.set_user_attr(\"n_feat\", n_feat)\n",
    "    trial.set_user_attr(\"arch\", kind.upper())\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd6d81e",
   "metadata": {},
   "source": [
    "###  Dilated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5d2023",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def objective_dilated(trial: optuna.Trial) -> float:\n",
    "    steps   = trial.suggest_categorical(\"input_steps\",  [24, 36, 48, 60, 72])\n",
    "    horizon = trial.suggest_categorical(\"horizon_steps\",[3, 6, 12])\n",
    "    units   = trial.suggest_int(\"hidden\", 64, 256, step=32)\n",
    "    dilation= trial.suggest_categorical(\"dilation\", [1, 2, 3, 4, 6])\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "    lr      = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "    bs      = trial.suggest_categorical(\"batch\", [64, 128, 256, 512])\n",
    "    eps     = trial.suggest_int(\"epochs\", 40, MAX_EPOCHS)\n",
    "\n",
    "    Xtr_seq, ytr_seq, Xva_seq, yva_seq = make_seq_data_for_trial(steps, horizon)\n",
    "    n_feat = Xtr_seq.shape[2]\n",
    "    model = build_dilated_like(steps, n_feat, units=units, dilation=dilation, dropout=dropout)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss=\"mse\")\n",
    "    tmp_dir = (ART_DIR / f\"dilated_t{trial.number:04d}\"); tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.weights.h5\").resolve()\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=PATIENCE, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\", save_best_only=True, save_weights_only=True),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "    model.fit(Xtr_seq, ytr_seq, validation_data=(Xva_seq, yva_seq),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xva_seq, verbose=0).squeeze()\n",
    "    p_o = y_scaler.inverse_transform(yhat.reshape(-1,1)).ravel()\n",
    "    t_o = y_scaler.inverse_transform(yva_seq.reshape(-1,1)).ravel()\n",
    "    val_rmse = float(np.sqrt(mean_squared_error(t_o, p_o)))\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    trial.set_user_attr(\"seq_len_used\", steps)\n",
    "    trial.set_user_attr(\"horizon_used\", horizon)\n",
    "    trial.set_user_attr(\"n_feat\", n_feat)\n",
    "    trial.set_user_attr(\"arch\", \"DILATED\")\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999742b4",
   "metadata": {},
   "source": [
    "### Clockwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c7b6b7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def objective_clockwork(trial: optuna.Trial) -> float:\n",
    "    steps   = trial.suggest_categorical(\"input_steps\",  [24, 36, 48, 60, 72])\n",
    "    horizon = trial.suggest_categorical(\"horizon_steps\",[3, 6, 12])\n",
    "    hidden  = trial.suggest_int(\"hidden\", 90, 300, step=30)\n",
    "    modules = trial.suggest_categorical(\"modules\", [3, 4, 5])\n",
    "    if hidden % modules != 0:\n",
    "        raise optuna.TrialPruned()\n",
    "    base_p  = trial.suggest_categorical(\"base_period\", [1, 2])\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "    lr      = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "    bs      = trial.suggest_categorical(\"batch\", [64, 128, 256, 512])\n",
    "    eps     = trial.suggest_int(\"epochs\", 40, MAX_EPOCHS)\n",
    "\n",
    "    Xtr_seq, ytr_seq, Xva_seq, yva_seq = make_seq_data_for_trial(steps, horizon)\n",
    "    n_feat = Xtr_seq.shape[2]\n",
    "    model = build_clockwork(steps, n_feat, hidden=hidden, modules=modules, base_period=base_p, dropout=dropout)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss=\"mse\")\n",
    "    tmp_dir = (ART_DIR / f\"clock_t{trial.number:04d}\"); tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.weights.h5\").resolve()\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=PATIENCE, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\", save_best_only=True, save_weights_only=True),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "    model.fit(Xtr_seq, ytr_seq, validation_data=(Xva_seq, yva_seq),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xva_seq, verbose=0).squeeze()\n",
    "    p_o = y_scaler.inverse_transform(yhat.reshape(-1,1)).ravel()\n",
    "    t_o = y_scaler.inverse_transform(yva_seq.reshape(-1,1)).ravel()\n",
    "    val_rmse = float(np.sqrt(mean_squared_error(t_o, p_o)))\n",
    "\n",
    "    if not np.isfinite(val_rmse):\n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    trial.set_user_attr(\"seq_len_used\", steps)\n",
    "    trial.set_user_attr(\"horizon_used\", horizon)\n",
    "    trial.set_user_attr(\"n_feat\", n_feat)\n",
    "    trial.set_user_attr(\"arch\", \"CLOCKWORK\")\n",
    "\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ff1f9d",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb58568a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def run_study(name, obj_fn, n_trials):\n",
    "    print(f\"→ Running {name} …\")\n",
    "    study = optuna.create_study(\n",
    "        direction=\"minimize\",\n",
    "        sampler=TPESampler(seed=SEED),\n",
    "        pruner=PRUNER,\n",
    "        study_name=name,\n",
    "        storage=STORAGE,\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(obj_fn, n_trials=n_trials, show_progress_bar=True)\n",
    "\n",
    "    completes = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "    if completes:\n",
    "        print(f\"{name} best:\", study.best_trial.value, study.best_trial.params)\n",
    "    else:\n",
    "        print(f\"{name}: no completed trials (all pruned/failed).\")\n",
    "    return study\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9279c0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "study_rf   = run_study(\"RF_RMSE\", objective_rf, N_TRIALS_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f375d279",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "study_lstm = run_study(\"LSTM_MSEval\", lambda t: objective_rnn(t,\"lstm\"), N_TRIALS_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df8e10c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "study_gru  = run_study(\"GRU_MSEval\", lambda t: objective_rnn(t,\"gru\"), N_TRIALS_GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e40db08",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "study_dil  = run_study(\"DilatedRNN_MSEval\", objective_dilated, N_TRIALS_DIL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6750fb8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "study_cw   = run_study(\"ClockworkRNN_MSEval\", objective_clockwork, N_TRIALS_CW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc592eb",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6bf09f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Best LSTM      :\", study_lstm.best_trial.params)\n",
    "print(\"Best GRU       :\", study_gru.best_trial.params)\n",
    "print(\"Best Dilated   :\", study_dil.best_trial.params)\n",
    "print(\"Best Clockwork :\", study_cw.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98a16e7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "best_rf = RandomForestRegressor(random_state=SEED, n_jobs=-1, **study_rf.best_trial.params)\n",
    "best_rf.fit(np.vstack([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "rf_opt_metrics, (y_true_rf_opt, y_pred_rf_opt) = metrics_from_scaled(best_rf.predict(X_test), y_test, y_scaler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20a03c6",
   "metadata": {},
   "source": [
    "## Retrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f09a8b",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ee8fe4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def rebuild_and_train(best_trial, arch):\n",
    "    # Pasos y horizonte óptimos\n",
    "    steps   = best_trial.user_attrs.get(\"seq_len_used\") or best_trial.params.get(\"input_steps\", DEFAULT_INPUT_STEPS)\n",
    "    horizon = best_trial.user_attrs.get(\"horizon_used\") or best_trial.params.get(\"horizon_steps\", DEFAULT_HORIZON_STEPS)\n",
    "\n",
    "    # Reentrenar SIN mezclar train+val (evitar fuga)\n",
    "    Xtr_seq, ytr_seq = build_seq_arrays(X_train, y_train, steps, horizon)\n",
    "    Xva_seq, yva_seq = build_seq_arrays(X_val,   y_val,   steps, horizon)\n",
    "    n_feat = Xtr_seq.shape[2]\n",
    "\n",
    "    p = best_trial.params\n",
    "    lr = p.get(\"lr\", 1e-3)\n",
    "    bs = p.get(\"batch\", 128)\n",
    "    eps = min(p.get(\"epochs\", MAX_EPOCHS), MAX_EPOCHS)\n",
    "\n",
    "    if arch == \"LSTM\":\n",
    "        model = build_lstm(steps, n_feat, units=p.get(\"hidden\",64),\n",
    "                           layers_n=p.get(\"num_layers\",1),\n",
    "                           dropout=p.get(\"dropout\",0.0), bidir=False)\n",
    "    elif arch == \"GRU\":\n",
    "        model = build_gru(steps, n_feat, units=p.get(\"hidden\",64),\n",
    "                          layers_n=p.get(\"num_layers\",1),\n",
    "                          dropout=p.get(\"dropout\",0.0), bidir=False)\n",
    "    elif arch == \"DILATED\":\n",
    "        model = build_dilated_like(steps, n_feat, units=p.get(\"hidden\",64),\n",
    "                                   dilation=p.get(\"dilation\",2),\n",
    "                                   dropout=p.get(\"dropout\",0.0))\n",
    "    elif arch == \"CLOCKWORK\":\n",
    "        model = build_clockwork(steps, n_feat, hidden=p.get(\"hidden\",120),\n",
    "                                modules=p.get(\"modules\",3),\n",
    "                                base_period=p.get(\"base_period\",1),\n",
    "                                dropout=p.get(\"dropout\",0.0))\n",
    "    else:\n",
    "        raise ValueError(arch)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss=\"mse\")\n",
    "    ckpt = (ART_DIR / f\"best_{arch.lower()}.weights.h5\").resolve()\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=PATIENCE, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(ckpt), monitor=\"val_loss\", save_best_only=True, save_weights_only=True),\n",
    "    ]\n",
    "    model.fit(Xtr_seq, ytr_seq, validation_data=(Xva_seq, yva_seq),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    # Eval test\n",
    "    Xte_seq, yte_seq = build_seq_arrays(X_test, y_test, steps, horizon)\n",
    "    yhat = model.predict(Xte_seq, verbose=0).squeeze()\n",
    "\n",
    "    # Métricas en escala original\n",
    "    p_o = y_scaler.inverse_transform(yhat.reshape(-1,1)).ravel()\n",
    "    t_o = y_scaler.inverse_transform(yte_seq.reshape(-1,1)).ravel()\n",
    "    mae  = mean_absolute_error(t_o, p_o)\n",
    "    rmse = _rmse(t_o, p_o)\n",
    "    mape = float(np.mean(np.abs(t_o - p_o) / (np.abs(t_o) + 1e-6)) * 100)\n",
    "    smape= float(100*np.mean(2*np.abs(p_o - t_o)/(np.abs(t_o)+np.abs(p_o)+1e-6)))\n",
    "    r2   = r2_score(t_o, p_o)\n",
    "    return {\"MAE\":mae,\"RMSE\":rmse,\"MAPE\":mape,\"sMAPE\":smape,\"R2\":r2}, (t_o, p_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4db6bed",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "lstm_metrics, (yt_lstm, yp_lstm) = rebuild_and_train(study_lstm.best_trial, \"LSTM\")\n",
    "gru_metrics,  (yt_gru,  yp_gru)  = rebuild_and_train(study_gru.best_trial,  \"GRU\")\n",
    "dil_metrics,  (yt_dil,  yp_dil)  = rebuild_and_train(study_dil.best_trial,  \"DILATED\")\n",
    "cw_metrics,   (yt_cw,   yp_cw)   = rebuild_and_train(study_cw.best_trial,   \"CLOCKWORK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01d24f4",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2047515",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Persistence\": pers_metrics,\n",
    "    \"LinearRegression\": lin_metrics,\n",
    "    \"RandomForest_baseline\": rf0_metrics,\n",
    "    \"RandomForest_Optuna\": rf_opt_metrics,\n",
    "    \"LSTM_Optuna\": lstm_metrics,\n",
    "    \"GRU_Optuna\":  gru_metrics,\n",
    "    \"DilatedRNN_Optuna\": dil_metrics,\n",
    "    \"ClockworkRNN_Optuna\": cw_metrics,\n",
    "}\n",
    "res_df = pd.DataFrame(results).T.sort_values(\"RMSE\")\n",
    "print(res_df.round(3).to_string())\n",
    "\n",
    "with open(ART_DIR/\"tabular_results_optuna_keras.json\",\"w\") as f:\n",
    "    json.dump({k:{m:float(vv) for m,vv in v.items()} for k,vv in results.items()}, f, indent=2)\n",
    "print(\"Saved:\", ART_DIR/\"tabular_results_optuna_keras.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61512bb7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    \"LSTM_Optuna\": study_lstm.best_trial.params,\n",
    "    \"GRU_Optuna\":  study_gru.best_trial.params,\n",
    "    \"DilatedRNN_Optuna\": study_dil.best_trial.params,\n",
    "    \"ClockworkRNN_Optuna\": study_cw.best_trial.params,\n",
    "    \"RF_Optuna\": study_rf.best_trial.params,\n",
    "}\n",
    "with open(ART_DIR/\"tabular_best_params_keras.json\",\"w\") as f:\n",
    "    json.dump(best_params, f, indent=2)\n",
    "print(\"Saved:\", ART_DIR/\"tabular_best_params_keras.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3d707c",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53597e4d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def plot_sample(y_true, y_pred, title, n=1000, fname=None):\n",
    "    n = min(n, len(y_true))\n",
    "    plt.figure(figsize=(11,3.8))\n",
    "    plt.plot(y_true[:n], label=\"Real\", lw=1.5)\n",
    "    plt.plot(y_pred[:n], label=\"Pred\", lw=1.2, alpha=0.9)\n",
    "    plt.title(title); plt.xlabel(\"Time steps (10-min)\"); plt.ylabel(\"GHI (W/m²)\")\n",
    "    plt.legend(frameon=False); plt.tight_layout()\n",
    "    if fname: plt.savefig(fname, dpi=140)\n",
    "    plt.show()\n",
    "\n",
    "plot_sample(y_true_rf_opt, y_pred_rf_opt, \"RandomForest Optuna — Test (sample)\",\n",
    "            fname=FIG_DIR / \"pred_rf_opt_sample.png\")\n",
    "\n",
    "for name, (yt, yp) in {\n",
    "    \"LSTM\": (yt_lstm, yp_lstm),\n",
    "    \"GRU\":  (yt_gru,  yp_gru),\n",
    "    \"Dilated\": (yt_dil, yp_dil),\n",
    "    \"Clockwork\": (yt_cw, yp_cw),\n",
    "}.items():\n",
    "    plot_sample(yt, yp, f\"{name} — Test (sample)\",\n",
    "                fname=FIG_DIR / f\"pred_{name.lower()}_sample.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e905bf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "res_df[\"RMSE\"].plot(kind=\"bar\")\n",
    "plt.ylabel(\"RMSE (W/m²)\")\n",
    "plt.title(\"Comparación de modelos – RMSE en test\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR/\"models_rmse_bar.png\", dpi=140)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d1b055",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def scatter_pred_vs_true(y_true, y_pred, title, fname=None, lim=None):\n",
    "    plt.figure(figsize=(4.2,4.2))\n",
    "    plt.scatter(y_true, y_pred, s=5, alpha=0.3)\n",
    "    if lim is None:\n",
    "        maxv = max(np.max(y_true), np.max(y_pred))\n",
    "    else:\n",
    "        maxv = lim\n",
    "    plt.plot([0, maxv], [0, maxv], ls=\"--\")\n",
    "    plt.xlabel(\"GHI real (W/m²)\")\n",
    "    plt.ylabel(\"GHI predicho (W/m²)\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    if fname: plt.savefig(fname, dpi=140)\n",
    "    plt.show()\n",
    "\n",
    "scatter_pred_vs_true(y_true_rf_opt, y_pred_rf_opt,\n",
    "                     \"Random Forest Optuna – Test\",\n",
    "                     fname=FIG_DIR/\"scatter_rf.png\")\n",
    "\n",
    "scatter_pred_vs_true(yt_gru, yp_gru,\n",
    "                     \"GRU Optuna – Test\",\n",
    "                     fname=FIG_DIR/\"scatter_gru.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa37ad35",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def binned_rmse(y_true, y_pred, bins):\n",
    "    df_err = pd.DataFrame({\"y\": y_true, \"yhat\": y_pred})\n",
    "    df_err[\"bin\"] = pd.cut(df_err[\"y\"], bins=bins, include_lowest=True)\n",
    "    stats = df_err.groupby(\"bin\").apply(\n",
    "        lambda d: np.sqrt(mean_squared_error(d[\"y\"], d[\"yhat\"]))\n",
    "    )\n",
    "    return stats\n",
    "\n",
    "bins = [0, 200, 400, 600, 800, 1200]\n",
    "\n",
    "rf_rmse_bins = binned_rmse(y_true_rf_opt, y_pred_rf_opt, bins)\n",
    "gru_rmse_bins = binned_rmse(yt_gru, yp_gru, bins)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(rf_rmse_bins.index.astype(str), rf_rmse_bins.values, marker=\"o\", label=\"RF\")\n",
    "plt.plot(gru_rmse_bins.index.astype(str), gru_rmse_bins.values, marker=\"o\", label=\"GRU\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"RMSE (W/m²)\")\n",
    "plt.title(\"RMSE por rango de GHI real\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR/\"rmse_by_ghi_bin.png\", dpi=140)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67311ccb",
   "metadata": {},
   "source": [
    "#### Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18710c26",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def train_fixed_arch_horizon(arch, best_trial, horizon):\n",
    "    \"\"\"\n",
    "    Entrena un modelo de arquitectura fija (LSTM/GRU/DILATED/CLOCKWORK) para un horizonte dado,\n",
    "    usando los mismos hiperparámetros del best_trial salvo horizon.\n",
    "    \"\"\"\n",
    "    steps = best_trial.user_attrs.get(\"seq_len_used\") or best_trial.params.get(\"input_steps\", DEFAULT_INPUT_STEPS)\n",
    "    p = best_trial.params\n",
    "\n",
    "    Xtr_seq, ytr_seq, _ = build_seq_arrays_with_idx(X_train, y_train, df_train.index.values, steps, horizon)\n",
    "    Xva_seq, yva_seq, _ = build_seq_arrays_with_idx(X_val,   y_val,   df_val.index.values,   steps, horizon)\n",
    "    Xte_seq, yte_seq, idx_te = build_seq_arrays_with_idx(X_test,  y_test,  df_test.index.values,  steps, horizon)\n",
    "\n",
    "    n_feat = Xtr_seq.shape[2]\n",
    "    lr  = p.get(\"lr\", 1e-3)\n",
    "    bs  = p.get(\"batch\", 128)\n",
    "    eps = min(p.get(\"epochs\", MAX_EPOCHS), MAX_EPOCHS)\n",
    "    dropout = p.get(\"dropout\", 0.0)\n",
    "\n",
    "    if arch == \"LSTM\":\n",
    "        units = p.get(\"hidden\", 64)\n",
    "        layers_n = p.get(\"num_layers\", 1)\n",
    "        model = build_lstm(steps, n_feat, units=units, layers_n=layers_n, dropout=dropout, bidir=False)\n",
    "    elif arch == \"GRU\":\n",
    "        units = p.get(\"hidden\", 64)\n",
    "        layers_n = p.get(\"num_layers\", 1)\n",
    "        model = build_gru(steps, n_feat, units=units, layers_n=layers_n, dropout=dropout, bidir=False)\n",
    "    elif arch == \"DILATED\":\n",
    "        units = p.get(\"hidden\", 64)\n",
    "        dilation = p.get(\"dilation\", 2)\n",
    "        model = build_dilated_like(steps, n_feat, units=units, dilation=dilation, dropout=dropout)\n",
    "    elif arch == \"CLOCKWORK\":\n",
    "        hidden = p.get(\"hidden\", 120)\n",
    "        modules = p.get(\"modules\", 3)\n",
    "        base_period = p.get(\"base_period\", 1)\n",
    "        model = build_clockwork(steps, n_feat, hidden=hidden, modules=modules, base_period=base_period, dropout=dropout)\n",
    "    else:\n",
    "        raise ValueError(arch)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss=\"mse\")\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=PATIENCE, restore_best_weights=True, verbose=0),\n",
    "    ]\n",
    "    model.fit(Xtr_seq, ytr_seq, validation_data=(Xva_seq, yva_seq),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xte_seq, verbose=0).squeeze()\n",
    "    y_pred = y_scaler.inverse_transform(yhat.reshape(-1,1)).ravel()\n",
    "    y_true = y_scaler.inverse_transform(yte_seq.reshape(-1,1)).ravel()\n",
    "\n",
    "    return y_true, y_pred, idx_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8815f08",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def skill_vs_persistence_by_hour(y_true, y_pred, idx_times, horizon):\n",
    "    \"\"\"\n",
    "    Calcula RMSE del modelo y de la persistencia por hora del día,\n",
    "    y el skill = 1 - RMSE_model / RMSE_persistencia.\n",
    "    Aquí la persistencia se calcula simplemente como un shift sobre y_true.\n",
    "    \"\"\"\n",
    "    df_err = pd.DataFrame({\n",
    "        \"time\": idx_times,\n",
    "        \"y_true\": y_true,\n",
    "        \"y_pred\": y_pred,\n",
    "    }).set_index(\"time\")\n",
    "\n",
    "    # baseline de persistencia con la misma malla temporal (sobre y_true)\n",
    "    base_pred = np.roll(df_err[\"y_true\"].values, horizon)\n",
    "    if len(base_pred) > horizon:\n",
    "        base_pred[:horizon] = df_err[\"y_true\"].values[horizon]\n",
    "    df_err[\"baseline\"] = base_pred\n",
    "\n",
    "    df_err[\"hour\"] = df_err.index.hour\n",
    "\n",
    "    rows = []\n",
    "    for h in sorted(df_err[\"hour\"].unique()):\n",
    "        sub = df_err[df_err[\"hour\"] == h]\n",
    "        if len(sub) < 10:\n",
    "            continue\n",
    "        rmse_model = _rmse(sub[\"y_true\"], sub[\"y_pred\"])\n",
    "        rmse_base  = _rmse(sub[\"y_true\"], sub[\"baseline\"])\n",
    "        skill = 1.0 - rmse_model / (rmse_base + 1e-6)\n",
    "        rows.append((h, rmse_model, rmse_base, skill))\n",
    "    res = pd.DataFrame(rows, columns=[\"hour\",\"rmse_model\",\"rmse_base\",\"skill\"]).set_index(\"hour\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fe67fe",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def build_skill_matrix_for_arch(arch, best_trial, horizons=[1,3,6]):\n",
    "    hours = list(range(24))\n",
    "    mat_skill = np.full((len(horizons), len(hours)), np.nan)\n",
    "\n",
    "    for i, h in enumerate(horizons):\n",
    "        y_true, y_pred, idx_te = train_fixed_arch_horizon(arch, best_trial, h)\n",
    "        stats = skill_vs_persistence_by_hour(y_true, y_pred, idx_te, h)\n",
    "        for hr in stats.index:\n",
    "            if 0 <= hr < 24:\n",
    "                mat_skill[i, hr] = stats.loc[hr, \"skill\"]\n",
    "    return np.array(horizons), np.array(hours), mat_skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3272ab9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def plot_skill_heatmap(horizons, hours, mat_skill, title, fname=None):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    im = plt.imshow(mat_skill, aspect=\"auto\", origin=\"lower\",\n",
    "                    extent=[hours[0]-0.5, hours[-1]+0.5, horizons[0]-0.5, horizons[-1]+0.5])\n",
    "    plt.colorbar(im, label=\"Skill vs persistencia\")\n",
    "    plt.xlabel(\"Hora del día (issue time)\")\n",
    "    plt.ylabel(\"Horizonte (pasos de 10 min)\")\n",
    "    plt.title(title)\n",
    "    plt.xticks(hours)\n",
    "    plt.yticks(horizons)\n",
    "    plt.tight_layout()\n",
    "    if fname:\n",
    "        plt.savefig(fname, dpi=160)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253424a8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "rnn_keys = [\"LSTM_Optuna\", \"GRU_Optuna\", \"DilatedRNN_Optuna\", \"ClockworkRNN_Optuna\"]\n",
    "rnn_res = res_df.loc[[k for k in rnn_keys if k in res_df.index]]\n",
    "best_two_rnns = list(rnn_res.index[:2])\n",
    "print(\"Mejores dos RNN según RMSE:\", best_two_rnns)\n",
    "\n",
    "study_map = {\n",
    "    \"LSTM_Optuna\": study_lstm,\n",
    "    \"GRU_Optuna\": study_gru,\n",
    "    \"DilatedRNN_Optuna\": study_dil,\n",
    "    \"ClockworkRNN_Optuna\": study_cw,\n",
    "}\n",
    "arch_map = {\n",
    "    \"LSTM_Optuna\": \"LSTM\",\n",
    "    \"GRU_Optuna\": \"GRU\",\n",
    "    \"DilatedRNN_Optuna\": \"DILATED\",\n",
    "    \"ClockworkRNN_Optuna\": \"CLOCKWORK\",\n",
    "}\n",
    "\n",
    "HORIZONS = [1, 3, 6]\n",
    "\n",
    "for key in best_two_rnns:\n",
    "    arch = arch_map[key]\n",
    "    study = study_map[key]\n",
    "    print(f\"Construyendo heatmap para {arch} (clave {key}) ...\")\n",
    "    horizons_arr, hours_arr, mat_skill = build_skill_matrix_for_arch(arch, study.best_trial, HORIZONS)\n",
    "    plot_skill_heatmap(horizons_arr, hours_arr, mat_skill,\n",
    "                       f\"Skill {arch} vs persistencia por hora y horizonte\",\n",
    "                       fname=FIG_DIR/f\"heatmap_skill_{arch.lower()}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4e1a90",
   "metadata": {},
   "source": [
    "## MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab1aa20",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if USE_MLFLOW:\n",
    "    print(\"Registrando resultados en MLflow...\")\n",
    "    mlflow.set_experiment(\"ghi-tabular-rnns\")\n",
    "\n",
    "    with mlflow.start_run(run_name=\"final_tabular_models\"):\n",
    "        # Hiperparámetros\n",
    "        mlflow.log_params({f\"LSTM_{k}\": v for k,v in study_lstm.best_trial.params.items()})\n",
    "        mlflow.log_params({f\"GRU_{k}\": v for k,v in study_gru.best_trial.params.items()})\n",
    "        mlflow.log_params({f\"DIL_{k}\": v for k,v in study_dil.best_trial.params.items()})\n",
    "        mlflow.log_params({f\"CW_{k}\": v for k,v in study_cw.best_trial.params.items()})\n",
    "        mlflow.log_params({f\"RF_{k}\": v for k,v in study_rf.best_trial.params.items()})\n",
    "\n",
    "        # Métricas\n",
    "        for model_name, mets in results.items():\n",
    "            for m_name, m_val in mets.items():\n",
    "                mlflow.log_metric(f\"{model_name}_{m_name}\", float(m_val))\n",
    "\n",
    "        # Artifacts\n",
    "        mlflow.log_artifact(ART_DIR/\"tabular_results_optuna_keras.json\")\n",
    "        mlflow.log_artifact(ART_DIR/\"tabular_best_params_keras.json\")\n",
    "\n",
    "        for fig_name in [\n",
    "            \"pred_rf_opt_sample.png\",\n",
    "            \"pred_lstm_sample.png\",\n",
    "            \"pred_gru_sample.png\",\n",
    "            \"pred_dilated_sample.png\",\n",
    "            \"pred_clockwork_sample.png\",\n",
    "            \"models_rmse_bar.png\",\n",
    "            \"scatter_rf.png\",\n",
    "            \"scatter_gru.png\",\n",
    "            \"rmse_by_ghi_bin.png\",\n",
    "        ]:\n",
    "            fig_path = FIG_DIR/fig_name\n",
    "            if fig_path.exists():\n",
    "                mlflow.log_artifact(fig_path)\n",
    "\n",
    "        for key in best_two_rnns:\n",
    "            arch = arch_map[key]\n",
    "            fname = FIG_DIR/f\"heatmap_skill_{arch.lower()}.png\"\n",
    "            if fname.exists():\n",
    "                mlflow.log_artifact(fname)\n",
    "\n",
    "    print(\"MLflow logging completado.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
